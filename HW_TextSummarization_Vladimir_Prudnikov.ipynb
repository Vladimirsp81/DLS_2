{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_TextSummarization_Vladimir_Prudnikov.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d940238d6c1a435399c418967658c42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6634c76402854a88af03eeed0cce5b3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_efc6bf6fbc144da584c975bbe9dff3c4",
              "IPY_MODEL_4651ee3d18bb422bb4eefb0af0f433ec"
            ]
          }
        },
        "6634c76402854a88af03eeed0cce5b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efc6bf6fbc144da584c975bbe9dff3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c456dbaf9d64d3181d28f1b69cb5f0d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbaa4791720648ed926f06d941fb8a8e"
          }
        },
        "4651ee3d18bb422bb4eefb0af0f433ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_20517876140743fbbcab797fb26d53a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [03:40&lt;00:00,  4.53it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0d4886e93074f90a200584ad19e3ac9"
          }
        },
        "0c456dbaf9d64d3181d28f1b69cb5f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbaa4791720648ed926f06d941fb8a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20517876140743fbbcab797fb26d53a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0d4886e93074f90a200584ad19e3ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "868089a267d54418bd57d004e9159d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a9572bf225d4c12ba835092cd6b7592",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a13c0f7f383b4008bf6c9b457056bef2",
              "IPY_MODEL_c3eada2b07e848ff9c001d73c1ed25f2"
            ]
          }
        },
        "5a9572bf225d4c12ba835092cd6b7592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a13c0f7f383b4008bf6c9b457056bef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e04575adbdb47eeafc40ec89326dfb2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 12288,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12288,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f40a53a221fe428ba805f863213953a0"
          }
        },
        "c3eada2b07e848ff9c001d73c1ed25f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fd396c8ca4b404888178a18417c98e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12288/12288 [32:36&lt;00:00,  6.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47bd7b7482a04f59bea44f636c46dd89"
          }
        },
        "7e04575adbdb47eeafc40ec89326dfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f40a53a221fe428ba805f863213953a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fd396c8ca4b404888178a18417c98e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47bd7b7482a04f59bea44f636c46dd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e086fffbf78417b804fed65a400e360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7baa209d46c94fee85a884b606d23365",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5d525648f8f481a837affe4ff2bfcf4",
              "IPY_MODEL_15805032471c46fb8da0f7629be81ae8"
            ]
          }
        },
        "7baa209d46c94fee85a884b606d23365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5d525648f8f481a837affe4ff2bfcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb588c18fb7e4d148cd7c050b1f21793",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 768,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 768,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2341ccb3466247cc9dc15c186d3ff27c"
          }
        },
        "15805032471c46fb8da0f7629be81ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_339f24e2cfcf4a13992f9d09ed1bde72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 768/768 [02:38&lt;00:00,  4.84it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2de2454ef2d439985a2e6c76ce2cf1f"
          }
        },
        "cb588c18fb7e4d148cd7c050b1f21793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2341ccb3466247cc9dc15c186d3ff27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "339f24e2cfcf4a13992f9d09ed1bde72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2de2454ef2d439985a2e6c76ce2cf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab526f45e9174ba09cc73e8ea60e1246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec8c67c6cb3d4985bb72b6ff2c85818f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_253590e7be9a46fb8d3899f7ce50a36e",
              "IPY_MODEL_8d2ed9d7e16347f19dec492c616d7256"
            ]
          }
        },
        "ec8c67c6cb3d4985bb72b6ff2c85818f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "253590e7be9a46fb8d3899f7ce50a36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76a189e3f11d4ba688046cd69dd75c05",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 768,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 768,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1739c0a242c849f3a2500128b53e2f88"
          }
        },
        "8d2ed9d7e16347f19dec492c616d7256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb7899c3c24741089e3d823045a74f1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 768/768 [02:36&lt;00:00,  4.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd8bc76b17d44724bc0320ee6b3af760"
          }
        },
        "76a189e3f11d4ba688046cd69dd75c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1739c0a242c849f3a2500128b53e2f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb7899c3c24741089e3d823045a74f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd8bc76b17d44724bc0320ee6b3af760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c3136d950844ef59e2b2fe08073ead3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_81f6351d900a42d29dc0dbd360436d5f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cbae51c469ac42a5802c5f8c088eb0a9",
              "IPY_MODEL_16bff7e1e17d458a8e6005893e2f5226"
            ]
          }
        },
        "81f6351d900a42d29dc0dbd360436d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbae51c469ac42a5802c5f8c088eb0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f90643df67ad46ab9ed13c54953689f9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 642,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 642,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9f89d4314314209a6ae28d23899973a"
          }
        },
        "16bff7e1e17d458a8e6005893e2f5226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55e5f4581c294291bac0feaeba9390a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 642/642 [00:01&lt;00:00, 404B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a5f5237b3864ac9b9897a326a4f7bf8"
          }
        },
        "f90643df67ad46ab9ed13c54953689f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9f89d4314314209a6ae28d23899973a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55e5f4581c294291bac0feaeba9390a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a5f5237b3864ac9b9897a326a4f7bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3d947bc75ac4afdb52c239fd2430863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f28e6e2d1c4345968e1e120f0b405158",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d149456f285841a7b97dc6151b4e43f5",
              "IPY_MODEL_cb8e5ddaaf98402b8670f27e7a65ac10"
            ]
          }
        },
        "f28e6e2d1c4345968e1e120f0b405158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d149456f285841a7b97dc6151b4e43f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d74970ed6e064408acb7d3e77fd2cad1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1649718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1649718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7be28691d69f40c7a42e15576c7cc888"
          }
        },
        "cb8e5ddaaf98402b8670f27e7a65ac10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5293ce9bef246a6bef4c55003d7bee0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.65M/1.65M [00:05&lt;00:00, 311kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dccc0c2d731542718db10882aa82200b"
          }
        },
        "d74970ed6e064408acb7d3e77fd2cad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7be28691d69f40c7a42e15576c7cc888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5293ce9bef246a6bef4c55003d7bee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dccc0c2d731542718db10882aa82200b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a521246c182748be8d919c6393448010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3aab990b6bc14addba22d31e8a96cb96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef2db283c00347b18a0d144f4b5bc13d",
              "IPY_MODEL_fe7414f2dc1e44c9a5d8515b88285bf7"
            ]
          }
        },
        "3aab990b6bc14addba22d31e8a96cb96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef2db283c00347b18a0d144f4b5bc13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb9ef205b1574b64a193369da6444978",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df88c053c3df4dda939286d71695f80e"
          }
        },
        "fe7414f2dc1e44c9a5d8515b88285bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62260b343e794232836b8d98761e591a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:01&lt;00:00, 64.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a54a395ddc24cf6a9956f47d21d38f5"
          }
        },
        "cb9ef205b1574b64a193369da6444978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df88c053c3df4dda939286d71695f80e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62260b343e794232836b8d98761e591a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a54a395ddc24cf6a9956f47d21d38f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "142ba7e0846d4ea1b166ff2360065673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48dfcf8d69e44c189e263e7551df7e2e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3887f69c06a475a83dbb8c46b0d12a1",
              "IPY_MODEL_11bc5477911d48fe96b3749edff7c86f"
            ]
          }
        },
        "48dfcf8d69e44c189e263e7551df7e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3887f69c06a475a83dbb8c46b0d12a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee052781872c4ca7ab2268ff27119e4a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be8381255ef04c95be4ec7dea88eec52"
          }
        },
        "11bc5477911d48fe96b3749edff7c86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_935aaeb9b3c84ad89645093cbfaa2ea0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:00&lt;00:00, 12.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c6e062b3b2247b285a15a0ff5d1df72"
          }
        },
        "ee052781872c4ca7ab2268ff27119e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be8381255ef04c95be4ec7dea88eec52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "935aaeb9b3c84ad89645093cbfaa2ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c6e062b3b2247b285a15a0ff5d1df72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df1eaed187b14437b29e2e4a2671b7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c1b852c8c40849e6938cddbcadd76ae2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a7f285e92da846d59cbd098fc4bb1c42",
              "IPY_MODEL_78298d57211e47ba84b169a0486e5ccd"
            ]
          }
        },
        "c1b852c8c40849e6938cddbcadd76ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7f285e92da846d59cbd098fc4bb1c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8727f3c9505f4be79d3c0cbbf58032e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 711456796,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 711456796,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a9eb6b76c5a400ba490360036e85fdb"
          }
        },
        "78298d57211e47ba84b169a0486e5ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0598fd987d1640378e86e5b4adf14b17",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 711M/711M [00:31&lt;00:00, 22.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0b8d577b6a24ea7b8825ba5af66b0ba"
          }
        },
        "8727f3c9505f4be79d3c0cbbf58032e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a9eb6b76c5a400ba490360036e85fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0598fd987d1640378e86e5b4adf14b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0b8d577b6a24ea7b8825ba5af66b0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vladimirsp81/DLS_2/blob/master/HW_TextSummarization_Vladimir_Prudnikov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmb8UhIzOnfK",
        "colab_type": "text"
      },
      "source": [
        "# Text Summarization. Homework\n",
        "\n",
        "Всем привет! Это домашка по суммаризации текста.\n",
        "\n",
        "На семинаре мы рассмотрели базовые модели для суммаризации текста. Попробуйте теперь улучшить два метода: TextRank и Extractive RNN. Задание достаточно большое и требует хорошую фантазию, тут можно эксперементировать во всю.\n",
        "\n",
        "Для сдачи заданий надо получить определенное качество по test-у:\n",
        "\n",
        "- 1 задание: 0.27 BLEU\n",
        "- 2 задание: 0.3 BLEU\n",
        "\n",
        "Если ваш подход пробивает это качество – задание считается пройденным. Плюсом будет описание того, почему вы решили использовать то или иное решение. \n",
        "\n",
        "Датасет: gazeta.ru\n",
        "\n",
        "**P.S.** Возможно, в датасете находятся пустые данные. Проверьте эту гипотезу, и если надо, сделайте предобратоку датасета.\n",
        "\n",
        "\n",
        "`Ноутбук создан на основе семинара Гусева Ильи на кафедре компьютерной лингвистики МФТИ.`\n",
        "\n",
        "Загрузим датасет и необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqkLTkFRfXvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
        "!wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
        "!wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXS1sdYZCluU",
        "colab_type": "code",
        "outputId": "cb69f088-e9de-41d4-eb70-917ee5ef0493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade razdel allennlp torch fasttext OpenNMT-py networkx pymorphy2 nltk rouge==0.3.1 summa\n",
        "!pip install transformers youtokentome catalyst"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 3.9MB/s \n",
            "\u001b[?25hRequirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hCollecting OpenNMT-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c7/b3d9bf9a6a681b10c00aa897650f79d4e7ad8a80317c5cddb6a3ef43540c/OpenNMT_py-1.1.1-py3-none-any.whl (189kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 40.8MB/s \n",
            "\u001b[?25hRequirement already up-to-date: networkx in /usr/local/lib/python3.6/dist-packages (2.4)\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hCollecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 41.6MB/s \n",
            "\u001b[?25hCollecting rouge==0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/89/af359c22e1d858e0299d4cc9219f36b504817c9797acad23081247867845/rouge-0.3.1-py3-none-any.whl\n",
            "Collecting summa\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/3b/1c7dc435d05aef474c4137328400f1e11787b9bffab1f87a3f160c1fef54/summa-1.2.0.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.13.13)\n",
            "Requirement already satisfied, skipping upgrade: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/70/ed1ba808a87d896b9f4d25400dda54e089ca7a97e87cee620b3744997c89/jsonnet-0.16.0.tar.gz (256kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 46.4MB/s \n",
            "\u001b[?25hCollecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Collecting spacy<2.2,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl (30.8MB)\n",
            "\u001b[K     |████████████████████████████████| 30.9MB 100kB/s \n",
            "\u001b[?25hCollecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.1)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 41.3MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 46.8MB/s \n",
            "\u001b[?25hCollecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 42.0MB/s \n",
            "\u001b[?25hCollecting gevent>=1.3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/db/5a9852b2940fc45d134d332fc277a39a7eb365522d1a99452120cd9e9585/gevent-20.5.1-cp36-cp36m-manylinux2010_x86_64.whl (5.2MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2MB 33.9MB/s \n",
            "\u001b[?25hCollecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/01/0c/e4da4191474e27bc41bedab2bf249b27d9261db749f59769d7e7ca8feead/responses-0.10.14-py2.py3-none-any.whl\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d8/5e877ac5e827eaa41a7ea8c0dc1d3042e05d7e337604dc2aedb854e7b500/ftfy-5.7.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hCollecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Collecting numpydoc>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/43/2402fd1f63992a52f88e3b169d59674617013bf7f1ad0cd7d842eafd0c58/numpydoc-1.0.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hCollecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.3.0)\n",
            "Collecting pyonmttok==1.*; platform_system == \"Linux\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/2e/4f589ec5bcf916229bb7374e66e3824b97ae4c8c4ea28c404aed15be3c01/pyonmttok-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 39.4MB/s \n",
            "\u001b[?25hCollecting waitress\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/ca/ede3ed29723ca944f6e77bd1d7b38c271dd801c7d6a11ab6037597e4fd5b/waitress-1.4.3-py2.py3-none-any.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.12.0)\n",
            "Collecting torchtext==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (2.2.1)\n",
            "Collecting configargparse\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/79/3045743bb26ca2e44a1d317c37395462bfed82dbbd38e69a3280b63696ce/ConfigArgParse-1.2.3.tar.gz (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx) (4.4.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 37.8MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.16.13)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.6.0)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 24.4MB/s \n",
            "\u001b[?25hCollecting thinc<7.1.0,>=7.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 22.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.9)\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 42.3MB/s \n",
            "\u001b[?25hCollecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/96/361edb421a077a4c208b4a5c212737d78ae03ce67fbbcd01621c49f332d1/zope.event-4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.29.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->allennlp) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied, skipping upgrade: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.2)\n",
            "Requirement already satisfied, skipping upgrade: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.4.8)\n",
            "Building wheels for collected packages: fasttext, nltk, summa, word2number, jsonnet, overrides, ftfy, parsimonious, configargparse\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3018867 sha256=7ae6c882726bba7443f22e6a0424753460d41c40b9f1926a477a34ef155e8393\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=9ba699d53f6cd0206c7eae6c656143167c267d5625a9850b901fb5cb7114bbba\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-cp36-none-any.whl size=54411 sha256=59fcf6dadf3fee38873e9872058bd833eca1d9a966cee7f11e52cddbca911aba\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/09/68/e2f2861c01d86407c3fa5220826ed7eed2abaa56b001be5970\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5587 sha256=51b8cb2bea447f9b7e72f2d5a02c63ce8ba4ccde7f05674eb2dae43128d8dc92\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3321541 sha256=e25b5e89afc9f9c7a98f637b1a68796b5c615c46eab4c7b80ad10568c6b12e8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/a9/43/bc5e0463deeec89dfca928a2a64595f1bdb520c891f6fbd09c\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=18dac667a69f12a8df8ac9c00c6a3e5b49fc0c1a4837003126c0e7ec94fed247\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.7-cp36-none-any.whl size=44593 sha256=48b1e61c81b51162c54aae1316f3318c99afe0a9c6e313fd2aa3df9633cc3725\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/da/59/6c8925d571aacade638a0f515960c21c0887af1bfe31908fbf\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42712 sha256=2f4a2214f50eebd26c2d9ad96eed5526333c7f3bee8e653d1ac3ffd8ea807a85\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configargparse: filename=ConfigArgParse-1.2.3-cp36-none-any.whl size=19328 sha256=965a48d7132c46408fc70eb53327389e530556d7c8842680c7afa0c024c4caac\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d6/53/034032da9498bda2385cd50a51a289e88090b5da2d592b1fdf\n",
            "Successfully built fasttext nltk summa word2number jsonnet overrides ftfy parsimonious configargparse\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: opennmt-py 1.1.1 has requirement tqdm~=4.30.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: razdel, word2number, sentencepiece, pytorch-transformers, jsonnet, overrides, preshed, plac, blis, thinc, spacy, jsonpickle, nltk, flask-cors, tensorboardX, pytorch-pretrained-bert, flaky, unidecode, zope.interface, greenlet, zope.event, gevent, responses, ftfy, parsimonious, numpydoc, conllu, allennlp, fasttext, pyonmttok, waitress, torchtext, configargparse, OpenNMT-py, pymorphy2-dicts, dawg-python, pymorphy2, rouge, summa\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed OpenNMT-py-1.1.1 allennlp-0.9.0 blis-0.2.4 configargparse-1.2.3 conllu-1.3.1 dawg-python-0.7.2 fasttext-0.9.2 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.7 gevent-20.5.1 greenlet-0.4.15 jsonnet-0.16.0 jsonpickle-1.4.1 nltk-3.5 numpydoc-1.0.0 overrides-3.0.0 parsimonious-0.8.1 plac-0.9.6 preshed-2.0.1 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pyonmttok-1.18.4 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 razdel-0.5.0 responses-0.10.14 rouge-0.3.1 sentencepiece-0.1.91 spacy-2.1.9 summa-1.2.0 tensorboardX-2.0 thinc-7.0.8 torchtext-0.4.0 unidecode-1.1.1 waitress-1.4.3 word2number-1.1 zope.event-4.4 zope.interface-5.1.0\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 2.8MB/s \n",
            "\u001b[?25hCollecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 13.2MB/s \n",
            "\u001b[?25hCollecting catalyst\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/58/03dd689feee9089450d977b3be7b4579f097d236532afaeb64202d18fb72/catalyst-20.5.1-py2.py3-none-any.whl (362kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n",
            "Collecting deprecation\n",
            "  Downloading https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.0)\n",
            "Collecting crc32c>=1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/82/f60248c01a8a23ae07bd4c43d78d69b20ffe324311db3b0785e391aa09d2/crc32c-2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.5.0+cu101)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.0.3)\n",
            "Collecting GitPython>=3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.2.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.22.2.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst) (20.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.29.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (46.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.6.0.post3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.9.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.4.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2.8.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (1.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.1.9)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=22c28adaa37ae1d96b6704df4383b4d5616ad921288357e0930dd0297c086cbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, youtokentome, deprecation, crc32c, smmap, gitdb, GitPython, catalyst\n",
            "Successfully installed GitPython-3.1.2 catalyst-20.5.1 crc32c-2.0 deprecation-2.1.0 gitdb-4.0.5 sacremoses-0.0.43 smmap-3.0.4 tokenizers-0.7.0 transformers-2.10.0 youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pZ2UGS2DGjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
        "    assert shuffle != sort_by_date\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        for line in r:\n",
        "            records.append(eval(line)) # Simple hack\n",
        "    records = pd.DataFrame(records)\n",
        "    if sort_by_date:\n",
        "        records = records.sort(\"date\")\n",
        "    if shuffle:\n",
        "        records = records.sample(frac=1)\n",
        "    return records"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDp-BunEA91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
        "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
        "test_records = read_gazeta_records(\"gazeta_test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAcVSli3r3S",
        "colab_type": "text"
      },
      "source": [
        "## 1 задание: TextRank (порог: 0.27 BLEU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7jAQp-_Ds98",
        "colab_type": "text"
      },
      "source": [
        "TextRank - unsupervised метод для составления кратких выжимок из текста. \n",
        "Описание метода:\n",
        "\n",
        "1. Сплитим текст по предложениям\n",
        "2. Считаем \"похожесть\" предложений между собой\n",
        "3. Строим граф предложений с взвешенными ребрами\n",
        "4. С помощью алгоритм PageRank получаем наиболее важные предложения, на основе которых делаем summary.\n",
        "\n",
        "Функция похожести можно сделать и из нейросетевых(или около) моделек: FastText, ELMO и BERT. Выберете один метод, загрузите предобученную модель и с ее помощью для каждого предложениия сделайте sentence embedding. С помощью косинусной меры определяйте похожесть предложений.\n",
        "\n",
        "Предобученные модели можно взять по [ссылке](http://docs.deeppavlov.ai/en/master/features/pretrained_vectors.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VblCmc68__Sf",
        "colab_type": "code",
        "outputId": "6bc56f0c-80d2-410a-817a-66e5b14f89a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-26 20:06:56--  http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662024852 (631M) [application/octet-stream]\n",
            "Saving to: ‘rubert_cased_L-12_H-768_A-12_pt.tar.gz’\n",
            "\n",
            "rubert_cased_L-12_H 100%[===================>] 631.36M  8.69MB/s    in 92s     \n",
            "\n",
            "2020-05-26 20:08:29 (6.85 MB/s) - ‘rubert_cased_L-12_H-768_A-12_pt.tar.gz’ saved [662024852/662024852]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIcXRsNRSupD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf '/content/rubert_cased_L-12_H-768_A-12_pt.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGTrjofVU_Ml",
        "colab_type": "code",
        "outputId": "f9bedf72-ffab-4e67-a364-2d1c4d7128fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/74/600871c188f82023575c86f6119804c35f0cdbd009bd5b73e4538978ba3d/deeppavlov-0.9.1-py3-none-any.whl (777kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 5.7MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.10.0)\n",
            "Collecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 14.2MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 56.5MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy==0.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Collecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.8)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 40.3MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/9f/83bb34eaf84032b0b54fcc4a6aff1858572d279d65a301c7ae875f523df5/ruamel.yaml-0.15.100-cp36-cp36m-manylinux1_x86_64.whl (656kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (4.41.1)\n",
            "Collecting uvicorn==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/11f4b4bf3963ead6de570feeae49eeced02f6768cf1f68e16f4b16d3b0aa/uvicorn-0.11.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 48.1MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 7.8MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 40.7MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 8.8MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.10.0->deeppavlov) (1.12.0)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov) (0.7)\n",
            "Collecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov) (7.1.2)\n",
            "Collecting httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 58.3MB/s \n",
            "\u001b[?25hCollecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 39.2MB/s \n",
            "\u001b[?25hCollecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 59.0MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/90/e8089608c2fcf75d6a8ff805611a1e31ed7cc523f5eafe244a2fb3dd75b8/aiormq-3.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.15.1)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.0)\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 50.0MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: nltk, overrides, pytelegrambotapi, starlette, httptools\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449905 sha256=6186a50b28f6366240da0c6fe94cbc7a82c21ea2fb67439863c4548d23251b66\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=0347a43f65875314ece2dbebf79b79567a5a8f6526751de0da100d1f8ad72326\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47178 sha256=ce13f2b25f127c6654b87194b00cf5b8a48c9f33201949880b4c5c1d663f9991\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=d698e38b00b03d2813757d6298f8c6ddf0def529eb6fccff12b05a31495a1e47\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212524 sha256=e9d756e15335e9d88af15bcc5d1d94de4fec31451e282c69b917a56936392cae\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
            "Successfully built nltk overrides pytelegrambotapi starlette httptools\n",
            "\u001b[31mERROR: opennmt-py 1.1.1 has requirement tqdm~=4.30.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: starlette, pydantic, fastapi, pymorphy2-dicts-ru, nltk, fuzzywuzzy, overrides, cryptography, pyopenssl, idna, requests, pytelegrambotapi, ruamel.yaml, websockets, h11, httptools, uvloop, uvicorn, Cython, multidict, yarl, pamqp, aiormq, aio-pika, numpy, pandas, rusenttokenize, scikit-learn, deeppavlov\n",
            "  Found existing installation: nltk 3.5\n",
            "    Uninstalling nltk-3.5:\n",
            "      Successfully uninstalled nltk-3.5\n",
            "  Found existing installation: overrides 3.0.0\n",
            "    Uninstalling overrides-3.0.0:\n",
            "      Successfully uninstalled overrides-3.0.0\n",
            "  Found existing installation: idna 2.9\n",
            "    Uninstalling idna-2.9:\n",
            "      Successfully uninstalled idna-2.9\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: Cython 0.29.18\n",
            "    Uninstalling Cython-0.29.18:\n",
            "      Successfully uninstalled Cython-0.29.18\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "  Found existing installation: pandas 1.0.3\n",
            "    Uninstalling pandas-1.0.3:\n",
            "      Successfully uninstalled pandas-1.0.3\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.2 cryptography-2.9.2 deeppavlov-0.9.1 fastapi-0.47.1 fuzzywuzzy-0.17.0 h11-0.9.0 httptools-0.0.13 idna-2.8 multidict-4.7.6 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 pydantic-1.3 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.1 uvloop-0.14.0 websockets-8.1 yarl-1.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "numpy",
                  "pandas",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i6CJzC56LPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov.core.common.file import read_json\n",
        "from deeppavlov import build_model, configs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvqOFS4P6cQE",
        "colab_type": "code",
        "outputId": "a7c2670f-0e5d-41a3-8699-fb2d2a912e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "bert_config = read_json(configs.embedder.bert_embedder)\n",
        "bert_config['metadata']['variables']['BERT_PATH'] = '/content/rubert_cased_L-12_H-768_A-12_pt'\n",
        "\n",
        "model = build_model(bert_config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoux_nnyFX0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "import razdel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VrDQYBq_Rds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "def calc_scores(references, predictions, metric=\"all\"):\n",
        "    print(\"Count:\", len(predictions))\n",
        "    print(\"Ref:\", references[-1])\n",
        "    print(\"Hyp:\", predictions[-1])\n",
        "\n",
        "    if metric in (\"bleu\", \"all\"):\n",
        "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
        "    if metric in (\"rouge\", \"all\"):\n",
        "        rouge = Rouge()\n",
        "        scores = rouge.get_scores(predictions, references, avg=True)\n",
        "        print(\"ROUGE: \", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GwyRrMPAzS",
        "colab_type": "code",
        "outputId": "b889cc3e-97f2-4a63-d3f9-f597ad760106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "%%time\n",
        "from itertools import combinations\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pymorphy2\n",
        "\n",
        "# Используйте эту штуку как бэйзлайн\n",
        "def unique_words_similarity(words1, words2):\n",
        "    '''\n",
        "    Функция подсчёта близости предложений на основе пересечения слов\n",
        "    ''' \n",
        "    words1 = set(words1)\n",
        "    words2 = set(words2)\n",
        "    if not len(words1) or not len(words2):\n",
        "        return 0.0\n",
        "    return len(words1.intersection(words2))/(np.log10(len(words1)) + np.log10(len(words2)))\n",
        "\n",
        "def your_super_words_similarity(words1, words2):\n",
        "    # Your code\n",
        "    sent = [words1, words2]\n",
        "    tokens, token_embs, subtokens, subtoken_embs, sent_max_embs, sent_mean_embs, bert_pooler_outputs = model(sent)\n",
        "    similarity = scipy.spatial.distance.cosine(bert_pooler_outputs[0], bert_pooler_outputs[1])\n",
        "\n",
        "    return similarity\n",
        "\n",
        "def gen_text_rank_summary(text, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, morph=None):\n",
        "    '''\n",
        "    Составление summary с помощью TextRank\n",
        "    '''\n",
        "    # Разбиваем текст на предложения\n",
        "    sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
        "    n_sentences = len(sentences)\n",
        "\n",
        "    # Токенизируем предложения\n",
        "    sentences_words = [[token.text.lower() if lower else token.text for token in razdel.tokenize(sentence)] for sentence in sentences]\n",
        "\n",
        "    # При необходимости лемматизируем слова\n",
        "    if morph is not None:\n",
        "        sentences_words = [[morph.parse(word)[0].normal_form for word in words] for words in sentences_words]\n",
        "\n",
        "    # Для каждой пары предложений считаем близость\n",
        "    pairs = combinations(range(n_sentences), 2)\n",
        "    scores = [(i, j, calc_similarity(sentences_words[i], sentences_words[j])) for i, j in pairs]\n",
        "\n",
        "    # Строим граф с рёбрами, равными близости между предложениями\n",
        "    g = nx.Graph()\n",
        "    g.add_weighted_edges_from(scores)\n",
        "\n",
        "    # Считаем PageRank\n",
        "    pr = nx.pagerank(g)\n",
        "    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n",
        "    result.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Выбираем топ предложений\n",
        "    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n",
        "    result = result[:n_summary_sentences]\n",
        "\n",
        "    # Восстанавливаем оригинальный их порядок\n",
        "    result.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Восстанавливаем текст выжимки\n",
        "    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n",
        "    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n",
        "    return predicted_summary\n",
        "\n",
        "def calc_text_rank_score(records, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, nrows=1000, morph=None):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for text, summary in records[['text', 'summary']].values[:nrows]:\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        predicted_summary = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n",
        "        text = text if not lower else text.lower()\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_text_rank_score(test_records, calc_similarity=unique_words_similarity)\n",
        "calc_text_rank_score(test_records, calc_similarity=your_super_words_similarity)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: украинская писательница лариса ницой раскритиковала участников и членов жюри нацотбора на «евровидение-2020» за использование русского языка. она заявила, что одна из артисток «пренебрежительно» относится к родному языку и назвала «козлами» артиста андрея данилко (верка сердючка) и продюсера руслана квинту.\n",
            "Hyp: «перепрыгивает с украинского на русский, даже не замечая этого, — возмутилась она. «спецразработка, чтобы, не дай бог, не заговорили все на украинском», — уверена ницой. в 2019 году украину на «евровидении» должна была представлять певица maruv, но в предложенном контракте ее не устроил пункт о запрете выступать в россии и ряд других жестких требований.\n",
            "BLEU:  0.27462959007731597\n",
            "ROUGE:  {'rouge-1': {'f': 0.1598688066977366, 'p': 0.13265208579998486, 'r': 0.2159307810626273}, 'rouge-2': {'f': 0.03648547206749619, 'p': 0.029489569984196617, 'r': 0.05183898329233899}, 'rouge-l': {'f': 0.12713362237801293, 'p': 0.11797839871172253, 'r': 0.19237418967548445}}\n",
            "Count: 1000\n",
            "Ref: украинская писательница лариса ницой раскритиковала участников и членов жюри нацотбора на «евровидение-2020» за использование русского языка. она заявила, что одна из артисток «пренебрежительно» относится к родному языку и назвала «козлами» артиста андрея данилко (верка сердючка) и продюсера руслана квинту.\n",
            "Hyp: также на нацотборе присутствовал исполнитель константин бочаров (melovin) — в 2018 году он уже представлял украину на «евровидении» и занял 17-е место. пусть тебе повезет, наша суперзвезда! в 2019 году украину на «евровидении» должна была представлять певица maruv, но в предложенном контракте ее не устроил пункт о запрете выступать в россии и ряд других жестких требований.\n",
            "BLEU:  0.3039025232143511\n",
            "ROUGE:  {'rouge-1': {'f': 0.11817520514791913, 'p': 0.13431084466983206, 'r': 0.11776534346032563}, 'rouge-2': {'f': 0.01954220699042647, 'p': 0.02323872327588019, 'r': 0.019688848618822304}, 'rouge-l': {'f': 0.09992343986500181, 'p': 0.12393870207169162, 'r': 0.10775963393843808}}\n",
            "CPU times: user 3h 54min 32s, sys: 19min 37s, total: 4h 14min 10s\n",
            "Wall time: 4h 14min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdTrfxycB7cd",
        "colab_type": "text"
      },
      "source": [
        "## 2 Задание: Extractive RNN (порог: 0.3 BLEU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q7DeHDYFSjX",
        "colab_type": "text"
      },
      "source": [
        "Второй метод, который вам предлагается улучшить – поиск предложений для summary с помощью RNN. В рассмотренной методе мы использовали LSTM для генерации sentence embedding. Попробуйте использовать другие архитектуры: CNN, Transformer; или добавьте предобученные модели, как и в первом задании.\n",
        "\n",
        "P.S. Тут предполагается, что придется изменять много кода в ячееках (например, поменять токенизацию). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dZamxigdEc-",
        "colab_type": "text"
      },
      "source": [
        "### Модель\n",
        "\n",
        "Картинка для привлечения внимания:\n",
        "\n",
        "![img](https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_14%2Fproject_398421%2Fimages%2Farchitecture.png)\n",
        "\n",
        "Статья с оригинальным методом:\n",
        "https://arxiv.org/pdf/1611.04230.pdf\n",
        "\n",
        "Список вдохновения: \n",
        "- https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b Пример того, как можно применять CNN в текстовых задачах\n",
        "- https://arxiv.org/pdf/1808.08745.pdf Очень крутой метод генерации summary без Transformers\n",
        "- https://towardsdatascience.com/super-easy-way-to-get-sentence-embedding-using-fasttext-in-python-a70f34ac5b7c – простой метод генерации sentence embedding\n",
        "- https://towardsdatascience.com/fse-2b1ffa791cf9 – Необычный метод генерации sentence embedding\n",
        "- https://github.com/UKPLab/sentence-transformers – BERT предобученный для sentence embedding\n",
        "\n",
        "P.S. Выше написанные ссылки нужны только для разогрева вашей фантазии, можно воспользоваться ими, а можно придумать свой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxsc0Orf8hGq",
        "colab_type": "code",
        "outputId": "d4799546-3a28-44c4-ba52-ec71f51c74fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "import copy\n",
        "import random\n",
        "\n",
        "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
        "    '''\n",
        "    Жадное построение oracle summary\n",
        "    '''\n",
        "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
        "    # Делим текст на предложения\n",
        "    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "    n_sentences = len(sentences)\n",
        "    oracle_summary_sentences = set()\n",
        "    score = -1.0\n",
        "    summaries = []\n",
        "    for _ in range(min(n_sentences, 10)):\n",
        "        for i in range(n_sentences):\n",
        "            if i in oracle_summary_sentences:\n",
        "                continue\n",
        "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
        "            # Добавляем какое-то предложения к уже существующему summary\n",
        "            current_summary_sentences.add(i)\n",
        "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
        "            # Считаем метрики\n",
        "            current_score = calc_score(current_summary, gold_summary)\n",
        "            summaries.append((current_score, current_summary_sentences))\n",
        "        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n",
        "        # Иначе на этом заканчиваем\n",
        "        best_summary_score, best_summary_sentences = max(summaries)\n",
        "        if best_summary_score <= score:\n",
        "            break\n",
        "        oracle_summary_sentences = best_summary_sentences\n",
        "        score = best_summary_score\n",
        "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
        "    return oracle_summary, oracle_summary_sentences\n",
        "\n",
        "def calc_single_score(pred_summary, gold_summary, rouge):\n",
        "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10 µs, sys: 0 ns, total: 10 µs\n",
            "Wall time: 15.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T_ak-KDB8rp",
        "colab_type": "code",
        "outputId": "35420532-4c28-493f-9e77-315b8221bb6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "d940238d6c1a435399c418967658c42e",
            "6634c76402854a88af03eeed0cce5b3b",
            "efc6bf6fbc144da584c975bbe9dff3c4",
            "4651ee3d18bb422bb4eefb0af0f433ec",
            "0c456dbaf9d64d3181d28f1b69cb5f0d",
            "bbaa4791720648ed926f06d941fb8a8e",
            "20517876140743fbbcab797fb26d53a4",
            "d0d4886e93074f90a200584ad19e3ac9"
          ]
        }
      },
      "source": [
        "%%time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "def calc_oracle_score(records, nrows=1000, lower=True):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    rouge = Rouge()\n",
        "  \n",
        "    for text, summary in tqdm(records[['text', 'summary']].values[:nrows]):\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "        predicted_summary, _ = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_oracle_score(test_records)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d940238d6c1a435399c418967658c42e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Count: 1000\n",
            "Ref: в россии упростили механизм взыскания долгов с дачников. если раньше садоводческие товарищества возвращали их годами и через суд, то теперь это можно сделать всего за месяц и гораздо проще.\n",
            "Hyp: в россии вступили в силу изменения в гражданский процессуальный кодекс, которые упрощают процедуру взыскания долгов дачников перед их садоводческими товариществами, пишет « российская газета ». раньше садоводческие товарищества должны были обращаться с иском в суд. однако некоторые не платят годами и накопили долг в 50 и более тысяч рублей.\n",
            "BLEU:  0.532084710070161\n",
            "ROUGE:  {'rouge-1': {'f': 0.36574656214034473, 'p': 0.4029093480237559, 'r': 0.3614917044410697}, 'rouge-2': {'f': 0.20503529670892753, 'p': 0.2319005332294102, 'r': 0.20086025531982027}, 'rouge-l': {'f': 0.3183738666138893, 'p': 0.37329373278291683, 'r': 0.3339666881497283}}\n",
            "CPU times: user 3min 19s, sys: 798 ms, total: 3min 20s\n",
            "Wall time: 3min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgjewfWrbJZ",
        "colab_type": "text"
      },
      "source": [
        "## (!)\n",
        "Если надо, поменяйте код загрузки токенизатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIRKm4TCHzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import youtokentome as yttm\n",
        "\n",
        "def train_bpe(records, model_path, model_type=\"bpe\", vocab_size=10000, lower=True):\n",
        "    temp_file_name = \"temp.txt\"\n",
        "    with open(temp_file_name, \"w\") as temp:\n",
        "        for text, summary in records[['text', 'summary']].values:\n",
        "            if lower:\n",
        "                summary = summary.lower()\n",
        "                text = text.lower()\n",
        "            if not text or not summary:\n",
        "                continue\n",
        "            temp.write(text + \"\\n\")\n",
        "            temp.write(summary + \"\\n\")\n",
        "    yttm.BPE.train(data=temp_file_name, vocab_size=vocab_size, model=model_path)\n",
        "\n",
        "train_bpe(train_records, \"BPE_model.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAkZ2f5LhWwE",
        "colab_type": "code",
        "outputId": "a300a5c7-ae39-4a68-cae0-d448f4ad70b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import youtokentome as yttm\n",
        "\n",
        "bpe_processor = yttm.BPE('BPE_model.bin')\n",
        "bpe_processor.encode([\"октябрь богат на изменения\"], output_type=yttm.OutputType.SUBWORD)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['▁окт', 'ябрь', '▁бога', 'т', '▁на', '▁изменения']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOkUL_YIGp-S",
        "colab_type": "text"
      },
      "source": [
        "## (!)\n",
        "Если надо, поменяйте код словаря"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhQYN1beiVEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "import os\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, bpe_processor):\n",
        "        self.index2word = bpe_processor.vocab()\n",
        "        self.word2index = {w: i for i, w in enumerate(self.index2word)}\n",
        "        self.word2count = Counter()\n",
        "\n",
        "    def get_pad(self):\n",
        "        return self.word2index[\"<PAD>\"]\n",
        "\n",
        "    def get_sos(self):\n",
        "        return self.word2index[\"<SOS>\"]\n",
        "\n",
        "    def get_eos(self):\n",
        "        return self.word2index[\"<EOS>\"]\n",
        "\n",
        "    def get_unk(self):\n",
        "        return self.word2index[\"<UNK>\"]\n",
        "    \n",
        "    def has_word(self, word) -> bool:\n",
        "        return word in self.word2index\n",
        "\n",
        "    def get_index(self, word):\n",
        "        if word in self.word2index:\n",
        "            return self.word2index[word]\n",
        "        return self.get_unk()\n",
        "\n",
        "    def get_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def is_empty(self):\n",
        "        empty_size = 4\n",
        "        return self.size() <= empty_size\n",
        "\n",
        "    def reset(self):\n",
        "        self.word2count = Counter()\n",
        "        self.index2word = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
        "        self.word2index = {word: index for index, word in enumerate(self.index2word)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qvZtNcOifAn",
        "colab_type": "code",
        "outputId": "c9d94dc8-a84c-49d2-eeaf-e66d8531f406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocabulary = Vocabulary(bpe_processor)\n",
        "vocabulary.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdb-39jO-72q",
        "colab_type": "code",
        "outputId": "21f70294-59e9-4d0e-edab-51a32cc90b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "868089a267d54418bd57d004e9159d7d",
            "5a9572bf225d4c12ba835092cd6b7592",
            "a13c0f7f383b4008bf6c9b457056bef2",
            "c3eada2b07e848ff9c001d73c1ed25f2",
            "7e04575adbdb47eeafc40ec89326dfb2",
            "f40a53a221fe428ba805f863213953a0",
            "1fd396c8ca4b404888178a18417c98e5",
            "47bd7b7482a04f59bea44f636c46dd89",
            "4e086fffbf78417b804fed65a400e360",
            "7baa209d46c94fee85a884b606d23365",
            "e5d525648f8f481a837affe4ff2bfcf4",
            "15805032471c46fb8da0f7629be81ae8",
            "cb588c18fb7e4d148cd7c050b1f21793",
            "2341ccb3466247cc9dc15c186d3ff27c",
            "339f24e2cfcf4a13992f9d09ed1bde72",
            "f2de2454ef2d439985a2e6c76ce2cf1f",
            "ab526f45e9174ba09cc73e8ea60e1246",
            "ec8c67c6cb3d4985bb72b6ff2c85818f",
            "253590e7be9a46fb8d3899f7ce50a36e",
            "8d2ed9d7e16347f19dec492c616d7256",
            "76a189e3f11d4ba688046cd69dd75c05",
            "1739c0a242c849f3a2500128b53e2f88",
            "fb7899c3c24741089e3d823045a74f1f",
            "fd8bc76b17d44724bc0320ee6b3af760"
          ]
        }
      },
      "source": [
        "%%time\n",
        "from rouge import Rouge\n",
        "import razdel\n",
        "\n",
        "def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n",
        "    rouge = Rouge()\n",
        "    sentences_ = []\n",
        "    oracle_sentences_ = []\n",
        "    oracle_summary_ = []\n",
        "    records = records.iloc[:nrows].copy()\n",
        "\n",
        "    for text, summary in tqdm(records[['text', 'summary']].values):\n",
        "        summary = summary.lower() if lower else summary\n",
        "        sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "        oracle_summary, sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge),\n",
        "                                                                         lower=lower, max_sentences=max_sentences)\n",
        "        sentences_ += [sentences]\n",
        "        oracle_sentences_ += [list(sentences_indicies)]\n",
        "        oracle_summary_ += [oracle_summary]\n",
        "    records['sentences'] = sentences_\n",
        "    records['oracle_sentences'] = oracle_sentences_\n",
        "    records['oracle_summary'] = oracle_summary_\n",
        "    return records\n",
        "\n",
        "ext_train_records = add_oracle_summary_to_records(train_records, nrows=12288) ### \n",
        "ext_val_records = add_oracle_summary_to_records(val_records, nrows=768)###\n",
        "ext_test_records = add_oracle_summary_to_records(test_records, nrows=768)###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "868089a267d54418bd57d004e9159d7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=12288.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e086fffbf78417b804fed65a400e360",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=768.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab526f45e9174ba09cc73e8ea60e1246",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=768.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 37min 20s, sys: 7.8 s, total: 37min 27s\n",
            "Wall time: 37min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXXc8qUHC5m",
        "colab_type": "text"
      },
      "source": [
        "## (!)\n",
        "Если надо, поменяйте код генератора датасета и батчевалки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IupBaV36MuNF",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import math\n",
        "import razdel\n",
        "import torch\n",
        "import numpy as np\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "class ExtDataset(data.Dataset):\n",
        "    def __init__(self, records, vocabulary, bpe_processor, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
        "        self.records = records\n",
        "        self.num_samples = records.shape[0]\n",
        "        self.bpe_processor = bpe_processor\n",
        "        self.lower = lower\n",
        "        self.rouge = Rouge()\n",
        "        self.vocabulary = vocabulary\n",
        "        self.max_sentences = max_sentences\n",
        "        self.max_sentence_length = max_sentence_length\n",
        "        self.device = device\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.records.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        cur_record = self.records.iloc[idx]\n",
        "        inputs = list(map(lambda x: x[:self.max_sentence_length], self.bpe_processor.encode(cur_record['sentences'], output_type=yttm.OutputType.ID)))\n",
        "        outputs = [int(i in cur_record['oracle_sentences']) for i in range(len(cur_record['sentences']))]\n",
        "        return {'inputs': inputs, 'outputs': outputs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JegA9fOMsZN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = ExtDataset(ext_train_records, vocabulary, bpe_processor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YxUt1F5vVw5",
        "colab_type": "code",
        "outputId": "a610f8f8-ff24-4819-df71-6ddf91bf1055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(train_dataset[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'inputs': [[4175, 7116, 4203, 2905, 281, 1318, 1429, 338, 1227, 6553, 1567, 6262, 3064, 4445, 856, 2952, 1276, 340, 4940, 1172, 1058, 5388, 3668, 5640, 275, 4111, 558, 7566, 9289, 297, 5370, 309, 1380, 1292, 276, 452, 39, 6008, 2835, 28, 288, 390, 286, 5910, 714, 286, 3288, 4207, 784, 1517], [9287, 883, 344, 387, 368, 919, 1378, 5414, 4741, 3714, 286, 999, 1736], [705, 318, 4305, 495, 1455, 6593, 9772, 29], [1712, 459, 3688, 338, 2084, 1900, 4024, 1156, 399, 344, 1201, 1619, 2580, 3655, 300, 287, 2095, 486, 976, 696], [484, 4846, 714, 2598, 317, 7477, 702, 276, 1844, 540, 6874, 286, 5910, 3288, 2707, 368, 555, 4727, 495, 8077, 425, 3586, 25, 3830, 380, 971, 1975], [484, 562, 4846, 7592, 3489, 2985, 540, 481, 316, 6997, 286, 1698, 308, 353, 4332, 2346, 918, 2643, 2487, 2324, 8385, 29], [5825, 276, 3760, 918, 2143, 2933, 25, 5225, 4525, 2819, 315, 1134, 2610, 9, 519, 399, 7388, 283, 355, 5457, 286, 1547, 304, 359, 493, 36, 7422, 326, 1410, 9420, 4950, 276, 2432, 4812, 7917, 7590, 313, 3346, 2262, 1535, 2745, 942, 3335, 7622, 13, 7611, 1753, 595, 8542, 29], [4627, 1353, 2431, 2488, 338, 7477, 702, 8209, 1159, 2326, 285, 8830, 298, 2319, 286, 318, 7220, 435, 556, 4199, 441, 2643, 6923], [287, 1194, 3945, 8209, 5503, 2432, 6944, 423, 359, 3142, 7671, 2656, 2050, 36, 286, 274, 519, 12, 3348, 9, 399, 319, 562, 359, 3142, 7671, 6411, 533, 278, 36, 286, 293, 18, 15, 5078, 940, 4572, 36, 3123, 2078, 430, 580, 290, 7378, 2115, 8888, 423, 2235, 971, 1377], [6188, 5225, 4950, 314, 760, 4216, 8712, 286, 1044, 556, 276, 6970, 2151, 5362, 1305], [9660, 3136, 25, 1634, 2201, 2431, 534, 338, 2432, 6944, 765, 276, 1939, 7239, 276, 1844, 514, 6874, 767, 4209, 276, 6747, 4894, 275, 2189, 306, 441, 2643, 5850], [484, 3841, 338, 2235, 6944, 732, 2925, 1457, 4209, 4789, 5658, 1070, 1305], [286, 6944, 423, 3586, 2408, 289, 6529, 2847, 767, 4209, 377, 3889, 6959], [2124, 1952, 3428, 5362, 687, 8209, 1159, 297, 22, 6302, 1412, 3506, 1778, 4856, 6559, 29], [1196, 5664, 765, 767, 4209, 276, 4894, 275, 349, 449, 325, 286, 2189, 295, 831, 472, 377, 767, 4209, 8858, 6944, 423, 3586, 2408, 289, 8696, 779, 377, 454, 297, 3922, 924, 1412, 733, 7, 713, 1753, 543, 794, 2285, 399, 344, 7188, 1016, 1975], [485, 7239, 1016, 1159, 5089, 2396, 6616, 313, 2297, 284, 9493, 275, 9, 362, 6883, 992, 540, 3752, 276, 7226], [983, 3451, 2235, 5003, 7092, 25, 6388, 398, 1328, 1260, 486, 9546, 5217, 1204, 5503, 2075, 4185, 372, 3253, 4121, 699, 5263, 451, 4111, 1159, 276, 7812, 286, 276, 7919, 30, 276, 4894, 275, 2133, 23, 3430, 1906, 286, 9037, 1159, 399, 344, 2161, 276, 4074, 738, 3536, 29], [2396, 5828, 1162, 9209, 896, 766, 338, 313, 2297, 1637, 2587, 3899, 6999, 1084, 4804, 36, 286, 276, 762, 552, 6331, 495, 3633, 4865], [7798, 420, 1023, 569, 6908, 562, 1637, 9248, 9435, 8184, 372, 3253, 301, 1139, 388, 594, 4351, 7, 1059, 275, 5239, 1179, 2378, 1026, 959, 433], [3064, 562, 4466, 285, 4630, 496, 284, 4898, 2112, 29], [1434, 16, 318, 7957, 552, 7129, 430, 918, 3621, 9543, 2719, 338, 2533, 594, 6582, 465, 6785, 344, 1115, 3064, 276, 1005, 297, 1880, 350, 2781, 309, 276, 7551, 811, 6605, 6061], [484, 3890, 338, 7555, 2169, 2204, 340, 7129, 1126, 3771, 358, 318, 276, 2381, 12, 648, 399, 286, 6474, 1902, 275, 1745, 2062, 4240, 7094, 6088, 1306, 6582, 465, 1510, 4338, 29], [6188, 772, 18, 16, 340, 7059, 5640, 275, 9289, 297, 5370, 309, 1380, 1292, 276, 8112, 336, 1094, 855, 2781, 1980], [2159, 5221, 338, 485, 8578, 276, 7551, 811, 6605, 347, 1698, 308, 353, 2289, 3881, 5793, 5447, 559, 3547, 714, 9041, 1369, 41, 60, 46, 1369, 5756, 45, 4308, 1180, 3893, 5854, 503, 295, 2741, 287, 509, 276, 3740, 1535, 3015], [287, 1615, 5056, 302, 1369, 63, 1262, 912, 2988, 1684, 25, 3881, 9088, 496, 332, 3346, 7681, 5314, 3769, 500, 7678, 465, 297, 3725, 332, 696], [689, 287, 2194, 1677, 308, 431, 616, 11, 1291, 9707], [4238, 13, 287, 509, 25, 3881, 7306, 297, 319, 39, 758, 582, 633, 401, 2401, 29], [276, 649, 555, 3740, 3893, 5434, 393, 3155, 2798, 9743, 308, 3575, 6776, 2741, 4532, 10, 8966, 714, 3087, 95, 6063, 46, 1380, 63, 7512, 1503, 2324, 46, 76, 78, 29], [350, 509, 647, 717, 3046, 3346, 22, 5880, 286, 5312, 1053, 25, 484, 562, 3893, 8290, 4784, 2113, 5314, 445, 462, 292, 1118, 276, 7966, 1420], [2634, 3881, 4750, 39, 311, 587, 1211, 380, 5434, 314, 8966, 714, 9041, 3087, 66, 2079, 51, 50, 81, 8529, 5854, 503, 295, 2741, 287, 509, 5796, 299, 1691, 3346, 2262, 9420, 4950, 5825, 276, 3008, 25, 3304, 2933, 29]], 'outputs': [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvARjudojEDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Это батчевалка\n",
        "def collate_fn(records):\n",
        "    max_length = max(len(sentence) for record in records for sentence in record['inputs'])\n",
        "    max_sentences = max(len(record['outputs']) for record in records)\n",
        "\n",
        "    new_inputs = torch.zeros((len(records), max_sentences, max_length))\n",
        "    new_outputs = torch.zeros((len(records), max_sentences))\n",
        "    for i, record in enumerate(records):\n",
        "        for j, sentence in enumerate(record['inputs']):\n",
        "            new_inputs[i, j, :len(sentence)] += np.array(sentence)\n",
        "        new_outputs[i, :len(record['outputs'])] += np.array(record['outputs'])\n",
        "    return {'features': new_inputs.type(torch.LongTensor), 'targets': new_outputs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvbB10e4EGrq",
        "colab_type": "code",
        "outputId": "79703a80-f81d-4e5e-d1e2-af3ff9c7f2f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "6c3136d950844ef59e2b2fe08073ead3",
            "81f6351d900a42d29dc0dbd360436d5f",
            "cbae51c469ac42a5802c5f8c088eb0a9",
            "16bff7e1e17d458a8e6005893e2f5226",
            "f90643df67ad46ab9ed13c54953689f9",
            "d9f89d4314314209a6ae28d23899973a",
            "55e5f4581c294291bac0feaeba9390a9",
            "5a5f5237b3864ac9b9897a326a4f7bf8",
            "f3d947bc75ac4afdb52c239fd2430863",
            "f28e6e2d1c4345968e1e120f0b405158",
            "d149456f285841a7b97dc6151b4e43f5",
            "cb8e5ddaaf98402b8670f27e7a65ac10",
            "d74970ed6e064408acb7d3e77fd2cad1",
            "7be28691d69f40c7a42e15576c7cc888",
            "e5293ce9bef246a6bef4c55003d7bee0",
            "dccc0c2d731542718db10882aa82200b",
            "a521246c182748be8d919c6393448010",
            "3aab990b6bc14addba22d31e8a96cb96",
            "ef2db283c00347b18a0d144f4b5bc13d",
            "fe7414f2dc1e44c9a5d8515b88285bf7",
            "cb9ef205b1574b64a193369da6444978",
            "df88c053c3df4dda939286d71695f80e",
            "62260b343e794232836b8d98761e591a",
            "7a54a395ddc24cf6a9956f47d21d38f5",
            "142ba7e0846d4ea1b166ff2360065673",
            "48dfcf8d69e44c189e263e7551df7e2e",
            "f3887f69c06a475a83dbb8c46b0d12a1",
            "11bc5477911d48fe96b3749edff7c86f",
            "ee052781872c4ca7ab2268ff27119e4a",
            "be8381255ef04c95be4ec7dea88eec52",
            "935aaeb9b3c84ad89645093cbfaa2ea0",
            "7c6e062b3b2247b285a15a0ff5d1df72"
          ]
        }
      },
      "source": [
        "import transformers\n",
        "model_name = 'DeepPavlov/rubert-base-cased'\n",
        "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c3136d950844ef59e2b2fe08073ead3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3d947bc75ac4afdb52c239fd2430863",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1649718.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a521246c182748be8d919c6393448010",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "142ba7e0846d4ea1b166ff2360065673",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0V-A8OlO_eJ",
        "colab_type": "code",
        "outputId": "686aa98f-12cb-483f-9e9a-eaab83cc144e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "!pip install sentence-transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/46/b7d6c37d92d1bd65319220beabe4df845434930e3f30e42d3cfaecb74dc4/sentence-transformers-0.2.6.1.tar.gz (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 1.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (2.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.8.0->sentence-transformers) (1.12.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.1-cp36-none-any.whl size=74031 sha256=d26b3df89b79617f30ccb2e72e6cf57eb70640463c9a1ce5493745be22e143dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/fa/17/2b081a8cd8b0a86753fb0e9826b3cc19f0207062c0b2da7008\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-0.2.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0TRGdDmftSy",
        "colab_type": "code",
        "outputId": "d89b1dca-9ecc-4e8a-d317-0d673bac4b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "df1eaed187b14437b29e2e4a2671b7fd",
            "c1b852c8c40849e6938cddbcadd76ae2",
            "a7f285e92da846d59cbd098fc4bb1c42",
            "78298d57211e47ba84b169a0486e5ccd",
            "8727f3c9505f4be79d3c0cbbf58032e5",
            "3a9eb6b76c5a400ba490360036e85fdb",
            "0598fd987d1640378e86e5b4adf14b17",
            "a0b8d577b6a24ea7b8825ba5af66b0ba"
          ]
        }
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, models\n",
        "\n",
        "embedding_model_word = models.Transformer('DeepPavlov/rubert-base-cased')\n",
        "\n",
        "pooling_model = models.Pooling(embedding_model_word.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "transformers_model_sentence = SentenceTransformer(modules=[embedding_model_word, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df1eaed187b14437b29e2e4a2671b7fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711456796.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZCyuvwjHfyP",
        "colab_type": "code",
        "outputId": "cc6151b3-63d2-451f-ff4d-36169aa9aec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "\n",
        "\n",
        "class SentenceEncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super(SentenceEncoderRNN, self).__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
        "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        embedded = self.embedding_layer(inputs)\n",
        "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
        "        sentences_embeddings = torch.mean(outputs, 1)\n",
        "        return sentences_embeddings\n",
        "\n",
        "\n",
        "class YourSentenceEncoder(nn.Module):\n",
        "    # Место для вашего Sentence Encoder-а. Разрешается использовать любые методы, которые вам нравятся.\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super(YourSentenceEncoder, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "      sentences = []\n",
        "      for i in inputs:\n",
        "          sentences.append(bert_tokenizer.decode(i, skip_special_tokens=True))\n",
        "      \n",
        "      return torch.tensor(transformers_model_sentence.encode(sentences)).to(device)\n",
        "\n",
        "\n",
        "class SentenceTaggerRNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 sentence_encoder=SentenceEncoderRNN,\n",
        "                 token_embedding_dim=256,\n",
        "                 sentence_encoder_hidden_size=256,\n",
        "                 hidden_size=256,\n",
        "                 bidirectional=True,\n",
        "                 sentence_encoder_n_layers=2,\n",
        "                 sentence_encoder_dropout=0.3,\n",
        "                 sentence_encoder_bidirectional=True,\n",
        "                 n_layers=1,\n",
        "                 dropout=0.3):\n",
        "        super(SentenceTaggerRNN, self).__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.sentence_encoder = sentence_encoder(vocabulary_size, token_embedding_dim,\n",
        "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
        "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional) ####\n",
        "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
        "                           bidirectional=bidirectional, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
        "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.tanh_layer = nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        # print('INPUTS=', inputs)\n",
        "        batch_size = inputs.size(0)\n",
        "        sentences_count = inputs.size(1)\n",
        "        tokens_count = inputs.size(2)\n",
        "        inputs = inputs.reshape(-1, tokens_count)\n",
        "        embedded_sentences = self.sentence_encoder(inputs)\n",
        "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
        "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
        "        outputs = self.dropout_layer(outputs)\n",
        "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
        "        content = self.content_linear_layer(outputs).squeeze(2)\n",
        "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
        "        return content + salience\n",
        "\n",
        "model = SentenceTaggerRNN(vocabulary.size(), sentence_encoder=YourSentenceEncoder, token_embedding_dim=768, sentence_encoder_hidden_size=768)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning:\n",
            "\n",
            "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q2Gb6ODHHB_",
        "colab_type": "text"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVDW8raJeQxn",
        "colab_type": "code",
        "outputId": "b70beed8-7aa4-4d65-ced2-c05d18630212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "import catalyst\n",
        "from catalyst.dl.runner import SupervisedRunner\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "loaders = {\n",
        "    'train': data.DataLoader(ExtDataset(ext_train_records, vocabulary, bpe_processor=bpe_processor), batch_size=128, collate_fn=collate_fn),\n",
        "    'valid': data.DataLoader(ExtDataset(ext_val_records, vocabulary, bpe_processor=bpe_processor), batch_size=128, collate_fn=collate_fn),\n",
        "    'test': data.DataLoader(ExtDataset(ext_test_records, vocabulary, bpe_processor=bpe_processor), batch_size=128, collate_fn=collate_fn),\n",
        "}\n",
        "\n",
        "lr = 1e-3\n",
        "num_epochs = 10\n",
        "\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "runner = SupervisedRunner()\n",
        "runner.train(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    loaders=loaders,\n",
        "    logdir='./logs',\n",
        "    num_epochs=num_epochs,\n",
        "    criterion=criterion,\n",
        "    verbose=True,\n",
        "    load_best_on_end=True \n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "1/10 * Epoch (train):   0% 0/96 [00:40<?, ?it/s, loss=0.606]\u001b[A\n",
            "1/10 * Epoch (train):   1% 1/96 [00:40<1:03:54, 40.36s/it, loss=0.606]\u001b[A\n",
            "1/10 * Epoch (train):   1% 1/96 [01:20<1:03:54, 40.36s/it, loss=0.369]\u001b[A\n",
            "1/10 * Epoch (train):   2% 2/96 [01:20<1:03:13, 40.36s/it, loss=0.369]\u001b[A\n",
            "1/10 * Epoch (train):   2% 2/96 [02:00<1:03:13, 40.36s/it, loss=0.315]\u001b[A\n",
            "1/10 * Epoch (train):   3% 3/96 [02:00<1:02:16, 40.18s/it, loss=0.315]\u001b[A\n",
            "1/10 * Epoch (train):   3% 3/96 [02:40<1:02:16, 40.18s/it, loss=0.318]\u001b[A\n",
            "1/10 * Epoch (train):   4% 4/96 [02:40<1:01:24, 40.05s/it, loss=0.318]\u001b[A\n",
            "1/10 * Epoch (train):   4% 4/96 [03:20<1:01:24, 40.05s/it, loss=0.260]\u001b[A\n",
            "1/10 * Epoch (train):   5% 5/96 [03:20<1:00:46, 40.07s/it, loss=0.260]\u001b[A\n",
            "1/10 * Epoch (train):   5% 5/96 [04:00<1:00:46, 40.07s/it, loss=0.274]\u001b[A\n",
            "1/10 * Epoch (train):   6% 6/96 [04:00<1:00:04, 40.05s/it, loss=0.274]\u001b[A\n",
            "1/10 * Epoch (train):   6% 6/96 [04:40<1:00:04, 40.05s/it, loss=0.290]\u001b[A\n",
            "1/10 * Epoch (train):   7% 7/96 [04:40<59:30, 40.12s/it, loss=0.290]  \u001b[A\n",
            "1/10 * Epoch (train):   7% 7/96 [05:20<59:30, 40.12s/it, loss=0.245]\u001b[A\n",
            "1/10 * Epoch (train):   8% 8/96 [05:20<58:36, 39.96s/it, loss=0.245]\u001b[A\n",
            "1/10 * Epoch (train):   8% 8/96 [06:00<58:36, 39.96s/it, loss=0.256]\u001b[A\n",
            "1/10 * Epoch (train):   9% 9/96 [06:00<58:00, 40.01s/it, loss=0.256]\u001b[A\n",
            "1/10 * Epoch (train):   9% 9/96 [06:40<58:00, 40.01s/it, loss=0.262]\u001b[A\n",
            "1/10 * Epoch (train):  10% 10/96 [06:40<57:19, 39.99s/it, loss=0.262]\u001b[A\n",
            "1/10 * Epoch (train):  10% 10/96 [07:21<57:19, 39.99s/it, loss=0.248]\u001b[A\n",
            "1/10 * Epoch (train):  11% 11/96 [07:21<56:58, 40.22s/it, loss=0.248]\u001b[A\n",
            "1/10 * Epoch (train):  11% 11/96 [08:01<56:58, 40.22s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  12% 12/96 [08:01<56:16, 40.20s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  12% 12/96 [08:41<56:16, 40.20s/it, loss=0.270]\u001b[A\n",
            "1/10 * Epoch (train):  14% 13/96 [08:41<55:34, 40.18s/it, loss=0.270]\u001b[A\n",
            "1/10 * Epoch (train):  14% 13/96 [09:21<55:34, 40.18s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  15% 14/96 [09:21<54:50, 40.13s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  15% 14/96 [10:01<54:50, 40.13s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  16% 15/96 [10:01<54:10, 40.13s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  16% 15/96 [10:41<54:10, 40.13s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  17% 16/96 [10:41<53:22, 40.03s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  17% 16/96 [11:21<53:22, 40.03s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  18% 17/96 [11:21<52:43, 40.05s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  18% 17/96 [12:01<52:43, 40.05s/it, loss=0.246]\u001b[A\n",
            "1/10 * Epoch (train):  19% 18/96 [12:01<52:15, 40.20s/it, loss=0.246]\u001b[A\n",
            "1/10 * Epoch (train):  19% 18/96 [12:41<52:15, 40.20s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  20% 19/96 [12:41<51:29, 40.13s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  20% 19/96 [13:21<51:29, 40.13s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  21% 20/96 [13:21<50:47, 40.10s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  21% 20/96 [14:02<50:47, 40.10s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  22% 21/96 [14:02<50:08, 40.11s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  22% 21/96 [14:42<50:08, 40.11s/it, loss=0.229]\u001b[A\n",
            "1/10 * Epoch (train):  23% 22/96 [14:42<49:38, 40.25s/it, loss=0.229]\u001b[A\n",
            "1/10 * Epoch (train):  23% 22/96 [15:22<49:38, 40.25s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  24% 23/96 [15:22<48:53, 40.19s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  24% 23/96 [16:03<48:53, 40.19s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  25% 24/96 [16:03<48:18, 40.25s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  25% 24/96 [16:43<48:18, 40.25s/it, loss=0.248]\u001b[A\n",
            "1/10 * Epoch (train):  26% 25/96 [16:43<47:33, 40.18s/it, loss=0.248]\u001b[A\n",
            "1/10 * Epoch (train):  26% 25/96 [17:23<47:33, 40.18s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  27% 26/96 [17:23<47:01, 40.31s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  27% 26/96 [18:03<47:01, 40.31s/it, loss=0.224]\u001b[A\n",
            "1/10 * Epoch (train):  28% 27/96 [18:03<46:07, 40.11s/it, loss=0.224]\u001b[A\n",
            "1/10 * Epoch (train):  28% 27/96 [18:43<46:07, 40.11s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  29% 28/96 [18:43<45:25, 40.09s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  29% 28/96 [19:23<45:25, 40.09s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  30% 29/96 [19:23<44:43, 40.06s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  30% 29/96 [20:03<44:43, 40.06s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  31% 30/96 [20:03<43:56, 39.95s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  31% 30/96 [20:43<43:56, 39.95s/it, loss=0.243]\u001b[A\n",
            "1/10 * Epoch (train):  32% 31/96 [20:43<43:18, 39.98s/it, loss=0.243]\u001b[A\n",
            "1/10 * Epoch (train):  32% 31/96 [21:22<43:18, 39.98s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  33% 32/96 [21:22<42:21, 39.72s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  33% 32/96 [22:02<42:21, 39.72s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (train):  34% 33/96 [22:02<41:49, 39.83s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (train):  34% 33/96 [22:42<41:49, 39.83s/it, loss=0.255]\u001b[A\n",
            "1/10 * Epoch (train):  35% 34/96 [22:42<41:11, 39.87s/it, loss=0.255]\u001b[A\n",
            "1/10 * Epoch (train):  35% 34/96 [23:22<41:11, 39.87s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  36% 35/96 [23:22<40:44, 40.07s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  36% 35/96 [24:03<40:44, 40.07s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  38% 36/96 [24:03<40:08, 40.14s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  38% 36/96 [24:41<40:08, 40.14s/it, loss=0.233]\u001b[A\n",
            "1/10 * Epoch (train):  39% 37/96 [24:41<39:05, 39.76s/it, loss=0.233]\u001b[A\n",
            "1/10 * Epoch (train):  39% 37/96 [25:21<39:05, 39.76s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  40% 38/96 [25:21<38:28, 39.81s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  40% 38/96 [26:01<38:28, 39.81s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  41% 39/96 [26:01<37:51, 39.86s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  41% 39/96 [26:41<37:51, 39.86s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  42% 40/96 [26:41<37:11, 39.85s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  42% 40/96 [27:21<37:11, 39.85s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  43% 41/96 [27:21<36:23, 39.70s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  43% 41/96 [28:01<36:23, 39.70s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  44% 42/96 [28:01<36:03, 40.07s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  44% 42/96 [28:42<36:03, 40.07s/it, loss=0.257]\u001b[A\n",
            "1/10 * Epoch (train):  45% 43/96 [28:42<35:24, 40.09s/it, loss=0.257]\u001b[A\n",
            "1/10 * Epoch (train):  45% 43/96 [29:22<35:24, 40.09s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  46% 44/96 [29:22<34:47, 40.14s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  46% 44/96 [30:02<34:47, 40.14s/it, loss=0.214]\u001b[A\n",
            "1/10 * Epoch (train):  47% 45/96 [30:02<34:06, 40.13s/it, loss=0.214]\u001b[A\n",
            "1/10 * Epoch (train):  47% 45/96 [30:42<34:06, 40.13s/it, loss=0.245]\u001b[A\n",
            "1/10 * Epoch (train):  48% 46/96 [30:42<33:24, 40.10s/it, loss=0.245]\u001b[A\n",
            "1/10 * Epoch (train):  48% 46/96 [31:22<33:24, 40.10s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  49% 47/96 [31:22<32:44, 40.09s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  49% 47/96 [32:02<32:44, 40.09s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  50% 48/96 [32:02<31:59, 40.00s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  50% 48/96 [32:42<31:59, 40.00s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  51% 49/96 [32:42<31:19, 39.98s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  51% 49/96 [33:21<31:19, 39.98s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  52% 50/96 [33:21<30:29, 39.77s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  52% 50/96 [34:01<30:29, 39.77s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  53% 51/96 [34:01<29:50, 39.78s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  53% 51/96 [34:41<29:50, 39.78s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  54% 52/96 [34:41<29:11, 39.80s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  54% 52/96 [35:20<29:11, 39.80s/it, loss=0.235]\u001b[A\n",
            "1/10 * Epoch (train):  55% 53/96 [35:20<28:21, 39.57s/it, loss=0.235]\u001b[A\n",
            "1/10 * Epoch (train):  55% 53/96 [36:00<28:21, 39.57s/it, loss=0.233]\u001b[A\n",
            "1/10 * Epoch (train):  56% 54/96 [36:00<27:44, 39.63s/it, loss=0.233]\u001b[A\n",
            "1/10 * Epoch (train):  56% 54/96 [36:40<27:44, 39.63s/it, loss=0.253]\u001b[A\n",
            "1/10 * Epoch (train):  57% 55/96 [36:40<27:15, 39.88s/it, loss=0.253]\u001b[A\n",
            "1/10 * Epoch (train):  57% 55/96 [37:20<27:15, 39.88s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  58% 56/96 [37:20<26:37, 39.94s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  58% 56/96 [38:00<26:37, 39.94s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  59% 57/96 [38:00<25:57, 39.94s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  59% 57/96 [38:40<25:57, 39.94s/it, loss=0.229]\u001b[A\n",
            "1/10 * Epoch (train):  60% 58/96 [38:40<25:19, 39.99s/it, loss=0.229]\u001b[A\n",
            "1/10 * Epoch (train):  60% 58/96 [39:20<25:19, 39.99s/it, loss=0.234]\u001b[A\n",
            "1/10 * Epoch (train):  61% 59/96 [39:20<24:36, 39.91s/it, loss=0.234]\u001b[A\n",
            "1/10 * Epoch (train):  61% 59/96 [40:00<24:36, 39.91s/it, loss=0.237]\u001b[A\n",
            "1/10 * Epoch (train):  62% 60/96 [40:00<23:57, 39.92s/it, loss=0.237]\u001b[A\n",
            "1/10 * Epoch (train):  62% 60/96 [40:40<23:57, 39.92s/it, loss=0.227]\u001b[A\n",
            "1/10 * Epoch (train):  64% 61/96 [40:40<23:18, 39.95s/it, loss=0.227]\u001b[A\n",
            "1/10 * Epoch (train):  64% 61/96 [41:20<23:18, 39.95s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  65% 62/96 [41:20<22:39, 39.98s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  65% 62/96 [41:59<22:39, 39.98s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  66% 63/96 [41:59<21:54, 39.83s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  66% 63/96 [42:39<21:54, 39.83s/it, loss=0.232]\u001b[A\n",
            "1/10 * Epoch (train):  67% 64/96 [42:39<21:12, 39.76s/it, loss=0.232]\u001b[A\n",
            "1/10 * Epoch (train):  67% 64/96 [43:19<21:12, 39.76s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  68% 65/96 [43:19<20:35, 39.87s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  68% 65/96 [43:59<20:35, 39.87s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  69% 66/96 [43:59<19:56, 39.90s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train):  69% 66/96 [44:39<19:56, 39.90s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  70% 67/96 [44:39<19:15, 39.85s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (train):  70% 67/96 [45:18<19:15, 39.85s/it, loss=0.226]\u001b[A\n",
            "1/10 * Epoch (train):  71% 68/96 [45:18<18:32, 39.72s/it, loss=0.226]\u001b[A\n",
            "1/10 * Epoch (train):  71% 68/96 [45:58<18:32, 39.72s/it, loss=0.255]\u001b[A\n",
            "1/10 * Epoch (train):  72% 69/96 [45:58<17:54, 39.81s/it, loss=0.255]\u001b[A\n",
            "1/10 * Epoch (train):  72% 69/96 [46:38<17:54, 39.81s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  73% 70/96 [46:38<17:15, 39.84s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  73% 70/96 [47:18<17:15, 39.84s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (train):  74% 71/96 [47:18<16:38, 39.95s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (train):  74% 71/96 [47:59<16:38, 39.95s/it, loss=0.226]\u001b[A\n",
            "1/10 * Epoch (train):  75% 72/96 [47:59<16:01, 40.07s/it, loss=0.226]\u001b[A\n",
            "1/10 * Epoch (train):  75% 72/96 [48:39<16:01, 40.07s/it, loss=0.245]\u001b[A\n",
            "1/10 * Epoch (train):  76% 73/96 [48:39<15:23, 40.17s/it, loss=0.245]\u001b[A\n",
            "1/10 * Epoch (train):  76% 73/96 [49:20<15:23, 40.17s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  77% 74/96 [49:20<14:46, 40.28s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  77% 74/96 [50:00<14:46, 40.28s/it, loss=0.220]\u001b[A\n",
            "1/10 * Epoch (train):  78% 75/96 [50:00<14:08, 40.42s/it, loss=0.220]\u001b[A\n",
            "1/10 * Epoch (train):  78% 75/96 [50:41<14:08, 40.42s/it, loss=0.213]\u001b[A\n",
            "1/10 * Epoch (train):  79% 76/96 [50:41<13:28, 40.40s/it, loss=0.213]\u001b[A\n",
            "1/10 * Epoch (train):  79% 76/96 [51:22<13:28, 40.40s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  80% 77/96 [51:22<12:50, 40.53s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (train):  80% 77/96 [52:02<12:50, 40.53s/it, loss=0.234]\u001b[A\n",
            "1/10 * Epoch (train):  81% 78/96 [52:02<12:10, 40.56s/it, loss=0.234]\u001b[A\n",
            "1/10 * Epoch (train):  81% 78/96 [52:43<12:10, 40.56s/it, loss=0.227]\u001b[A\n",
            "1/10 * Epoch (train):  82% 79/96 [52:43<11:29, 40.57s/it, loss=0.227]\u001b[A\n",
            "1/10 * Epoch (train):  82% 79/96 [53:23<11:29, 40.57s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  83% 80/96 [53:23<10:46, 40.38s/it, loss=0.238]\u001b[A\n",
            "1/10 * Epoch (train):  83% 80/96 [54:03<10:46, 40.38s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  84% 81/96 [54:03<10:07, 40.48s/it, loss=0.242]\u001b[A\n",
            "1/10 * Epoch (train):  84% 81/96 [54:43<10:07, 40.48s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  85% 82/96 [54:43<09:24, 40.34s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  85% 82/96 [55:24<09:24, 40.34s/it, loss=0.233]\u001b[A\n",
            "1/10 * Epoch (train):  86% 83/96 [55:24<08:46, 40.49s/it, loss=0.233]\u001b[A\n",
            "1/10 * Epoch (train):  86% 83/96 [56:05<08:46, 40.49s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  88% 84/96 [56:05<08:06, 40.57s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  88% 84/96 [56:46<08:06, 40.57s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  89% 85/96 [56:46<07:25, 40.54s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  89% 85/96 [57:26<07:25, 40.54s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  90% 86/96 [57:26<06:44, 40.44s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  90% 86/96 [58:06<06:44, 40.44s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  91% 87/96 [58:06<06:02, 40.25s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  91% 87/96 [58:46<06:02, 40.25s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  92% 88/96 [58:46<05:21, 40.23s/it, loss=0.222]\u001b[A\n",
            "1/10 * Epoch (train):  92% 88/96 [59:26<05:21, 40.23s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (train):  93% 89/96 [59:26<04:41, 40.26s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (train):  93% 89/96 [1:00:06<04:41, 40.26s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  94% 90/96 [1:00:06<04:01, 40.24s/it, loss=0.241]\u001b[A\n",
            "1/10 * Epoch (train):  94% 90/96 [1:00:46<04:01, 40.24s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  95% 91/96 [1:00:46<03:20, 40.11s/it, loss=0.225]\u001b[A\n",
            "1/10 * Epoch (train):  95% 91/96 [1:01:27<03:20, 40.11s/it, loss=0.217]\u001b[A\n",
            "1/10 * Epoch (train):  96% 92/96 [1:01:27<02:40, 40.23s/it, loss=0.217]\u001b[A\n",
            "1/10 * Epoch (train):  96% 92/96 [1:02:07<02:40, 40.23s/it, loss=0.258]\u001b[A\n",
            "1/10 * Epoch (train):  97% 93/96 [1:02:07<02:00, 40.33s/it, loss=0.258]\u001b[A\n",
            "1/10 * Epoch (train):  97% 93/96 [1:02:48<02:00, 40.33s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  98% 94/96 [1:02:48<01:20, 40.48s/it, loss=0.244]\u001b[A\n",
            "1/10 * Epoch (train):  98% 94/96 [1:03:28<01:20, 40.48s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  99% 95/96 [1:03:28<00:40, 40.44s/it, loss=0.231]\u001b[A\n",
            "1/10 * Epoch (train):  99% 95/96 [1:04:09<00:40, 40.44s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train): 100% 96/96 [1:04:09<00:00, 40.58s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (train): 100% 96/96 [1:04:09<00:00, 40.10s/it, loss=0.240]\n",
            "\n",
            "1/10 * Epoch (valid):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "1/10 * Epoch (valid):   0% 0/6 [00:40<?, ?it/s, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (valid):  17% 1/6 [00:40<03:21, 40.26s/it, loss=0.240]\u001b[A\n",
            "1/10 * Epoch (valid):  17% 1/6 [01:20<03:21, 40.26s/it, loss=0.235]\u001b[A\n",
            "1/10 * Epoch (valid):  33% 2/6 [01:20<02:41, 40.39s/it, loss=0.235]\u001b[A\n",
            "1/10 * Epoch (valid):  33% 2/6 [02:01<02:41, 40.39s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (valid):  50% 3/6 [02:01<02:01, 40.39s/it, loss=0.228]\u001b[A\n",
            "1/10 * Epoch (valid):  50% 3/6 [02:41<02:01, 40.39s/it, loss=0.235]\u001b[A\n",
            "1/10 * Epoch (valid):  67% 4/6 [02:41<01:20, 40.36s/it, loss=0.235]\u001b[A\n",
            "1/10 * Epoch (valid):  67% 4/6 [03:22<01:20, 40.36s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (valid):  83% 5/6 [03:22<00:40, 40.47s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (valid):  83% 5/6 [04:03<00:40, 40.47s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (valid): 100% 6/6 [04:03<00:00, 40.60s/it, loss=0.239]\u001b[A\n",
            "1/10 * Epoch (valid): 100% 6/6 [04:03<00:00, 40.54s/it, loss=0.239]\n",
            "\n",
            "1/10 * Epoch (test):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "1/10 * Epoch (test):   0% 0/6 [00:39<?, ?it/s, loss=0.269]\u001b[A\n",
            "1/10 * Epoch (test):  17% 1/6 [00:39<03:19, 39.90s/it, loss=0.269]\u001b[A\n",
            "1/10 * Epoch (test):  17% 1/6 [01:20<03:19, 39.90s/it, loss=0.249]\u001b[A\n",
            "1/10 * Epoch (test):  33% 2/6 [01:20<02:40, 40.01s/it, loss=0.249]\u001b[A\n",
            "1/10 * Epoch (test):  33% 2/6 [02:01<02:40, 40.01s/it, loss=0.250]\u001b[A\n",
            "1/10 * Epoch (test):  50% 3/6 [02:01<02:00, 40.26s/it, loss=0.250]\u001b[A\n",
            "1/10 * Epoch (test):  50% 3/6 [02:41<02:00, 40.26s/it, loss=0.230]\u001b[A\n",
            "1/10 * Epoch (test):  67% 4/6 [02:41<01:20, 40.32s/it, loss=0.230]\u001b[A\n",
            "1/10 * Epoch (test):  67% 4/6 [03:22<01:20, 40.32s/it, loss=0.248]\u001b[A\n",
            "1/10 * Epoch (test):  83% 5/6 [03:22<00:40, 40.40s/it, loss=0.248]\u001b[A\n",
            "1/10 * Epoch (test):  83% 5/6 [04:02<00:40, 40.40s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (test): 100% 6/6 [04:02<00:00, 40.41s/it, loss=0.236]\u001b[A\n",
            "1/10 * Epoch (test): 100% 6/6 [04:02<00:00, 40.42s/it, loss=0.236]\n",
            "[2020-05-27 09:46:51,400] \n",
            "1/10 * Epoch 1 (_base): lr=0.0010 | momentum=0.9000\n",
            "1/10 * Epoch 1 (train): loss=0.2449\n",
            "1/10 * Epoch 1 (valid): loss=0.2361\n",
            "1/10 * Epoch 1 (test): loss=0.2471\n",
            "[2020-05-27 09:46:51,400] \n",
            "1/10 * Epoch 1 (_base): lr=0.0010 | momentum=0.9000\n",
            "1/10 * Epoch 1 (train): loss=0.2449\n",
            "1/10 * Epoch 1 (valid): loss=0.2361\n",
            "1/10 * Epoch 1 (test): loss=0.2471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:metrics_logger:\n",
            "1/10 * Epoch 1 (_base): lr=0.0010 | momentum=0.9000\n",
            "1/10 * Epoch 1 (train): loss=0.2449\n",
            "1/10 * Epoch 1 (valid): loss=0.2361\n",
            "1/10 * Epoch 1 (test): loss=0.2471\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "2/10 * Epoch (train):   0% 0/96 [00:39<?, ?it/s, loss=0.230]\u001b[A\n",
            "2/10 * Epoch (train):   1% 1/96 [00:39<1:02:57, 39.77s/it, loss=0.230]\u001b[A\n",
            "2/10 * Epoch (train):   1% 1/96 [01:20<1:02:57, 39.77s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):   2% 2/96 [01:20<1:02:34, 39.94s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):   2% 2/96 [02:00<1:02:34, 39.94s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):   3% 3/96 [02:00<1:01:56, 39.96s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):   3% 3/96 [02:39<1:01:56, 39.96s/it, loss=0.229]\u001b[A\n",
            "2/10 * Epoch (train):   4% 4/96 [02:40<1:01:14, 39.94s/it, loss=0.229]\u001b[A\n",
            "2/10 * Epoch (train):   4% 4/96 [03:20<1:01:14, 39.94s/it, loss=0.235]\u001b[A\n",
            "2/10 * Epoch (train):   5% 5/96 [03:20<1:00:48, 40.09s/it, loss=0.235]\u001b[A\n",
            "2/10 * Epoch (train):   5% 5/96 [04:00<1:00:48, 40.09s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):   6% 6/96 [04:00<1:00:13, 40.15s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):   6% 6/96 [04:41<1:00:13, 40.15s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):   7% 7/96 [04:41<59:40, 40.23s/it, loss=0.241]  \u001b[A\n",
            "2/10 * Epoch (train):   7% 7/96 [05:21<59:40, 40.23s/it, loss=0.223]\u001b[A\n",
            "2/10 * Epoch (train):   8% 8/96 [05:21<58:53, 40.16s/it, loss=0.223]\u001b[A\n",
            "2/10 * Epoch (train):   8% 8/96 [06:01<58:53, 40.16s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):   9% 9/96 [06:01<58:15, 40.18s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):   9% 9/96 [06:41<58:15, 40.18s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):  10% 10/96 [06:41<57:31, 40.13s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):  10% 10/96 [07:22<57:31, 40.13s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):  11% 11/96 [07:22<57:07, 40.33s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):  11% 11/96 [08:02<57:07, 40.33s/it, loss=0.227]\u001b[A\n",
            "2/10 * Epoch (train):  12% 12/96 [08:02<56:26, 40.32s/it, loss=0.227]\u001b[A\n",
            "2/10 * Epoch (train):  12% 12/96 [08:43<56:26, 40.32s/it, loss=0.246]\u001b[A\n",
            "2/10 * Epoch (train):  14% 13/96 [08:43<55:52, 40.40s/it, loss=0.246]\u001b[A\n",
            "2/10 * Epoch (train):  14% 13/96 [09:23<55:52, 40.40s/it, loss=0.218]\u001b[A\n",
            "2/10 * Epoch (train):  15% 14/96 [09:23<55:08, 40.35s/it, loss=0.218]\u001b[A\n",
            "2/10 * Epoch (train):  15% 14/96 [10:03<55:08, 40.35s/it, loss=0.223]\u001b[A\n",
            "2/10 * Epoch (train):  16% 15/96 [10:03<54:33, 40.41s/it, loss=0.223]\u001b[A\n",
            "2/10 * Epoch (train):  16% 15/96 [10:44<54:33, 40.41s/it, loss=0.230]\u001b[A\n",
            "2/10 * Epoch (train):  17% 16/96 [10:44<53:52, 40.41s/it, loss=0.230]\u001b[A\n",
            "2/10 * Epoch (train):  17% 16/96 [11:24<53:52, 40.41s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  18% 17/96 [11:24<53:13, 40.43s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  18% 17/96 [12:05<53:13, 40.43s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  19% 18/96 [12:05<52:39, 40.50s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  19% 18/96 [12:45<52:39, 40.50s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  20% 19/96 [12:45<51:52, 40.42s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  20% 19/96 [13:25<51:52, 40.42s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  21% 20/96 [13:25<51:07, 40.36s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  21% 20/96 [14:06<51:07, 40.36s/it, loss=0.214]\u001b[A\n",
            "2/10 * Epoch (train):  22% 21/96 [14:06<50:30, 40.40s/it, loss=0.214]\u001b[A\n",
            "2/10 * Epoch (train):  22% 21/96 [14:47<50:30, 40.40s/it, loss=0.221]\u001b[A\n",
            "2/10 * Epoch (train):  23% 22/96 [14:47<49:59, 40.53s/it, loss=0.221]\u001b[A\n",
            "2/10 * Epoch (train):  23% 22/96 [15:27<49:59, 40.53s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  24% 23/96 [15:27<49:17, 40.52s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  24% 23/96 [16:08<49:17, 40.52s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  25% 24/96 [16:08<48:41, 40.58s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  25% 24/96 [16:48<48:41, 40.58s/it, loss=0.242]\u001b[A\n",
            "2/10 * Epoch (train):  26% 25/96 [16:48<47:52, 40.45s/it, loss=0.242]\u001b[A\n",
            "2/10 * Epoch (train):  26% 25/96 [17:29<47:52, 40.45s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (train):  27% 26/96 [17:29<47:14, 40.49s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (train):  27% 26/96 [18:08<47:14, 40.49s/it, loss=0.215]\u001b[A\n",
            "2/10 * Epoch (train):  28% 27/96 [18:08<46:19, 40.29s/it, loss=0.215]\u001b[A\n",
            "2/10 * Epoch (train):  28% 27/96 [18:49<46:19, 40.29s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  29% 28/96 [18:49<45:40, 40.30s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  29% 28/96 [19:29<45:40, 40.30s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  30% 29/96 [19:29<44:59, 40.28s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  30% 29/96 [20:09<44:59, 40.28s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  31% 30/96 [20:09<44:15, 40.24s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  31% 30/96 [20:50<44:15, 40.24s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  32% 31/96 [20:50<43:42, 40.35s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  32% 31/96 [21:29<43:42, 40.35s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (train):  33% 32/96 [21:29<42:49, 40.16s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (train):  33% 32/96 [22:10<42:49, 40.16s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  34% 33/96 [22:10<42:20, 40.32s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  34% 33/96 [22:50<42:20, 40.32s/it, loss=0.250]\u001b[A\n",
            "2/10 * Epoch (train):  35% 34/96 [22:50<41:37, 40.28s/it, loss=0.250]\u001b[A\n",
            "2/10 * Epoch (train):  35% 34/96 [23:32<41:37, 40.28s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (train):  36% 35/96 [23:32<41:12, 40.54s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (train):  36% 35/96 [24:12<41:12, 40.54s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (train):  38% 36/96 [24:12<40:33, 40.56s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (train):  38% 36/96 [24:52<40:33, 40.56s/it, loss=0.227]\u001b[A\n",
            "2/10 * Epoch (train):  39% 37/96 [24:52<39:33, 40.22s/it, loss=0.227]\u001b[A\n",
            "2/10 * Epoch (train):  39% 37/96 [25:32<39:33, 40.22s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  40% 38/96 [25:32<38:57, 40.31s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  40% 38/96 [26:13<38:57, 40.31s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  41% 39/96 [26:13<38:21, 40.38s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  41% 39/96 [26:53<38:21, 40.38s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  42% 40/96 [26:53<37:42, 40.40s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  42% 40/96 [27:33<37:42, 40.40s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  43% 41/96 [27:33<36:55, 40.28s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  43% 41/96 [28:14<36:55, 40.28s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (train):  44% 42/96 [28:14<36:33, 40.62s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (train):  44% 42/96 [28:55<36:33, 40.62s/it, loss=0.257]\u001b[A\n",
            "2/10 * Epoch (train):  45% 43/96 [28:55<35:49, 40.56s/it, loss=0.257]\u001b[A\n",
            "2/10 * Epoch (train):  45% 43/96 [29:36<35:49, 40.56s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  46% 44/96 [29:36<35:12, 40.62s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  46% 44/96 [30:16<35:12, 40.62s/it, loss=0.213]\u001b[A\n",
            "2/10 * Epoch (train):  47% 45/96 [30:16<34:33, 40.66s/it, loss=0.213]\u001b[A\n",
            "2/10 * Epoch (train):  47% 45/96 [30:57<34:33, 40.66s/it, loss=0.244]\u001b[A\n",
            "2/10 * Epoch (train):  48% 46/96 [30:57<33:53, 40.68s/it, loss=0.244]\u001b[A\n",
            "2/10 * Epoch (train):  48% 46/96 [31:38<33:53, 40.68s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  49% 47/96 [31:38<33:17, 40.77s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  49% 47/96 [32:18<33:17, 40.77s/it, loss=0.229]\u001b[A\n",
            "2/10 * Epoch (train):  50% 48/96 [32:18<32:27, 40.57s/it, loss=0.229]\u001b[A\n",
            "2/10 * Epoch (train):  50% 48/96 [32:59<32:27, 40.57s/it, loss=0.221]\u001b[A\n",
            "2/10 * Epoch (train):  51% 49/96 [32:59<31:47, 40.59s/it, loss=0.221]\u001b[A\n",
            "2/10 * Epoch (train):  51% 49/96 [33:39<31:47, 40.59s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  52% 50/96 [33:39<30:55, 40.33s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  52% 50/96 [34:19<30:55, 40.33s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  53% 51/96 [34:19<30:11, 40.26s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  53% 51/96 [34:59<30:11, 40.26s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  54% 52/96 [34:59<29:28, 40.20s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  54% 52/96 [35:38<29:28, 40.20s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  55% 53/96 [35:38<28:37, 39.94s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  55% 53/96 [36:18<28:37, 39.94s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  56% 54/96 [36:18<27:59, 39.98s/it, loss=0.231]\u001b[A\n",
            "2/10 * Epoch (train):  56% 54/96 [36:59<27:59, 39.98s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (train):  57% 55/96 [36:59<27:29, 40.23s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (train):  57% 55/96 [37:39<27:29, 40.23s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  58% 56/96 [37:39<26:48, 40.22s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  58% 56/96 [38:19<26:48, 40.22s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  59% 57/96 [38:19<26:06, 40.16s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  59% 57/96 [38:59<26:06, 40.16s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):  60% 58/96 [38:59<25:24, 40.11s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):  60% 58/96 [39:39<25:24, 40.11s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (train):  61% 59/96 [39:39<24:41, 40.05s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (train):  61% 59/96 [40:19<24:41, 40.05s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  62% 60/96 [40:19<24:00, 40.02s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  62% 60/96 [40:59<24:00, 40.02s/it, loss=0.227]\u001b[A\n",
            "2/10 * Epoch (train):  64% 61/96 [40:59<23:20, 40.01s/it, loss=0.227]\u001b[A\n",
            "2/10 * Epoch (train):  64% 61/96 [41:39<23:20, 40.01s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  65% 62/96 [41:39<22:40, 40.02s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  65% 62/96 [42:18<22:40, 40.02s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  66% 63/96 [42:18<21:54, 39.83s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  66% 63/96 [42:58<21:54, 39.83s/it, loss=0.230]\u001b[A\n",
            "2/10 * Epoch (train):  67% 64/96 [42:58<21:13, 39.79s/it, loss=0.230]\u001b[A\n",
            "2/10 * Epoch (train):  67% 64/96 [43:38<21:13, 39.79s/it, loss=0.222]\u001b[A\n",
            "2/10 * Epoch (train):  68% 65/96 [43:38<20:37, 39.91s/it, loss=0.222]\u001b[A\n",
            "2/10 * Epoch (train):  68% 65/96 [44:18<20:37, 39.91s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  69% 66/96 [44:18<19:56, 39.89s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (train):  69% 66/96 [44:58<19:56, 39.89s/it, loss=0.236]\u001b[A\n",
            "2/10 * Epoch (train):  70% 67/96 [44:58<19:17, 39.90s/it, loss=0.236]\u001b[A\n",
            "2/10 * Epoch (train):  70% 67/96 [45:38<19:17, 39.90s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):  71% 68/96 [45:38<18:33, 39.78s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):  71% 68/96 [46:18<18:33, 39.78s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (train):  72% 69/96 [46:18<17:57, 39.91s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (train):  72% 69/96 [46:58<17:57, 39.91s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  73% 70/96 [46:58<17:19, 39.96s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  73% 70/96 [47:38<17:19, 39.96s/it, loss=0.224]\u001b[A\n",
            "2/10 * Epoch (train):  74% 71/96 [47:38<16:37, 39.88s/it, loss=0.224]\u001b[A\n",
            "2/10 * Epoch (train):  74% 71/96 [48:17<16:37, 39.88s/it, loss=0.223]\u001b[A\n",
            "2/10 * Epoch (train):  75% 72/96 [48:17<15:56, 39.87s/it, loss=0.223]\u001b[A\n",
            "2/10 * Epoch (train):  75% 72/96 [48:57<15:56, 39.87s/it, loss=0.245]\u001b[A\n",
            "2/10 * Epoch (train):  76% 73/96 [48:57<15:16, 39.85s/it, loss=0.245]\u001b[A\n",
            "2/10 * Epoch (train):  76% 73/96 [49:37<15:16, 39.85s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):  77% 74/96 [49:37<14:38, 39.94s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (train):  77% 74/96 [50:18<14:38, 39.94s/it, loss=0.219]\u001b[A\n",
            "2/10 * Epoch (train):  78% 75/96 [50:18<14:00, 40.02s/it, loss=0.219]\u001b[A\n",
            "2/10 * Epoch (train):  78% 75/96 [50:57<14:00, 40.02s/it, loss=0.211]\u001b[A\n",
            "2/10 * Epoch (train):  79% 76/96 [50:57<13:19, 39.99s/it, loss=0.211]\u001b[A\n",
            "2/10 * Epoch (train):  79% 76/96 [51:38<13:19, 39.99s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  80% 77/96 [51:38<12:43, 40.16s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (train):  80% 77/96 [52:19<12:43, 40.16s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  81% 78/96 [52:19<12:05, 40.30s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  81% 78/96 [52:59<12:05, 40.30s/it, loss=0.224]\u001b[A\n",
            "2/10 * Epoch (train):  82% 79/96 [52:59<11:26, 40.40s/it, loss=0.224]\u001b[A\n",
            "2/10 * Epoch (train):  82% 79/96 [53:39<11:26, 40.40s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  83% 80/96 [53:39<10:44, 40.31s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  83% 80/96 [54:20<10:44, 40.31s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  84% 81/96 [54:20<10:04, 40.31s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  84% 81/96 [54:59<10:04, 40.31s/it, loss=0.225]\u001b[A\n",
            "2/10 * Epoch (train):  85% 82/96 [54:59<09:21, 40.12s/it, loss=0.225]\u001b[A\n",
            "2/10 * Epoch (train):  85% 82/96 [55:40<09:21, 40.12s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  86% 83/96 [55:40<08:43, 40.29s/it, loss=0.232]\u001b[A\n",
            "2/10 * Epoch (train):  86% 83/96 [56:20<08:43, 40.29s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  88% 84/96 [56:20<08:03, 40.32s/it, loss=0.240]\u001b[A\n",
            "2/10 * Epoch (train):  88% 84/96 [57:01<08:03, 40.32s/it, loss=0.222]\u001b[A\n",
            "2/10 * Epoch (train):  89% 85/96 [57:01<07:23, 40.34s/it, loss=0.222]\u001b[A\n",
            "2/10 * Epoch (train):  89% 85/96 [57:41<07:23, 40.34s/it, loss=0.225]\u001b[A\n",
            "2/10 * Epoch (train):  90% 86/96 [57:41<06:42, 40.24s/it, loss=0.225]\u001b[A\n",
            "2/10 * Epoch (train):  90% 86/96 [58:20<06:42, 40.24s/it, loss=0.236]\u001b[A\n",
            "2/10 * Epoch (train):  91% 87/96 [58:20<06:00, 40.02s/it, loss=0.236]\u001b[A\n",
            "2/10 * Epoch (train):  91% 87/96 [59:00<06:00, 40.02s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  92% 88/96 [59:00<05:20, 40.00s/it, loss=0.220]\u001b[A\n",
            "2/10 * Epoch (train):  92% 88/96 [59:40<05:20, 40.00s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):  93% 89/96 [59:40<04:40, 40.02s/it, loss=0.226]\u001b[A\n",
            "2/10 * Epoch (train):  93% 89/96 [1:00:20<04:40, 40.02s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  94% 90/96 [1:00:20<03:59, 39.97s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train):  94% 90/96 [1:01:00<03:59, 39.97s/it, loss=0.222]\u001b[A\n",
            "2/10 * Epoch (train):  95% 91/96 [1:01:00<03:19, 39.88s/it, loss=0.222]\u001b[A\n",
            "2/10 * Epoch (train):  95% 91/96 [1:01:40<03:19, 39.88s/it, loss=0.212]\u001b[A\n",
            "2/10 * Epoch (train):  96% 92/96 [1:01:40<02:40, 40.03s/it, loss=0.212]\u001b[A\n",
            "2/10 * Epoch (train):  96% 92/96 [1:02:20<02:40, 40.03s/it, loss=0.257]\u001b[A\n",
            "2/10 * Epoch (train):  97% 93/96 [1:02:20<02:00, 40.05s/it, loss=0.257]\u001b[A\n",
            "2/10 * Epoch (train):  97% 93/96 [1:03:01<02:00, 40.05s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  98% 94/96 [1:03:01<01:20, 40.19s/it, loss=0.241]\u001b[A\n",
            "2/10 * Epoch (train):  98% 94/96 [1:03:41<01:20, 40.19s/it, loss=0.229]\u001b[A\n",
            "2/10 * Epoch (train):  99% 95/96 [1:03:41<00:40, 40.20s/it, loss=0.229]\u001b[A\n",
            "2/10 * Epoch (train):  99% 95/96 [1:04:22<00:40, 40.20s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train): 100% 96/96 [1:04:22<00:00, 40.35s/it, loss=0.239]\u001b[A\n",
            "2/10 * Epoch (train): 100% 96/96 [1:04:22<00:00, 40.23s/it, loss=0.239]\n",
            "\n",
            "2/10 * Epoch (valid):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "2/10 * Epoch (valid):   0% 0/6 [00:39<?, ?it/s, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (valid):  17% 1/6 [00:39<03:18, 39.67s/it, loss=0.238]\u001b[A\n",
            "2/10 * Epoch (valid):  17% 1/6 [01:20<03:18, 39.67s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (valid):  33% 2/6 [01:20<02:39, 39.93s/it, loss=0.233]\u001b[A\n",
            "2/10 * Epoch (valid):  33% 2/6 [02:00<02:39, 39.93s/it, loss=0.225]\u001b[A\n",
            "2/10 * Epoch (valid):  50% 3/6 [02:00<01:59, 39.90s/it, loss=0.225]\u001b[A\n",
            "2/10 * Epoch (valid):  50% 3/6 [02:40<01:59, 39.90s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (valid):  67% 4/6 [02:40<01:19, 39.98s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (valid):  67% 4/6 [03:20<01:19, 39.98s/it, loss=0.236]\u001b[A\n",
            "2/10 * Epoch (valid):  83% 5/6 [03:20<00:40, 40.15s/it, loss=0.236]\u001b[A\n",
            "2/10 * Epoch (valid):  83% 5/6 [04:01<00:40, 40.15s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (valid): 100% 6/6 [04:01<00:00, 40.32s/it, loss=0.237]\u001b[A\n",
            "2/10 * Epoch (valid): 100% 6/6 [04:01<00:00, 40.25s/it, loss=0.237]\n",
            "\n",
            "2/10 * Epoch (test):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "2/10 * Epoch (test):   0% 0/6 [00:39<?, ?it/s, loss=0.267]\u001b[A\n",
            "2/10 * Epoch (test):  17% 1/6 [00:39<03:18, 39.80s/it, loss=0.267]\u001b[A\n",
            "2/10 * Epoch (test):  17% 1/6 [01:19<03:18, 39.80s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (test):  33% 2/6 [01:19<02:39, 39.91s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (test):  33% 2/6 [02:00<02:39, 39.91s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (test):  50% 3/6 [02:00<02:00, 40.10s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (test):  50% 3/6 [02:40<02:00, 40.10s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (test):  67% 4/6 [02:40<01:20, 40.12s/it, loss=0.228]\u001b[A\n",
            "2/10 * Epoch (test):  67% 4/6 [03:20<01:20, 40.12s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (test):  83% 5/6 [03:20<00:40, 40.15s/it, loss=0.248]\u001b[A\n",
            "2/10 * Epoch (test):  83% 5/6 [04:01<00:40, 40.15s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (test): 100% 6/6 [04:01<00:00, 40.17s/it, loss=0.234]\u001b[A\n",
            "2/10 * Epoch (test): 100% 6/6 [04:01<00:00, 40.18s/it, loss=0.234]\n",
            "[2020-05-27 10:59:16,444] \n",
            "2/10 * Epoch 2 (_base): lr=0.0010 | momentum=0.9000\n",
            "2/10 * Epoch 2 (train): loss=0.2319\n",
            "2/10 * Epoch 2 (valid): loss=0.2338\n",
            "2/10 * Epoch 2 (test): loss=0.2458\n",
            "[2020-05-27 10:59:16,444] \n",
            "2/10 * Epoch 2 (_base): lr=0.0010 | momentum=0.9000\n",
            "2/10 * Epoch 2 (train): loss=0.2319\n",
            "2/10 * Epoch 2 (valid): loss=0.2338\n",
            "2/10 * Epoch 2 (test): loss=0.2458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:metrics_logger:\n",
            "2/10 * Epoch 2 (_base): lr=0.0010 | momentum=0.9000\n",
            "2/10 * Epoch 2 (train): loss=0.2319\n",
            "2/10 * Epoch 2 (valid): loss=0.2338\n",
            "2/10 * Epoch 2 (test): loss=0.2458\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "3/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "3/10 * Epoch (train):   0% 0/96 [00:39<?, ?it/s, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):   1% 1/96 [00:39<1:02:43, 39.62s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):   1% 1/96 [01:19<1:02:43, 39.62s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):   2% 2/96 [01:19<1:02:20, 39.79s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):   2% 2/96 [01:59<1:02:20, 39.79s/it, loss=0.227]\u001b[A\n",
            "3/10 * Epoch (train):   3% 3/96 [01:59<1:01:36, 39.75s/it, loss=0.227]\u001b[A\n",
            "3/10 * Epoch (train):   3% 3/96 [02:39<1:01:36, 39.75s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):   4% 4/96 [02:39<1:00:53, 39.72s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):   4% 4/96 [03:19<1:00:53, 39.72s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):   5% 5/96 [03:19<1:00:26, 39.85s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):   5% 5/96 [03:59<1:00:26, 39.85s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):   6% 6/96 [03:59<59:51, 39.91s/it, loss=0.236]  \u001b[A\n",
            "3/10 * Epoch (train):   6% 6/96 [04:39<59:51, 39.91s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):   7% 7/96 [04:39<59:14, 39.94s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):   7% 7/96 [05:19<59:14, 39.94s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):   8% 8/96 [05:19<58:31, 39.91s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):   8% 8/96 [05:59<58:31, 39.91s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):   9% 9/96 [05:59<57:50, 39.89s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):   9% 9/96 [06:38<57:50, 39.89s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):  10% 10/96 [06:38<57:07, 39.86s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):  10% 10/96 [07:19<57:07, 39.86s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  11% 11/96 [07:19<56:40, 40.00s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  11% 11/96 [07:59<56:40, 40.00s/it, loss=0.221]\u001b[A\n",
            "3/10 * Epoch (train):  12% 12/96 [07:59<55:58, 39.98s/it, loss=0.221]\u001b[A\n",
            "3/10 * Epoch (train):  12% 12/96 [08:39<55:58, 39.98s/it, loss=0.243]\u001b[A\n",
            "3/10 * Epoch (train):  14% 13/96 [08:39<55:28, 40.10s/it, loss=0.243]\u001b[A\n",
            "3/10 * Epoch (train):  14% 13/96 [09:19<55:28, 40.10s/it, loss=0.218]\u001b[A\n",
            "3/10 * Epoch (train):  15% 14/96 [09:19<54:44, 40.05s/it, loss=0.218]\u001b[A\n",
            "3/10 * Epoch (train):  15% 14/96 [09:59<54:44, 40.05s/it, loss=0.223]\u001b[A\n",
            "3/10 * Epoch (train):  16% 15/96 [09:59<54:04, 40.06s/it, loss=0.223]\u001b[A\n",
            "3/10 * Epoch (train):  16% 15/96 [10:39<54:04, 40.06s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  17% 16/96 [10:39<53:16, 39.96s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  17% 16/96 [11:19<53:16, 39.96s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  18% 17/96 [11:19<52:36, 39.96s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  18% 17/96 [11:59<52:36, 39.96s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  19% 18/96 [11:59<52:04, 40.06s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  19% 18/96 [12:38<52:04, 40.06s/it, loss=0.216]\u001b[A\n",
            "3/10 * Epoch (train):  20% 19/96 [12:38<51:12, 39.90s/it, loss=0.216]\u001b[A\n",
            "3/10 * Epoch (train):  20% 19/96 [13:18<51:12, 39.90s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  21% 20/96 [13:18<50:28, 39.85s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  21% 20/96 [13:58<50:28, 39.85s/it, loss=0.214]\u001b[A\n",
            "3/10 * Epoch (train):  22% 21/96 [13:58<49:52, 39.89s/it, loss=0.214]\u001b[A\n",
            "3/10 * Epoch (train):  22% 21/96 [14:39<49:52, 39.89s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  23% 22/96 [14:39<49:24, 40.06s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  23% 22/96 [15:19<49:24, 40.06s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):  24% 23/96 [15:19<48:39, 40.00s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):  24% 23/96 [15:59<48:39, 40.00s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (train):  25% 24/96 [15:59<48:06, 40.09s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (train):  25% 24/96 [16:38<48:06, 40.09s/it, loss=0.243]\u001b[A\n",
            "3/10 * Epoch (train):  26% 25/96 [16:38<47:16, 39.95s/it, loss=0.243]\u001b[A\n",
            "3/10 * Epoch (train):  26% 25/96 [17:19<47:16, 39.95s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  27% 26/96 [17:19<46:41, 40.02s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  27% 26/96 [17:58<46:41, 40.02s/it, loss=0.213]\u001b[A\n",
            "3/10 * Epoch (train):  28% 27/96 [17:58<45:47, 39.82s/it, loss=0.213]\u001b[A\n",
            "3/10 * Epoch (train):  28% 27/96 [18:38<45:47, 39.82s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (train):  29% 28/96 [18:38<45:06, 39.80s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (train):  29% 28/96 [19:17<45:06, 39.80s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  30% 29/96 [19:17<44:23, 39.75s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  30% 29/96 [19:57<44:23, 39.75s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  31% 30/96 [19:57<43:43, 39.75s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  31% 30/96 [20:37<43:43, 39.75s/it, loss=0.234]\u001b[A\n",
            "3/10 * Epoch (train):  32% 31/96 [20:37<43:13, 39.91s/it, loss=0.234]\u001b[A\n",
            "3/10 * Epoch (train):  32% 31/96 [21:17<43:13, 39.91s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  33% 32/96 [21:17<42:18, 39.67s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  33% 32/96 [21:57<42:18, 39.67s/it, loss=0.221]\u001b[A\n",
            "3/10 * Epoch (train):  34% 33/96 [21:57<41:50, 39.85s/it, loss=0.221]\u001b[A\n",
            "3/10 * Epoch (train):  34% 33/96 [22:37<41:50, 39.85s/it, loss=0.250]\u001b[A\n",
            "3/10 * Epoch (train):  35% 34/96 [22:37<41:08, 39.81s/it, loss=0.250]\u001b[A\n",
            "3/10 * Epoch (train):  35% 34/96 [23:17<41:08, 39.81s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (train):  36% 35/96 [23:17<40:42, 40.05s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (train):  36% 35/96 [23:57<40:42, 40.05s/it, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (train):  38% 36/96 [23:57<40:04, 40.08s/it, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (train):  38% 36/96 [24:36<40:04, 40.08s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  39% 37/96 [24:36<39:06, 39.77s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  39% 37/96 [25:17<39:06, 39.77s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  40% 38/96 [25:17<38:35, 39.92s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  40% 38/96 [25:57<38:35, 39.92s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  41% 39/96 [25:57<38:00, 40.00s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  41% 39/96 [26:37<38:00, 40.00s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):  42% 40/96 [26:37<37:23, 40.07s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):  42% 40/96 [27:17<37:23, 40.07s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  43% 41/96 [27:17<36:36, 39.93s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  43% 41/96 [27:58<36:36, 39.93s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (train):  44% 42/96 [27:58<36:15, 40.28s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (train):  44% 42/96 [28:38<36:15, 40.28s/it, loss=0.255]\u001b[A\n",
            "3/10 * Epoch (train):  45% 43/96 [28:38<35:32, 40.23s/it, loss=0.255]\u001b[A\n",
            "3/10 * Epoch (train):  45% 43/96 [29:18<35:32, 40.23s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (train):  46% 44/96 [29:18<34:54, 40.29s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (train):  46% 44/96 [29:58<34:54, 40.29s/it, loss=0.214]\u001b[A\n",
            "3/10 * Epoch (train):  47% 45/96 [29:58<34:12, 40.24s/it, loss=0.214]\u001b[A\n",
            "3/10 * Epoch (train):  47% 45/96 [30:39<34:12, 40.24s/it, loss=0.241]\u001b[A\n",
            "3/10 * Epoch (train):  48% 46/96 [30:39<33:33, 40.27s/it, loss=0.241]\u001b[A\n",
            "3/10 * Epoch (train):  48% 46/96 [31:19<33:33, 40.27s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  49% 47/96 [31:19<32:52, 40.26s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  49% 47/96 [31:59<32:52, 40.26s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  50% 48/96 [31:59<32:06, 40.13s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  50% 48/96 [32:39<32:06, 40.13s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  51% 49/96 [32:39<31:28, 40.19s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  51% 49/96 [33:19<31:28, 40.19s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  52% 50/96 [33:19<30:39, 39.99s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  52% 50/96 [33:59<30:39, 39.99s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  53% 51/96 [33:59<30:01, 40.03s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  53% 51/96 [34:39<30:01, 40.03s/it, loss=0.234]\u001b[A\n",
            "3/10 * Epoch (train):  54% 52/96 [34:39<29:23, 40.08s/it, loss=0.234]\u001b[A\n",
            "3/10 * Epoch (train):  54% 52/96 [35:18<29:23, 40.08s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  55% 53/96 [35:18<28:36, 39.93s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  55% 53/96 [35:58<28:36, 39.93s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  56% 54/96 [35:58<27:57, 39.95s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  56% 54/96 [36:39<27:57, 39.95s/it, loss=0.249]\u001b[A\n",
            "3/10 * Epoch (train):  57% 55/96 [36:39<27:27, 40.18s/it, loss=0.249]\u001b[A\n",
            "3/10 * Epoch (train):  57% 55/96 [37:19<27:27, 40.18s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  58% 56/96 [37:19<26:46, 40.16s/it, loss=0.236]\u001b[A\n",
            "3/10 * Epoch (train):  58% 56/96 [37:59<26:46, 40.16s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  59% 57/96 [37:59<26:05, 40.14s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  59% 57/96 [38:40<26:05, 40.14s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  60% 58/96 [38:40<25:27, 40.21s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  60% 58/96 [39:20<25:27, 40.21s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  61% 59/96 [39:20<24:42, 40.08s/it, loss=0.230]\u001b[A\n",
            "3/10 * Epoch (train):  61% 59/96 [40:00<24:42, 40.08s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (train):  62% 60/96 [40:00<24:02, 40.06s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (train):  62% 60/96 [40:40<24:02, 40.06s/it, loss=0.222]\u001b[A\n",
            "3/10 * Epoch (train):  64% 61/96 [40:40<23:22, 40.06s/it, loss=0.222]\u001b[A\n",
            "3/10 * Epoch (train):  64% 61/96 [41:20<23:22, 40.06s/it, loss=0.240]\u001b[A\n",
            "3/10 * Epoch (train):  65% 62/96 [41:20<22:42, 40.06s/it, loss=0.240]\u001b[A\n",
            "3/10 * Epoch (train):  65% 62/96 [41:59<22:42, 40.06s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  66% 63/96 [41:59<21:55, 39.87s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  66% 63/96 [42:39<21:55, 39.87s/it, loss=0.227]\u001b[A\n",
            "3/10 * Epoch (train):  67% 64/96 [42:39<21:14, 39.83s/it, loss=0.227]\u001b[A\n",
            "3/10 * Epoch (train):  67% 64/96 [43:19<21:14, 39.83s/it, loss=0.219]\u001b[A\n",
            "3/10 * Epoch (train):  68% 65/96 [43:19<20:37, 39.92s/it, loss=0.219]\u001b[A\n",
            "3/10 * Epoch (train):  68% 65/96 [43:59<20:37, 39.92s/it, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (train):  69% 66/96 [43:59<19:55, 39.87s/it, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (train):  69% 66/96 [44:38<19:55, 39.87s/it, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (train):  70% 67/96 [44:38<19:14, 39.83s/it, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (train):  70% 67/96 [45:18<19:14, 39.83s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  71% 68/96 [45:18<18:31, 39.70s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  71% 68/96 [45:58<18:31, 39.70s/it, loss=0.250]\u001b[A\n",
            "3/10 * Epoch (train):  72% 69/96 [45:58<17:56, 39.87s/it, loss=0.250]\u001b[A\n",
            "3/10 * Epoch (train):  72% 69/96 [46:38<17:56, 39.87s/it, loss=0.219]\u001b[A\n",
            "3/10 * Epoch (train):  73% 70/96 [46:38<17:16, 39.88s/it, loss=0.219]\u001b[A\n",
            "3/10 * Epoch (train):  73% 70/96 [47:18<17:16, 39.88s/it, loss=0.222]\u001b[A\n",
            "3/10 * Epoch (train):  74% 71/96 [47:18<16:36, 39.84s/it, loss=0.222]\u001b[A\n",
            "3/10 * Epoch (train):  74% 71/96 [47:58<16:36, 39.84s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  75% 72/96 [47:58<15:56, 39.85s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  75% 72/96 [48:38<15:56, 39.85s/it, loss=0.243]\u001b[A\n",
            "3/10 * Epoch (train):  76% 73/96 [48:38<15:16, 39.85s/it, loss=0.243]\u001b[A\n",
            "3/10 * Epoch (train):  76% 73/96 [49:18<15:16, 39.85s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  77% 74/96 [49:18<14:39, 39.99s/it, loss=0.228]\u001b[A\n",
            "3/10 * Epoch (train):  77% 74/96 [49:58<14:39, 39.99s/it, loss=0.216]\u001b[A\n",
            "3/10 * Epoch (train):  78% 75/96 [49:58<14:00, 40.05s/it, loss=0.216]\u001b[A\n",
            "3/10 * Epoch (train):  78% 75/96 [50:38<14:00, 40.05s/it, loss=0.211]\u001b[A\n",
            "3/10 * Epoch (train):  79% 76/96 [50:38<13:19, 39.98s/it, loss=0.211]\u001b[A\n",
            "3/10 * Epoch (train):  79% 76/96 [51:18<13:19, 39.98s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (train):  80% 77/96 [51:18<12:41, 40.07s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (train):  80% 77/96 [51:58<12:41, 40.07s/it, loss=0.229]\u001b[A\n",
            "3/10 * Epoch (train):  81% 78/96 [51:58<12:02, 40.15s/it, loss=0.229]\u001b[A\n",
            "3/10 * Epoch (train):  81% 78/96 [52:39<12:02, 40.15s/it, loss=0.222]\u001b[A\n",
            "3/10 * Epoch (train):  82% 79/96 [52:39<11:23, 40.18s/it, loss=0.222]\u001b[A\n",
            "3/10 * Epoch (train):  82% 79/96 [53:18<11:23, 40.18s/it, loss=0.240]\u001b[A\n",
            "3/10 * Epoch (train):  83% 80/96 [53:18<10:40, 40.04s/it, loss=0.240]\u001b[A\n",
            "3/10 * Epoch (train):  83% 80/96 [53:58<10:40, 40.04s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  84% 81/96 [53:58<10:00, 40.05s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  84% 81/96 [54:38<10:00, 40.05s/it, loss=0.223]\u001b[A\n",
            "3/10 * Epoch (train):  85% 82/96 [54:38<09:17, 39.84s/it, loss=0.223]\u001b[A\n",
            "3/10 * Epoch (train):  85% 82/96 [55:18<09:17, 39.84s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  86% 83/96 [55:18<08:39, 39.99s/it, loss=0.231]\u001b[A\n",
            "3/10 * Epoch (train):  86% 83/96 [55:58<08:39, 39.99s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):  88% 84/96 [55:58<08:00, 40.07s/it, loss=0.239]\u001b[A\n",
            "3/10 * Epoch (train):  88% 84/96 [56:39<08:00, 40.07s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  89% 85/96 [56:39<07:21, 40.09s/it, loss=0.220]\u001b[A\n",
            "3/10 * Epoch (train):  89% 85/96 [57:19<07:21, 40.09s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  90% 86/96 [57:19<06:40, 40.04s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (train):  90% 86/96 [57:58<06:40, 40.04s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (train):  91% 87/96 [57:58<05:58, 39.84s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (train):  91% 87/96 [58:38<05:58, 39.84s/it, loss=0.217]\u001b[A\n",
            "3/10 * Epoch (train):  92% 88/96 [58:38<05:18, 39.86s/it, loss=0.217]\u001b[A\n",
            "3/10 * Epoch (train):  92% 88/96 [59:18<05:18, 39.86s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):  93% 89/96 [59:18<04:39, 39.97s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):  93% 89/96 [59:58<04:39, 39.97s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  94% 90/96 [59:58<04:00, 40.01s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  94% 90/96 [1:00:38<04:00, 40.01s/it, loss=0.221]\u001b[A\n",
            "3/10 * Epoch (train):  95% 91/96 [1:00:38<03:19, 39.85s/it, loss=0.221]\u001b[A\n",
            "3/10 * Epoch (train):  95% 91/96 [1:01:18<03:19, 39.85s/it, loss=0.213]\u001b[A\n",
            "3/10 * Epoch (train):  96% 92/96 [1:01:18<02:39, 40.00s/it, loss=0.213]\u001b[A\n",
            "3/10 * Epoch (train):  96% 92/96 [1:01:58<02:39, 40.00s/it, loss=0.254]\u001b[A\n",
            "3/10 * Epoch (train):  97% 93/96 [1:01:58<01:59, 39.99s/it, loss=0.254]\u001b[A\n",
            "3/10 * Epoch (train):  97% 93/96 [1:02:39<01:59, 39.99s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  98% 94/96 [1:02:39<01:20, 40.22s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train):  98% 94/96 [1:03:19<01:20, 40.22s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):  99% 95/96 [1:03:19<00:40, 40.17s/it, loss=0.226]\u001b[A\n",
            "3/10 * Epoch (train):  99% 95/96 [1:03:59<00:40, 40.17s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train): 100% 96/96 [1:03:59<00:00, 40.27s/it, loss=0.238]\u001b[A\n",
            "3/10 * Epoch (train): 100% 96/96 [1:03:59<00:00, 40.00s/it, loss=0.238]\n",
            "\n",
            "3/10 * Epoch (valid):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "3/10 * Epoch (valid):   0% 0/6 [00:39<?, ?it/s, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (valid):  17% 1/6 [00:39<03:18, 39.67s/it, loss=0.237]\u001b[A\n",
            "3/10 * Epoch (valid):  17% 1/6 [01:20<03:18, 39.67s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (valid):  33% 2/6 [01:20<02:39, 39.88s/it, loss=0.232]\u001b[A\n",
            "3/10 * Epoch (valid):  33% 2/6 [02:00<02:39, 39.88s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (valid):  50% 3/6 [02:00<01:59, 39.92s/it, loss=0.224]\u001b[A\n",
            "3/10 * Epoch (valid):  50% 3/6 [02:40<01:59, 39.92s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (valid):  67% 4/6 [02:40<01:19, 40.00s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (valid):  67% 4/6 [03:20<01:19, 40.00s/it, loss=0.234]\u001b[A\n",
            "3/10 * Epoch (valid):  83% 5/6 [03:20<00:40, 40.13s/it, loss=0.234]\u001b[A\n",
            "3/10 * Epoch (valid):  83% 5/6 [04:01<00:40, 40.13s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (valid): 100% 6/6 [04:01<00:00, 40.29s/it, loss=0.235]\u001b[A\n",
            "3/10 * Epoch (valid): 100% 6/6 [04:01<00:00, 40.22s/it, loss=0.235]\n",
            "\n",
            "3/10 * Epoch (test):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "3/10 * Epoch (test):   0% 0/6 [00:40<?, ?it/s, loss=0.265]\u001b[A\n",
            "3/10 * Epoch (test):  17% 1/6 [00:40<03:20, 40.11s/it, loss=0.265]\u001b[A\n",
            "3/10 * Epoch (test):  17% 1/6 [01:20<03:20, 40.11s/it, loss=0.247]\u001b[A\n",
            "3/10 * Epoch (test):  33% 2/6 [01:20<02:40, 40.07s/it, loss=0.247]\u001b[A\n",
            "3/10 * Epoch (test):  33% 2/6 [02:00<02:40, 40.07s/it, loss=0.246]\u001b[A\n",
            "3/10 * Epoch (test):  50% 3/6 [02:00<02:00, 40.27s/it, loss=0.246]\u001b[A\n",
            "3/10 * Epoch (test):  50% 3/6 [02:41<02:00, 40.27s/it, loss=0.227]\u001b[A\n",
            "3/10 * Epoch (test):  67% 4/6 [02:41<01:20, 40.31s/it, loss=0.227]\u001b[A\n",
            "3/10 * Epoch (test):  67% 4/6 [03:21<01:20, 40.31s/it, loss=0.247]\u001b[A\n",
            "3/10 * Epoch (test):  83% 5/6 [03:21<00:40, 40.40s/it, loss=0.247]\u001b[A\n",
            "3/10 * Epoch (test):  83% 5/6 [04:02<00:40, 40.40s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (test): 100% 6/6 [04:02<00:00, 40.36s/it, loss=0.233]\u001b[A\n",
            "3/10 * Epoch (test): 100% 6/6 [04:02<00:00, 40.35s/it, loss=0.233]\n",
            "[2020-05-27 12:11:19,745] \n",
            "3/10 * Epoch 3 (_base): lr=0.0010 | momentum=0.9000\n",
            "3/10 * Epoch 3 (train): loss=0.2302\n",
            "3/10 * Epoch 3 (valid): loss=0.2324\n",
            "3/10 * Epoch 3 (test): loss=0.2442\n",
            "[2020-05-27 12:11:19,745] \n",
            "3/10 * Epoch 3 (_base): lr=0.0010 | momentum=0.9000\n",
            "3/10 * Epoch 3 (train): loss=0.2302\n",
            "3/10 * Epoch 3 (valid): loss=0.2324\n",
            "3/10 * Epoch 3 (test): loss=0.2442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:metrics_logger:\n",
            "3/10 * Epoch 3 (_base): lr=0.0010 | momentum=0.9000\n",
            "3/10 * Epoch 3 (train): loss=0.2302\n",
            "3/10 * Epoch 3 (valid): loss=0.2324\n",
            "3/10 * Epoch 3 (test): loss=0.2442\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "4/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "4/10 * Epoch (train):   0% 0/96 [00:39<?, ?it/s, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):   1% 1/96 [00:39<1:03:02, 39.82s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):   1% 1/96 [01:20<1:03:02, 39.82s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):   2% 2/96 [01:20<1:02:37, 39.97s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):   2% 2/96 [01:59<1:02:37, 39.97s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):   3% 3/96 [01:59<1:01:53, 39.93s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):   3% 3/96 [02:40<1:01:53, 39.93s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):   4% 4/96 [02:40<1:01:17, 39.97s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):   4% 4/96 [03:20<1:01:17, 39.97s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):   5% 5/96 [03:20<1:00:55, 40.17s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):   5% 5/96 [04:00<1:00:55, 40.17s/it, loss=0.235]\u001b[A\n",
            "4/10 * Epoch (train):   6% 6/96 [04:00<1:00:14, 40.16s/it, loss=0.235]\u001b[A\n",
            "4/10 * Epoch (train):   6% 6/96 [04:41<1:00:14, 40.16s/it, loss=0.238]\u001b[A\n",
            "4/10 * Epoch (train):   7% 7/96 [04:41<59:34, 40.17s/it, loss=0.238]  \u001b[A\n",
            "4/10 * Epoch (train):   7% 7/96 [05:20<59:34, 40.17s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):   8% 8/96 [05:20<58:45, 40.06s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):   8% 8/96 [06:00<58:45, 40.06s/it, loss=0.221]\u001b[A\n",
            "4/10 * Epoch (train):   9% 9/96 [06:00<58:06, 40.08s/it, loss=0.221]\u001b[A\n",
            "4/10 * Epoch (train):   9% 9/96 [06:40<58:06, 40.08s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  10% 10/96 [06:41<57:26, 40.07s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  10% 10/96 [07:21<57:26, 40.07s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):  11% 11/96 [07:21<56:57, 40.21s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):  11% 11/96 [08:01<56:57, 40.21s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (train):  12% 12/96 [08:01<56:18, 40.22s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (train):  12% 12/96 [08:42<56:18, 40.22s/it, loss=0.242]\u001b[A\n",
            "4/10 * Epoch (train):  14% 13/96 [08:42<55:49, 40.36s/it, loss=0.242]\u001b[A\n",
            "4/10 * Epoch (train):  14% 13/96 [09:22<55:49, 40.36s/it, loss=0.216]\u001b[A\n",
            "4/10 * Epoch (train):  15% 14/96 [09:22<55:03, 40.29s/it, loss=0.216]\u001b[A\n",
            "4/10 * Epoch (train):  15% 14/96 [10:02<55:03, 40.29s/it, loss=0.219]\u001b[A\n",
            "4/10 * Epoch (train):  16% 15/96 [10:02<54:22, 40.28s/it, loss=0.219]\u001b[A\n",
            "4/10 * Epoch (train):  16% 15/96 [10:42<54:22, 40.28s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):  17% 16/96 [10:42<53:33, 40.17s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):  17% 16/96 [11:22<53:33, 40.17s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):  18% 17/96 [11:22<52:52, 40.16s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):  18% 17/96 [12:03<52:52, 40.16s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  19% 18/96 [12:03<52:13, 40.17s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  19% 18/96 [12:42<52:13, 40.17s/it, loss=0.217]\u001b[A\n",
            "4/10 * Epoch (train):  20% 19/96 [12:42<51:23, 40.04s/it, loss=0.217]\u001b[A\n",
            "4/10 * Epoch (train):  20% 19/96 [13:22<51:23, 40.04s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  21% 20/96 [13:22<50:43, 40.05s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  21% 20/96 [14:03<50:43, 40.05s/it, loss=0.211]\u001b[A\n",
            "4/10 * Epoch (train):  22% 21/96 [14:03<50:08, 40.11s/it, loss=0.211]\u001b[A\n",
            "4/10 * Epoch (train):  22% 21/96 [14:43<50:08, 40.11s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  23% 22/96 [14:43<49:40, 40.27s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  23% 22/96 [15:23<49:40, 40.27s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  24% 23/96 [15:23<48:54, 40.20s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  24% 23/96 [16:04<48:54, 40.20s/it, loss=0.235]\u001b[A\n",
            "4/10 * Epoch (train):  25% 24/96 [16:04<48:17, 40.24s/it, loss=0.235]\u001b[A\n",
            "4/10 * Epoch (train):  25% 24/96 [16:43<48:17, 40.24s/it, loss=0.240]\u001b[A\n",
            "4/10 * Epoch (train):  26% 25/96 [16:43<47:28, 40.11s/it, loss=0.240]\u001b[A\n",
            "4/10 * Epoch (train):  26% 25/96 [17:24<47:28, 40.11s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):  27% 26/96 [17:24<46:55, 40.22s/it, loss=0.228]\u001b[A\n",
            "4/10 * Epoch (train):  27% 26/96 [18:03<46:55, 40.22s/it, loss=0.215]\u001b[A\n",
            "4/10 * Epoch (train):  28% 27/96 [18:03<46:00, 40.00s/it, loss=0.215]\u001b[A\n",
            "4/10 * Epoch (train):  28% 27/96 [18:43<46:00, 40.00s/it, loss=0.229]\u001b[A\n",
            "4/10 * Epoch (train):  29% 28/96 [18:43<45:19, 40.00s/it, loss=0.229]\u001b[A\n",
            "4/10 * Epoch (train):  29% 28/96 [19:23<45:19, 40.00s/it, loss=0.238]\u001b[A\n",
            "4/10 * Epoch (train):  30% 29/96 [19:23<44:38, 39.98s/it, loss=0.238]\u001b[A\n",
            "4/10 * Epoch (train):  30% 29/96 [20:03<44:38, 39.98s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  31% 30/96 [20:03<43:57, 39.97s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  31% 30/96 [20:44<43:57, 39.97s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  32% 31/96 [20:44<43:25, 40.09s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  32% 31/96 [21:23<43:25, 40.09s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  33% 32/96 [21:23<42:34, 39.92s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  33% 32/96 [22:04<42:34, 39.92s/it, loss=0.220]\u001b[A\n",
            "4/10 * Epoch (train):  34% 33/96 [22:04<42:04, 40.07s/it, loss=0.220]\u001b[A\n",
            "4/10 * Epoch (train):  34% 33/96 [22:44<42:04, 40.07s/it, loss=0.247]\u001b[A\n",
            "4/10 * Epoch (train):  35% 34/96 [22:44<41:25, 40.10s/it, loss=0.247]\u001b[A\n",
            "4/10 * Epoch (train):  35% 34/96 [23:24<41:25, 40.10s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  36% 35/96 [23:24<40:56, 40.27s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  36% 35/96 [24:05<40:56, 40.27s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  38% 36/96 [24:05<40:19, 40.32s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  38% 36/96 [24:44<40:19, 40.32s/it, loss=0.224]\u001b[A\n",
            "4/10 * Epoch (train):  39% 37/96 [24:44<39:15, 39.92s/it, loss=0.224]\u001b[A\n",
            "4/10 * Epoch (train):  39% 37/96 [25:24<39:15, 39.92s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  40% 38/96 [25:24<38:42, 40.03s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  40% 38/96 [26:04<38:42, 40.03s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  41% 39/96 [26:04<38:03, 40.07s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  41% 39/96 [26:45<38:03, 40.07s/it, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (train):  42% 40/96 [26:45<37:28, 40.14s/it, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (train):  42% 40/96 [27:24<37:28, 40.14s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  43% 41/96 [27:24<36:41, 40.03s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  43% 41/96 [28:06<36:41, 40.03s/it, loss=0.229]\u001b[A\n",
            "4/10 * Epoch (train):  44% 42/96 [28:06<36:19, 40.37s/it, loss=0.229]\u001b[A\n",
            "4/10 * Epoch (train):  44% 42/96 [28:46<36:19, 40.37s/it, loss=0.257]\u001b[A\n",
            "4/10 * Epoch (train):  45% 43/96 [28:46<35:37, 40.33s/it, loss=0.257]\u001b[A\n",
            "4/10 * Epoch (train):  45% 43/96 [29:26<35:37, 40.33s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  46% 44/96 [29:26<34:58, 40.35s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  46% 44/96 [30:06<34:58, 40.35s/it, loss=0.211]\u001b[A\n",
            "4/10 * Epoch (train):  47% 45/96 [30:06<34:16, 40.32s/it, loss=0.211]\u001b[A\n",
            "4/10 * Epoch (train):  47% 45/96 [30:47<34:16, 40.32s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  48% 46/96 [30:47<33:34, 40.29s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  48% 46/96 [31:27<33:34, 40.29s/it, loss=0.227]\u001b[A\n",
            "4/10 * Epoch (train):  49% 47/96 [31:27<32:52, 40.26s/it, loss=0.227]\u001b[A\n",
            "4/10 * Epoch (train):  49% 47/96 [32:07<32:52, 40.26s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  50% 48/96 [32:07<32:03, 40.08s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  50% 48/96 [32:47<32:03, 40.08s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  51% 49/96 [32:47<31:25, 40.11s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  51% 49/96 [33:26<31:25, 40.11s/it, loss=0.239]\u001b[A\n",
            "4/10 * Epoch (train):  52% 50/96 [33:26<30:34, 39.88s/it, loss=0.239]\u001b[A\n",
            "4/10 * Epoch (train):  52% 50/96 [34:06<30:34, 39.88s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  53% 51/96 [34:06<29:55, 39.90s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  53% 51/96 [34:46<29:55, 39.90s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  54% 52/96 [34:46<29:13, 39.85s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  54% 52/96 [35:25<29:13, 39.85s/it, loss=0.229]\u001b[A\n",
            "4/10 * Epoch (train):  55% 53/96 [35:25<28:25, 39.66s/it, loss=0.229]\u001b[A\n",
            "4/10 * Epoch (train):  55% 53/96 [36:05<28:25, 39.66s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  56% 54/96 [36:05<27:50, 39.77s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  56% 54/96 [36:46<27:50, 39.77s/it, loss=0.246]\u001b[A\n",
            "4/10 * Epoch (train):  57% 55/96 [36:46<27:20, 40.01s/it, loss=0.246]\u001b[A\n",
            "4/10 * Epoch (train):  57% 55/96 [37:26<27:20, 40.01s/it, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (train):  58% 56/96 [37:26<26:41, 40.04s/it, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (train):  58% 56/96 [38:06<26:41, 40.04s/it, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (train):  59% 57/96 [38:06<26:02, 40.05s/it, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (train):  59% 57/96 [38:46<26:02, 40.05s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  60% 58/96 [38:46<25:25, 40.15s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  60% 58/96 [39:26<25:25, 40.15s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  61% 59/96 [39:26<24:41, 40.05s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  61% 59/96 [40:06<24:41, 40.05s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):  62% 60/96 [40:06<24:02, 40.07s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):  62% 60/96 [40:46<24:02, 40.07s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (train):  64% 61/96 [40:46<23:24, 40.12s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (train):  64% 61/96 [41:26<23:24, 40.12s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  65% 62/96 [41:26<22:43, 40.11s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  65% 62/96 [42:06<22:43, 40.11s/it, loss=0.227]\u001b[A\n",
            "4/10 * Epoch (train):  66% 63/96 [42:06<21:56, 39.91s/it, loss=0.227]\u001b[A\n",
            "4/10 * Epoch (train):  66% 63/96 [42:46<21:56, 39.91s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):  67% 64/96 [42:46<21:15, 39.85s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):  67% 64/96 [43:26<21:15, 39.85s/it, loss=0.216]\u001b[A\n",
            "4/10 * Epoch (train):  68% 65/96 [43:26<20:38, 39.94s/it, loss=0.216]\u001b[A\n",
            "4/10 * Epoch (train):  68% 65/96 [44:06<20:38, 39.94s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  69% 66/96 [44:06<19:57, 39.91s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (train):  69% 66/96 [44:45<19:57, 39.91s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  70% 67/96 [44:45<19:16, 39.88s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (train):  70% 67/96 [45:25<19:16, 39.88s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  71% 68/96 [45:25<18:33, 39.78s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  71% 68/96 [46:05<18:33, 39.78s/it, loss=0.248]\u001b[A\n",
            "4/10 * Epoch (train):  72% 69/96 [46:05<17:55, 39.85s/it, loss=0.248]\u001b[A\n",
            "4/10 * Epoch (train):  72% 69/96 [46:45<17:55, 39.85s/it, loss=0.220]\u001b[A\n",
            "4/10 * Epoch (train):  73% 70/96 [46:45<17:14, 39.79s/it, loss=0.220]\u001b[A\n",
            "4/10 * Epoch (train):  73% 70/96 [47:24<17:14, 39.79s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  74% 71/96 [47:24<16:33, 39.74s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  74% 71/96 [48:04<16:33, 39.74s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  75% 72/96 [48:04<15:52, 39.70s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  75% 72/96 [48:43<15:52, 39.70s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  76% 73/96 [48:43<15:12, 39.67s/it, loss=0.241]\u001b[A\n",
            "4/10 * Epoch (train):  76% 73/96 [49:23<15:12, 39.67s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):  77% 74/96 [49:23<14:34, 39.73s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (train):  77% 74/96 [50:03<14:34, 39.73s/it, loss=0.217]\u001b[A\n",
            "4/10 * Epoch (train):  78% 75/96 [50:03<13:55, 39.80s/it, loss=0.217]\u001b[A\n",
            "4/10 * Epoch (train):  78% 75/96 [50:43<13:55, 39.80s/it, loss=0.209]\u001b[A\n",
            "4/10 * Epoch (train):  79% 76/96 [50:43<13:15, 39.77s/it, loss=0.209]\u001b[A\n",
            "4/10 * Epoch (train):  79% 76/96 [51:23<13:15, 39.77s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):  80% 77/96 [51:23<12:37, 39.89s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):  80% 77/96 [52:03<12:37, 39.89s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  81% 78/96 [52:03<11:58, 39.94s/it, loss=0.230]\u001b[A\n",
            "4/10 * Epoch (train):  81% 78/96 [52:43<11:58, 39.94s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  82% 79/96 [52:43<11:20, 40.02s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  82% 79/96 [53:23<11:20, 40.02s/it, loss=0.238]\u001b[A\n",
            "4/10 * Epoch (train):  83% 80/96 [53:23<10:37, 39.86s/it, loss=0.238]\u001b[A\n",
            "4/10 * Epoch (train):  83% 80/96 [54:03<10:37, 39.86s/it, loss=0.238]\u001b[A\n",
            "4/10 * Epoch (train):  84% 81/96 [54:03<09:58, 39.92s/it, loss=0.238]\u001b[A\n",
            "4/10 * Epoch (train):  84% 81/96 [54:42<09:58, 39.92s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (train):  85% 82/96 [54:42<09:16, 39.72s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (train):  85% 82/96 [55:22<09:16, 39.72s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):  86% 83/96 [55:22<08:38, 39.89s/it, loss=0.231]\u001b[A\n",
            "4/10 * Epoch (train):  86% 83/96 [56:02<08:38, 39.89s/it, loss=0.240]\u001b[A\n",
            "4/10 * Epoch (train):  88% 84/96 [56:02<07:58, 39.89s/it, loss=0.240]\u001b[A\n",
            "4/10 * Epoch (train):  88% 84/96 [56:42<07:58, 39.89s/it, loss=0.220]\u001b[A\n",
            "4/10 * Epoch (train):  89% 85/96 [56:42<07:19, 39.92s/it, loss=0.220]\u001b[A\n",
            "4/10 * Epoch (train):  89% 85/96 [57:22<07:19, 39.92s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  90% 86/96 [57:22<06:38, 39.84s/it, loss=0.222]\u001b[A\n",
            "4/10 * Epoch (train):  90% 86/96 [58:01<06:38, 39.84s/it, loss=0.235]\u001b[A\n",
            "4/10 * Epoch (train):  91% 87/96 [58:01<05:56, 39.63s/it, loss=0.235]\u001b[A\n",
            "4/10 * Epoch (train):  91% 87/96 [58:41<05:56, 39.63s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  92% 88/96 [58:41<05:16, 39.62s/it, loss=0.218]\u001b[A\n",
            "4/10 * Epoch (train):  92% 88/96 [59:21<05:16, 39.62s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  93% 89/96 [59:21<04:37, 39.69s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  93% 89/96 [1:00:00<04:37, 39.69s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  94% 90/96 [1:00:00<03:58, 39.74s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train):  94% 90/96 [1:00:40<03:58, 39.74s/it, loss=0.219]\u001b[A\n",
            "4/10 * Epoch (train):  95% 91/96 [1:00:40<03:18, 39.65s/it, loss=0.219]\u001b[A\n",
            "4/10 * Epoch (train):  95% 91/96 [1:01:20<03:18, 39.65s/it, loss=0.212]\u001b[A\n",
            "4/10 * Epoch (train):  96% 92/96 [1:01:20<02:39, 39.76s/it, loss=0.212]\u001b[A\n",
            "4/10 * Epoch (train):  96% 92/96 [1:02:00<02:39, 39.76s/it, loss=0.253]\u001b[A\n",
            "4/10 * Epoch (train):  97% 93/96 [1:02:00<01:59, 39.77s/it, loss=0.253]\u001b[A\n",
            "4/10 * Epoch (train):  97% 93/96 [1:02:40<01:59, 39.77s/it, loss=0.240]\u001b[A\n",
            "4/10 * Epoch (train):  98% 94/96 [1:02:40<01:19, 39.95s/it, loss=0.240]\u001b[A\n",
            "4/10 * Epoch (train):  98% 94/96 [1:03:20<01:19, 39.95s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  99% 95/96 [1:03:20<00:39, 39.88s/it, loss=0.225]\u001b[A\n",
            "4/10 * Epoch (train):  99% 95/96 [1:04:00<00:39, 39.88s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train): 100% 96/96 [1:04:00<00:00, 40.05s/it, loss=0.237]\u001b[A\n",
            "4/10 * Epoch (train): 100% 96/96 [1:04:00<00:00, 40.01s/it, loss=0.237]\n",
            "\n",
            "4/10 * Epoch (valid):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "4/10 * Epoch (valid):   0% 0/6 [00:39<?, ?it/s, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (valid):  17% 1/6 [00:39<03:18, 39.61s/it, loss=0.236]\u001b[A\n",
            "4/10 * Epoch (valid):  17% 1/6 [01:19<03:18, 39.61s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (valid):  33% 2/6 [01:19<02:39, 39.79s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (valid):  33% 2/6 [01:59<02:39, 39.79s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (valid):  50% 3/6 [01:59<01:59, 39.80s/it, loss=0.223]\u001b[A\n",
            "4/10 * Epoch (valid):  50% 3/6 [02:39<01:59, 39.80s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (valid):  67% 4/6 [02:39<01:19, 39.84s/it, loss=0.232]\u001b[A\n",
            "4/10 * Epoch (valid):  67% 4/6 [03:19<01:19, 39.84s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (valid):  83% 5/6 [03:19<00:40, 40.01s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (valid):  83% 5/6 [04:00<00:40, 40.01s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (valid): 100% 6/6 [04:00<00:00, 40.14s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (valid): 100% 6/6 [04:00<00:00, 40.07s/it, loss=0.233]\n",
            "\n",
            "4/10 * Epoch (test):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "4/10 * Epoch (test):   0% 0/6 [00:39<?, ?it/s, loss=0.264]\u001b[A\n",
            "4/10 * Epoch (test):  17% 1/6 [00:39<03:17, 39.58s/it, loss=0.264]\u001b[A\n",
            "4/10 * Epoch (test):  17% 1/6 [01:19<03:17, 39.58s/it, loss=0.246]\u001b[A\n",
            "4/10 * Epoch (test):  33% 2/6 [01:19<02:38, 39.69s/it, loss=0.246]\u001b[A\n",
            "4/10 * Epoch (test):  33% 2/6 [01:59<02:38, 39.69s/it, loss=0.246]\u001b[A\n",
            "4/10 * Epoch (test):  50% 3/6 [01:59<01:59, 39.86s/it, loss=0.246]\u001b[A\n",
            "4/10 * Epoch (test):  50% 3/6 [02:39<01:59, 39.86s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (test):  67% 4/6 [02:39<01:19, 39.90s/it, loss=0.226]\u001b[A\n",
            "4/10 * Epoch (test):  67% 4/6 [03:19<01:19, 39.90s/it, loss=0.247]\u001b[A\n",
            "4/10 * Epoch (test):  83% 5/6 [03:19<00:39, 39.93s/it, loss=0.247]\u001b[A\n",
            "4/10 * Epoch (test):  83% 5/6 [04:00<00:39, 39.93s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (test): 100% 6/6 [04:00<00:00, 40.03s/it, loss=0.233]\u001b[A\n",
            "4/10 * Epoch (test): 100% 6/6 [04:00<00:00, 40.01s/it, loss=0.233]\n",
            "[2020-05-27 13:23:21,048] \n",
            "4/10 * Epoch 4 (_base): lr=0.0010 | momentum=0.9000\n",
            "4/10 * Epoch 4 (train): loss=0.2293\n",
            "4/10 * Epoch 4 (valid): loss=0.2316\n",
            "4/10 * Epoch 4 (test): loss=0.2437\n",
            "[2020-05-27 13:23:21,048] \n",
            "4/10 * Epoch 4 (_base): lr=0.0010 | momentum=0.9000\n",
            "4/10 * Epoch 4 (train): loss=0.2293\n",
            "4/10 * Epoch 4 (valid): loss=0.2316\n",
            "4/10 * Epoch 4 (test): loss=0.2437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:metrics_logger:\n",
            "4/10 * Epoch 4 (_base): lr=0.0010 | momentum=0.9000\n",
            "4/10 * Epoch 4 (train): loss=0.2293\n",
            "4/10 * Epoch 4 (valid): loss=0.2316\n",
            "4/10 * Epoch 4 (test): loss=0.2437\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "5/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "5/10 * Epoch (train):   0% 0/96 [00:39<?, ?it/s, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):   1% 1/96 [00:39<1:02:20, 39.38s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):   1% 1/96 [01:19<1:02:20, 39.38s/it, loss=0.226]\u001b[A\n",
            "5/10 * Epoch (train):   2% 2/96 [01:19<1:02:01, 39.59s/it, loss=0.226]\u001b[A\n",
            "5/10 * Epoch (train):   2% 2/96 [01:59<1:02:01, 39.59s/it, loss=0.223]\u001b[A\n",
            "5/10 * Epoch (train):   3% 3/96 [01:59<1:01:21, 39.59s/it, loss=0.223]\u001b[A\n",
            "5/10 * Epoch (train):   3% 3/96 [02:38<1:01:21, 39.59s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):   4% 4/96 [02:38<1:00:40, 39.57s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):   4% 4/96 [03:18<1:00:40, 39.57s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):   5% 5/96 [03:18<1:00:18, 39.76s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):   5% 5/96 [03:58<1:00:18, 39.76s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):   6% 6/96 [03:58<59:41, 39.80s/it, loss=0.234]  \u001b[A\n",
            "5/10 * Epoch (train):   6% 6/96 [04:38<59:41, 39.80s/it, loss=0.238]\u001b[A\n",
            "5/10 * Epoch (train):   7% 7/96 [04:38<59:02, 39.81s/it, loss=0.238]\u001b[A\n",
            "5/10 * Epoch (train):   7% 7/96 [05:18<59:02, 39.81s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):   8% 8/96 [05:18<58:15, 39.72s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):   8% 8/96 [05:57<58:15, 39.72s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):   9% 9/96 [05:57<57:39, 39.76s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):   9% 9/96 [06:37<57:39, 39.76s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  10% 10/96 [06:37<57:01, 39.78s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  10% 10/96 [07:17<57:01, 39.78s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  11% 11/96 [07:17<56:33, 39.92s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  11% 11/96 [07:57<56:33, 39.92s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):  12% 12/96 [07:57<55:53, 39.93s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):  12% 12/96 [08:38<55:53, 39.93s/it, loss=0.243]\u001b[A\n",
            "5/10 * Epoch (train):  14% 13/96 [08:38<55:23, 40.04s/it, loss=0.243]\u001b[A\n",
            "5/10 * Epoch (train):  14% 13/96 [09:17<55:23, 40.04s/it, loss=0.216]\u001b[A\n",
            "5/10 * Epoch (train):  15% 14/96 [09:18<54:37, 39.97s/it, loss=0.216]\u001b[A\n",
            "5/10 * Epoch (train):  15% 14/96 [09:57<54:37, 39.97s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):  16% 15/96 [09:57<53:54, 39.93s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):  16% 15/96 [10:37<53:54, 39.93s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  17% 16/96 [10:37<53:05, 39.82s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  17% 16/96 [11:17<53:05, 39.82s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  18% 17/96 [11:17<52:25, 39.82s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  18% 17/96 [11:57<52:25, 39.82s/it, loss=0.230]\u001b[A\n",
            "5/10 * Epoch (train):  19% 18/96 [11:57<51:52, 39.91s/it, loss=0.230]\u001b[A\n",
            "5/10 * Epoch (train):  19% 18/96 [12:36<51:52, 39.91s/it, loss=0.216]\u001b[A\n",
            "5/10 * Epoch (train):  20% 19/96 [12:36<51:06, 39.83s/it, loss=0.216]\u001b[A\n",
            "5/10 * Epoch (train):  20% 19/96 [13:16<51:06, 39.83s/it, loss=0.228]\u001b[A\n",
            "5/10 * Epoch (train):  21% 20/96 [13:16<50:26, 39.83s/it, loss=0.228]\u001b[A\n",
            "5/10 * Epoch (train):  21% 20/96 [13:56<50:26, 39.83s/it, loss=0.210]\u001b[A\n",
            "5/10 * Epoch (train):  22% 21/96 [13:56<49:49, 39.86s/it, loss=0.210]\u001b[A\n",
            "5/10 * Epoch (train):  22% 21/96 [14:36<49:49, 39.86s/it, loss=0.219]\u001b[A\n",
            "5/10 * Epoch (train):  23% 22/96 [14:36<49:18, 39.98s/it, loss=0.219]\u001b[A\n",
            "5/10 * Epoch (train):  23% 22/96 [15:16<49:18, 39.98s/it, loss=0.240]\u001b[A\n",
            "5/10 * Epoch (train):  24% 23/96 [15:16<48:35, 39.94s/it, loss=0.240]\u001b[A\n",
            "5/10 * Epoch (train):  24% 23/96 [15:56<48:35, 39.94s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  25% 24/96 [15:56<48:00, 40.00s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  25% 24/96 [16:36<48:00, 40.00s/it, loss=0.241]\u001b[A\n",
            "5/10 * Epoch (train):  26% 25/96 [16:36<47:12, 39.89s/it, loss=0.241]\u001b[A\n",
            "5/10 * Epoch (train):  26% 25/96 [17:16<47:12, 39.89s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  27% 26/96 [17:16<46:39, 39.99s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  27% 26/96 [17:56<46:39, 39.99s/it, loss=0.214]\u001b[A\n",
            "5/10 * Epoch (train):  28% 27/96 [17:56<45:43, 39.76s/it, loss=0.214]\u001b[A\n",
            "5/10 * Epoch (train):  28% 27/96 [18:35<45:43, 39.76s/it, loss=0.228]\u001b[A\n",
            "5/10 * Epoch (train):  29% 28/96 [18:35<45:05, 39.79s/it, loss=0.228]\u001b[A\n",
            "5/10 * Epoch (train):  29% 28/96 [19:15<45:05, 39.79s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  30% 29/96 [19:15<44:25, 39.78s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  30% 29/96 [19:55<44:25, 39.78s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  31% 30/96 [19:55<43:44, 39.77s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  31% 30/96 [20:35<43:44, 39.77s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  32% 31/96 [20:35<43:13, 39.90s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  32% 31/96 [21:14<43:13, 39.90s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  33% 32/96 [21:14<42:22, 39.73s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  33% 32/96 [21:55<42:22, 39.73s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):  34% 33/96 [21:55<41:51, 39.87s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):  34% 33/96 [22:35<41:51, 39.87s/it, loss=0.248]\u001b[A\n",
            "5/10 * Epoch (train):  35% 34/96 [22:35<41:12, 39.88s/it, loss=0.248]\u001b[A\n",
            "5/10 * Epoch (train):  35% 34/96 [23:15<41:12, 39.88s/it, loss=0.232]\u001b[A\n",
            "5/10 * Epoch (train):  36% 35/96 [23:15<40:46, 40.10s/it, loss=0.232]\u001b[A\n",
            "5/10 * Epoch (train):  36% 35/96 [23:55<40:46, 40.10s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train):  38% 36/96 [23:55<40:07, 40.12s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train):  38% 36/96 [24:34<40:07, 40.12s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  39% 37/96 [24:34<39:05, 39.75s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  39% 37/96 [25:14<39:05, 39.75s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train):  40% 38/96 [25:14<38:31, 39.86s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train):  40% 38/96 [25:54<38:31, 39.86s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  41% 39/96 [25:54<37:55, 39.92s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  41% 39/96 [26:34<37:55, 39.92s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  42% 40/96 [26:34<37:15, 39.92s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  42% 40/96 [27:14<37:15, 39.92s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  43% 41/96 [27:14<36:30, 39.83s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  43% 41/96 [27:55<36:30, 39.83s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  44% 42/96 [27:55<36:07, 40.14s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  44% 42/96 [28:35<36:07, 40.14s/it, loss=0.255]\u001b[A\n",
            "5/10 * Epoch (train):  45% 43/96 [28:35<35:23, 40.06s/it, loss=0.255]\u001b[A\n",
            "5/10 * Epoch (train):  45% 43/96 [29:15<35:23, 40.06s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (train):  46% 44/96 [29:15<34:50, 40.19s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (train):  46% 44/96 [29:56<34:50, 40.19s/it, loss=0.211]\u001b[A\n",
            "5/10 * Epoch (train):  47% 45/96 [29:56<34:13, 40.27s/it, loss=0.211]\u001b[A\n",
            "5/10 * Epoch (train):  47% 45/96 [30:36<34:13, 40.27s/it, loss=0.239]\u001b[A\n",
            "5/10 * Epoch (train):  48% 46/96 [30:36<33:36, 40.34s/it, loss=0.239]\u001b[A\n",
            "5/10 * Epoch (train):  48% 46/96 [31:17<33:36, 40.34s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  49% 47/96 [31:17<33:00, 40.41s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  49% 47/96 [31:57<33:00, 40.41s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  50% 48/96 [31:57<32:14, 40.30s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  50% 48/96 [32:37<32:14, 40.30s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  51% 49/96 [32:37<31:35, 40.33s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  51% 49/96 [33:17<31:35, 40.33s/it, loss=0.239]\u001b[A\n",
            "5/10 * Epoch (train):  52% 50/96 [33:17<30:47, 40.17s/it, loss=0.239]\u001b[A\n",
            "5/10 * Epoch (train):  52% 50/96 [33:57<30:47, 40.17s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  53% 51/96 [33:57<30:09, 40.21s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  53% 51/96 [34:38<30:09, 40.21s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  54% 52/96 [34:38<29:30, 40.23s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  54% 52/96 [35:17<29:30, 40.23s/it, loss=0.230]\u001b[A\n",
            "5/10 * Epoch (train):  55% 53/96 [35:17<28:43, 40.07s/it, loss=0.230]\u001b[A\n",
            "5/10 * Epoch (train):  55% 53/96 [35:58<28:43, 40.07s/it, loss=0.228]\u001b[A\n",
            "5/10 * Epoch (train):  56% 54/96 [35:58<28:07, 40.17s/it, loss=0.228]\u001b[A\n",
            "5/10 * Epoch (train):  56% 54/96 [36:38<28:07, 40.17s/it, loss=0.245]\u001b[A\n",
            "5/10 * Epoch (train):  57% 55/96 [36:38<27:35, 40.38s/it, loss=0.245]\u001b[A\n",
            "5/10 * Epoch (train):  57% 55/96 [37:19<27:35, 40.38s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  58% 56/96 [37:19<26:56, 40.41s/it, loss=0.235]\u001b[A\n",
            "5/10 * Epoch (train):  58% 56/96 [37:59<26:56, 40.41s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  59% 57/96 [37:59<26:14, 40.38s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  59% 57/96 [38:40<26:14, 40.38s/it, loss=0.222]\u001b[A\n",
            "5/10 * Epoch (train):  60% 58/96 [38:40<25:35, 40.40s/it, loss=0.222]\u001b[A\n",
            "5/10 * Epoch (train):  60% 58/96 [39:20<25:35, 40.40s/it, loss=0.230]\u001b[A\n",
            "5/10 * Epoch (train):  61% 59/96 [39:20<24:52, 40.34s/it, loss=0.230]\u001b[A\n",
            "5/10 * Epoch (train):  61% 59/96 [40:00<24:52, 40.34s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  62% 60/96 [40:00<24:12, 40.34s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  62% 60/96 [40:41<24:12, 40.34s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):  64% 61/96 [40:41<23:31, 40.34s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):  64% 61/96 [41:21<23:31, 40.34s/it, loss=0.241]\u001b[A\n",
            "5/10 * Epoch (train):  65% 62/96 [41:21<22:51, 40.35s/it, loss=0.241]\u001b[A\n",
            "5/10 * Epoch (train):  65% 62/96 [42:01<22:51, 40.35s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  66% 63/96 [42:01<22:05, 40.18s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  66% 63/96 [42:41<22:05, 40.18s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  67% 64/96 [42:41<21:22, 40.09s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  67% 64/96 [43:21<21:22, 40.09s/it, loss=0.219]\u001b[A\n",
            "5/10 * Epoch (train):  68% 65/96 [43:21<20:48, 40.26s/it, loss=0.219]\u001b[A\n",
            "5/10 * Epoch (train):  68% 65/96 [44:02<20:48, 40.26s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (train):  69% 66/96 [44:02<20:08, 40.28s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (train):  69% 66/96 [44:42<20:08, 40.28s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  70% 67/96 [44:42<19:28, 40.28s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  70% 67/96 [45:22<19:28, 40.28s/it, loss=0.222]\u001b[A\n",
            "5/10 * Epoch (train):  71% 68/96 [45:22<18:44, 40.15s/it, loss=0.222]\u001b[A\n",
            "5/10 * Epoch (train):  71% 68/96 [46:02<18:44, 40.15s/it, loss=0.247]\u001b[A\n",
            "5/10 * Epoch (train):  72% 69/96 [46:02<18:06, 40.25s/it, loss=0.247]\u001b[A\n",
            "5/10 * Epoch (train):  72% 69/96 [46:43<18:06, 40.25s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  73% 70/96 [46:43<17:27, 40.27s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  73% 70/96 [47:23<17:27, 40.27s/it, loss=0.217]\u001b[A\n",
            "5/10 * Epoch (train):  74% 71/96 [47:23<16:46, 40.27s/it, loss=0.217]\u001b[A\n",
            "5/10 * Epoch (train):  74% 71/96 [48:03<16:46, 40.27s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):  75% 72/96 [48:03<16:05, 40.25s/it, loss=0.221]\u001b[A\n",
            "5/10 * Epoch (train):  75% 72/96 [48:43<16:05, 40.25s/it, loss=0.241]\u001b[A\n",
            "5/10 * Epoch (train):  76% 73/96 [48:43<15:24, 40.18s/it, loss=0.241]\u001b[A\n",
            "5/10 * Epoch (train):  76% 73/96 [49:23<15:24, 40.18s/it, loss=0.226]\u001b[A\n",
            "5/10 * Epoch (train):  77% 74/96 [49:24<14:46, 40.27s/it, loss=0.226]\u001b[A\n",
            "5/10 * Epoch (train):  77% 74/96 [50:04<14:46, 40.27s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  78% 75/96 [50:04<14:07, 40.37s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  78% 75/96 [50:44<14:07, 40.37s/it, loss=0.208]\u001b[A\n",
            "5/10 * Epoch (train):  79% 76/96 [50:44<13:26, 40.30s/it, loss=0.208]\u001b[A\n",
            "5/10 * Epoch (train):  79% 76/96 [51:25<13:26, 40.30s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  80% 77/96 [51:25<12:46, 40.35s/it, loss=0.231]\u001b[A\n",
            "5/10 * Epoch (train):  80% 77/96 [52:05<12:46, 40.35s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  81% 78/96 [52:05<12:06, 40.34s/it, loss=0.229]\u001b[A\n",
            "5/10 * Epoch (train):  81% 78/96 [52:46<12:06, 40.34s/it, loss=0.223]\u001b[A\n",
            "5/10 * Epoch (train):  82% 79/96 [52:46<11:26, 40.41s/it, loss=0.223]\u001b[A\n",
            "5/10 * Epoch (train):  82% 79/96 [53:26<11:26, 40.41s/it, loss=0.239]\u001b[A\n",
            "5/10 * Epoch (train):  83% 80/96 [53:26<10:45, 40.32s/it, loss=0.239]\u001b[A\n",
            "5/10 * Epoch (train):  83% 80/96 [54:06<10:45, 40.32s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train):  84% 81/96 [54:06<10:04, 40.33s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train):  84% 81/96 [54:46<10:04, 40.33s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):  85% 82/96 [54:46<09:22, 40.17s/it, loss=0.220]\u001b[A\n",
            "5/10 * Epoch (train):  85% 82/96 [55:27<09:22, 40.17s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  86% 83/96 [55:27<08:44, 40.32s/it, loss=0.227]\u001b[A\n",
            "5/10 * Epoch (train):  86% 83/96 [56:07<08:44, 40.32s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  88% 84/96 [56:07<08:03, 40.32s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  88% 84/96 [56:47<08:03, 40.32s/it, loss=0.219]\u001b[A\n",
            "5/10 * Epoch (train):  89% 85/96 [56:47<07:23, 40.30s/it, loss=0.219]\u001b[A\n",
            "5/10 * Epoch (train):  89% 85/96 [57:27<07:23, 40.30s/it, loss=0.223]\u001b[A\n",
            "5/10 * Epoch (train):  90% 86/96 [57:27<06:42, 40.23s/it, loss=0.223]\u001b[A\n",
            "5/10 * Epoch (train):  90% 86/96 [58:07<06:42, 40.23s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  91% 87/96 [58:07<06:00, 40.03s/it, loss=0.234]\u001b[A\n",
            "5/10 * Epoch (train):  91% 87/96 [58:47<06:00, 40.03s/it, loss=0.217]\u001b[A\n",
            "5/10 * Epoch (train):  92% 88/96 [58:47<05:20, 40.06s/it, loss=0.217]\u001b[A\n",
            "5/10 * Epoch (train):  92% 88/96 [59:27<05:20, 40.06s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  93% 89/96 [59:27<04:40, 40.09s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (train):  93% 89/96 [1:00:07<04:40, 40.09s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  94% 90/96 [1:00:07<04:00, 40.13s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  94% 90/96 [1:00:47<04:00, 40.13s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  95% 91/96 [1:00:47<03:20, 40.03s/it, loss=0.218]\u001b[A\n",
            "5/10 * Epoch (train):  95% 91/96 [1:01:28<03:20, 40.03s/it, loss=0.209]\u001b[A\n",
            "5/10 * Epoch (train):  96% 92/96 [1:01:28<02:40, 40.17s/it, loss=0.209]\u001b[A\n",
            "5/10 * Epoch (train):  96% 92/96 [1:02:08<02:40, 40.17s/it, loss=0.252]\u001b[A\n",
            "5/10 * Epoch (train):  97% 93/96 [1:02:08<02:00, 40.16s/it, loss=0.252]\u001b[A\n",
            "5/10 * Epoch (train):  97% 93/96 [1:02:48<02:00, 40.16s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  98% 94/96 [1:02:48<01:20, 40.34s/it, loss=0.237]\u001b[A\n",
            "5/10 * Epoch (train):  98% 94/96 [1:03:29<01:20, 40.34s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  99% 95/96 [1:03:29<00:40, 40.34s/it, loss=0.225]\u001b[A\n",
            "5/10 * Epoch (train):  99% 95/96 [1:04:10<00:40, 40.34s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train): 100% 96/96 [1:04:10<00:00, 40.52s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (train): 100% 96/96 [1:04:10<00:00, 40.11s/it, loss=0.236]\n",
            "\n",
            "5/10 * Epoch (valid):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "5/10 * Epoch (valid):   0% 0/6 [00:40<?, ?it/s, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (valid):  17% 1/6 [00:40<03:20, 40.08s/it, loss=0.236]\u001b[A\n",
            "5/10 * Epoch (valid):  17% 1/6 [01:20<03:20, 40.08s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (valid):  33% 2/6 [01:20<02:40, 40.23s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (valid):  33% 2/6 [02:00<02:40, 40.23s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (valid):  50% 3/6 [02:00<02:00, 40.19s/it, loss=0.224]\u001b[A\n",
            "5/10 * Epoch (valid):  50% 3/6 [02:41<02:00, 40.19s/it, loss=0.232]\u001b[A\n",
            "5/10 * Epoch (valid):  67% 4/6 [02:41<01:20, 40.22s/it, loss=0.232]\u001b[A\n",
            "5/10 * Epoch (valid):  67% 4/6 [03:21<01:20, 40.22s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (valid):  83% 5/6 [03:21<00:40, 40.37s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (valid):  83% 5/6 [04:02<00:40, 40.37s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (valid): 100% 6/6 [04:02<00:00, 40.46s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (valid): 100% 6/6 [04:02<00:00, 40.41s/it, loss=0.233]\n",
            "\n",
            "5/10 * Epoch (test):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "5/10 * Epoch (test):   0% 0/6 [00:39<?, ?it/s, loss=0.265]\u001b[A\n",
            "5/10 * Epoch (test):  17% 1/6 [00:39<03:19, 39.88s/it, loss=0.265]\u001b[A\n",
            "5/10 * Epoch (test):  17% 1/6 [01:19<03:19, 39.88s/it, loss=0.247]\u001b[A\n",
            "5/10 * Epoch (test):  33% 2/6 [01:20<02:39, 39.95s/it, loss=0.247]\u001b[A\n",
            "5/10 * Epoch (test):  33% 2/6 [02:00<02:39, 39.95s/it, loss=0.247]\u001b[A\n",
            "5/10 * Epoch (test):  50% 3/6 [02:00<02:00, 40.13s/it, loss=0.247]\u001b[A\n",
            "5/10 * Epoch (test):  50% 3/6 [02:40<02:00, 40.13s/it, loss=0.226]\u001b[A\n",
            "5/10 * Epoch (test):  67% 4/6 [02:40<01:20, 40.16s/it, loss=0.226]\u001b[A\n",
            "5/10 * Epoch (test):  67% 4/6 [03:21<01:20, 40.16s/it, loss=0.248]\u001b[A\n",
            "5/10 * Epoch (test):  83% 5/6 [03:21<00:40, 40.20s/it, loss=0.248]\u001b[A\n",
            "5/10 * Epoch (test):  83% 5/6 [04:01<00:40, 40.20s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (test): 100% 6/6 [04:01<00:00, 40.15s/it, loss=0.233]\u001b[A\n",
            "5/10 * Epoch (test): 100% 6/6 [04:01<00:00, 40.19s/it, loss=0.233]\n",
            "[2020-05-27 14:35:34,965] \n",
            "5/10 * Epoch 5 (_base): lr=0.0010 | momentum=0.9000\n",
            "5/10 * Epoch 5 (train): loss=0.2285\n",
            "5/10 * Epoch 5 (valid): loss=0.2319\n",
            "5/10 * Epoch 5 (test): loss=0.2442\n",
            "[2020-05-27 14:35:34,965] \n",
            "5/10 * Epoch 5 (_base): lr=0.0010 | momentum=0.9000\n",
            "5/10 * Epoch 5 (train): loss=0.2285\n",
            "5/10 * Epoch 5 (valid): loss=0.2319\n",
            "5/10 * Epoch 5 (test): loss=0.2442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:metrics_logger:\n",
            "5/10 * Epoch 5 (_base): lr=0.0010 | momentum=0.9000\n",
            "5/10 * Epoch 5 (train): loss=0.2285\n",
            "5/10 * Epoch 5 (valid): loss=0.2319\n",
            "5/10 * Epoch 5 (test): loss=0.2442\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "6/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "6/10 * Epoch (train):   0% 0/96 [00:39<?, ?it/s, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):   1% 1/96 [00:39<1:02:21, 39.38s/it, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):   1% 1/96 [01:19<1:02:21, 39.38s/it, loss=0.226]\u001b[A\n",
            "6/10 * Epoch (train):   2% 2/96 [01:19<1:02:02, 39.61s/it, loss=0.226]\u001b[A\n",
            "6/10 * Epoch (train):   2% 2/96 [01:59<1:02:02, 39.61s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (train):   3% 3/96 [01:59<1:01:23, 39.61s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (train):   3% 3/96 [02:38<1:01:23, 39.61s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (train):   4% 4/96 [02:38<1:00:45, 39.62s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (train):   4% 4/96 [03:19<1:00:45, 39.62s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):   5% 5/96 [03:19<1:00:26, 39.85s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):   5% 5/96 [03:59<1:00:26, 39.85s/it, loss=0.234]\u001b[A\n",
            "6/10 * Epoch (train):   6% 6/96 [03:59<59:49, 39.88s/it, loss=0.234]  \u001b[A\n",
            "6/10 * Epoch (train):   6% 6/96 [04:39<59:49, 39.88s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):   7% 7/96 [04:39<59:10, 39.89s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):   7% 7/96 [05:18<59:10, 39.89s/it, loss=0.220]\u001b[A\n",
            "6/10 * Epoch (train):   8% 8/96 [05:18<58:24, 39.82s/it, loss=0.220]\u001b[A\n",
            "6/10 * Epoch (train):   8% 8/96 [05:58<58:24, 39.82s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):   9% 9/96 [05:58<57:46, 39.84s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):   9% 9/96 [06:38<57:46, 39.84s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  10% 10/96 [06:38<57:04, 39.82s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  10% 10/96 [07:18<57:04, 39.82s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  11% 11/96 [07:18<56:39, 39.99s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  11% 11/96 [07:58<56:39, 39.99s/it, loss=0.221]\u001b[A\n",
            "6/10 * Epoch (train):  12% 12/96 [07:58<55:57, 39.97s/it, loss=0.221]\u001b[A\n",
            "6/10 * Epoch (train):  12% 12/96 [08:39<55:57, 39.97s/it, loss=0.243]\u001b[A\n",
            "6/10 * Epoch (train):  14% 13/96 [08:39<55:28, 40.10s/it, loss=0.243]\u001b[A\n",
            "6/10 * Epoch (train):  14% 13/96 [09:18<55:28, 40.10s/it, loss=0.215]\u001b[A\n",
            "6/10 * Epoch (train):  15% 14/96 [09:18<54:39, 39.99s/it, loss=0.215]\u001b[A\n",
            "6/10 * Epoch (train):  15% 14/96 [09:58<54:39, 39.99s/it, loss=0.218]\u001b[A\n",
            "6/10 * Epoch (train):  16% 15/96 [09:58<53:58, 39.98s/it, loss=0.218]\u001b[A\n",
            "6/10 * Epoch (train):  16% 15/96 [10:38<53:58, 39.98s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  17% 16/96 [10:38<53:13, 39.91s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  17% 16/96 [11:18<53:13, 39.91s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (train):  18% 17/96 [11:18<52:30, 39.88s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (train):  18% 17/96 [11:58<52:30, 39.88s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  19% 18/96 [11:58<51:57, 39.97s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  19% 18/96 [12:38<51:57, 39.97s/it, loss=0.218]\u001b[A\n",
            "6/10 * Epoch (train):  20% 19/96 [12:38<51:11, 39.89s/it, loss=0.218]\u001b[A\n",
            "6/10 * Epoch (train):  20% 19/96 [13:17<51:11, 39.89s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  21% 20/96 [13:17<50:27, 39.84s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  21% 20/96 [13:57<50:27, 39.84s/it, loss=0.209]\u001b[A\n",
            "6/10 * Epoch (train):  22% 21/96 [13:57<49:51, 39.88s/it, loss=0.209]\u001b[A\n",
            "6/10 * Epoch (train):  22% 21/96 [14:38<49:51, 39.88s/it, loss=0.215]\u001b[A\n",
            "6/10 * Epoch (train):  23% 22/96 [14:38<49:21, 40.02s/it, loss=0.215]\u001b[A\n",
            "6/10 * Epoch (train):  23% 22/96 [15:18<49:21, 40.02s/it, loss=0.239]\u001b[A\n",
            "6/10 * Epoch (train):  24% 23/96 [15:18<48:43, 40.05s/it, loss=0.239]\u001b[A\n",
            "6/10 * Epoch (train):  24% 23/96 [15:58<48:43, 40.05s/it, loss=0.234]\u001b[A\n",
            "6/10 * Epoch (train):  25% 24/96 [15:58<48:04, 40.06s/it, loss=0.234]\u001b[A\n",
            "6/10 * Epoch (train):  25% 24/96 [16:38<48:04, 40.06s/it, loss=0.241]\u001b[A\n",
            "6/10 * Epoch (train):  26% 25/96 [16:38<47:19, 39.99s/it, loss=0.241]\u001b[A\n",
            "6/10 * Epoch (train):  26% 25/96 [17:18<47:19, 39.99s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  27% 26/96 [17:18<46:45, 40.07s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  27% 26/96 [17:57<46:45, 40.07s/it, loss=0.212]\u001b[A\n",
            "6/10 * Epoch (train):  28% 27/96 [17:57<45:52, 39.89s/it, loss=0.212]\u001b[A\n",
            "6/10 * Epoch (train):  28% 27/96 [18:37<45:52, 39.89s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  29% 28/96 [18:37<45:12, 39.88s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  29% 28/96 [19:17<45:12, 39.88s/it, loss=0.234]\u001b[A\n",
            "6/10 * Epoch (train):  30% 29/96 [19:17<44:28, 39.83s/it, loss=0.234]\u001b[A\n",
            "6/10 * Epoch (train):  30% 29/96 [19:57<44:28, 39.83s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  31% 30/96 [19:57<43:49, 39.84s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  31% 30/96 [20:37<43:49, 39.84s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  32% 31/96 [20:37<43:15, 39.93s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  32% 31/96 [21:16<43:15, 39.93s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):  33% 32/96 [21:16<42:23, 39.75s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):  33% 32/96 [21:57<42:23, 39.75s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):  34% 33/96 [21:57<41:55, 39.92s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):  34% 33/96 [22:37<41:55, 39.92s/it, loss=0.246]\u001b[A\n",
            "6/10 * Epoch (train):  35% 34/96 [22:37<41:14, 39.91s/it, loss=0.246]\u001b[A\n",
            "6/10 * Epoch (train):  35% 34/96 [23:17<41:14, 39.91s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  36% 35/96 [23:17<40:52, 40.20s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  36% 35/96 [23:58<40:52, 40.20s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):  38% 36/96 [23:58<40:13, 40.23s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):  38% 36/96 [24:37<40:13, 40.23s/it, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):  39% 37/96 [24:37<39:10, 39.84s/it, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):  39% 37/96 [25:17<39:10, 39.84s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):  40% 38/96 [25:17<38:34, 39.91s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):  40% 38/96 [25:57<38:34, 39.91s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  41% 39/96 [25:57<38:02, 40.04s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  41% 39/96 [26:37<38:02, 40.04s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  42% 40/96 [26:37<37:26, 40.12s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  42% 40/96 [27:17<37:26, 40.12s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  43% 41/96 [27:17<36:38, 39.98s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  43% 41/96 [27:58<36:38, 39.98s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  44% 42/96 [27:58<36:19, 40.37s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  44% 42/96 [28:38<36:19, 40.37s/it, loss=0.254]\u001b[A\n",
            "6/10 * Epoch (train):  45% 43/96 [28:38<35:35, 40.30s/it, loss=0.254]\u001b[A\n",
            "6/10 * Epoch (train):  45% 43/96 [29:19<35:35, 40.30s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):  46% 44/96 [29:19<34:56, 40.32s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):  46% 44/96 [29:59<34:56, 40.32s/it, loss=0.211]\u001b[A\n",
            "6/10 * Epoch (train):  47% 45/96 [29:59<34:18, 40.35s/it, loss=0.211]\u001b[A\n",
            "6/10 * Epoch (train):  47% 45/96 [30:40<34:18, 40.35s/it, loss=0.242]\u001b[A\n",
            "6/10 * Epoch (train):  48% 46/96 [30:40<33:39, 40.39s/it, loss=0.242]\u001b[A\n",
            "6/10 * Epoch (train):  48% 46/96 [31:20<33:39, 40.39s/it, loss=0.227]\u001b[A\n",
            "6/10 * Epoch (train):  49% 47/96 [31:20<32:58, 40.38s/it, loss=0.227]\u001b[A\n",
            "6/10 * Epoch (train):  49% 47/96 [32:00<32:58, 40.38s/it, loss=0.226]\u001b[A\n",
            "6/10 * Epoch (train):  50% 48/96 [32:00<32:11, 40.23s/it, loss=0.226]\u001b[A\n",
            "6/10 * Epoch (train):  50% 48/96 [32:40<32:11, 40.23s/it, loss=0.218]\u001b[A\n",
            "6/10 * Epoch (train):  51% 49/96 [32:40<31:32, 40.27s/it, loss=0.218]\u001b[A\n",
            "6/10 * Epoch (train):  51% 49/96 [33:20<31:32, 40.27s/it, loss=0.240]\u001b[A\n",
            "6/10 * Epoch (train):  52% 50/96 [33:20<30:42, 40.06s/it, loss=0.240]\u001b[A\n",
            "6/10 * Epoch (train):  52% 50/96 [34:00<30:42, 40.06s/it, loss=0.236]\u001b[A\n",
            "6/10 * Epoch (train):  53% 51/96 [34:00<30:03, 40.09s/it, loss=0.236]\u001b[A\n",
            "6/10 * Epoch (train):  53% 51/96 [34:40<30:03, 40.09s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  54% 52/96 [34:40<29:25, 40.12s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  54% 52/96 [35:20<29:25, 40.12s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  55% 53/96 [35:20<28:37, 39.95s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  55% 53/96 [36:00<28:37, 39.95s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  56% 54/96 [36:00<28:00, 40.01s/it, loss=0.228]\u001b[A\n",
            "6/10 * Epoch (train):  56% 54/96 [36:41<28:00, 40.01s/it, loss=0.245]\u001b[A\n",
            "6/10 * Epoch (train):  57% 55/96 [36:41<27:34, 40.36s/it, loss=0.245]\u001b[A\n",
            "6/10 * Epoch (train):  57% 55/96 [37:22<27:34, 40.36s/it, loss=0.234]\u001b[A\n",
            "6/10 * Epoch (train):  58% 56/96 [37:22<26:55, 40.39s/it, loss=0.234]\u001b[A\n",
            "6/10 * Epoch (train):  58% 56/96 [38:02<26:55, 40.39s/it, loss=0.235]\u001b[A\n",
            "6/10 * Epoch (train):  59% 57/96 [38:02<26:15, 40.40s/it, loss=0.235]\u001b[A\n",
            "6/10 * Epoch (train):  59% 57/96 [38:43<26:15, 40.40s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  60% 58/96 [38:43<25:37, 40.46s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  60% 58/96 [39:23<25:37, 40.46s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  61% 59/96 [39:23<24:55, 40.41s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  61% 59/96 [40:03<24:55, 40.41s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  62% 60/96 [40:03<24:14, 40.40s/it, loss=0.230]\u001b[A\n",
            "6/10 * Epoch (train):  62% 60/96 [40:44<24:14, 40.40s/it, loss=0.221]\u001b[A\n",
            "6/10 * Epoch (train):  64% 61/96 [40:44<23:33, 40.38s/it, loss=0.221]\u001b[A\n",
            "6/10 * Epoch (train):  64% 61/96 [41:24<23:33, 40.38s/it, loss=0.240]\u001b[A\n",
            "6/10 * Epoch (train):  65% 62/96 [41:24<22:52, 40.37s/it, loss=0.240]\u001b[A\n",
            "6/10 * Epoch (train):  65% 62/96 [42:04<22:52, 40.37s/it, loss=0.227]\u001b[A\n",
            "6/10 * Epoch (train):  66% 63/96 [42:04<22:05, 40.16s/it, loss=0.227]\u001b[A\n",
            "6/10 * Epoch (train):  66% 63/96 [42:44<22:05, 40.16s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  67% 64/96 [42:44<21:23, 40.11s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  67% 64/96 [43:24<21:23, 40.11s/it, loss=0.216]\u001b[A\n",
            "6/10 * Epoch (train):  68% 65/96 [43:24<20:48, 40.26s/it, loss=0.216]\u001b[A\n",
            "6/10 * Epoch (train):  68% 65/96 [44:05<20:48, 40.26s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):  69% 66/96 [44:05<20:08, 40.29s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (train):  69% 66/96 [44:45<20:08, 40.29s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  70% 67/96 [44:45<19:28, 40.28s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  70% 67/96 [45:25<19:28, 40.28s/it, loss=0.222]\u001b[A\n",
            "6/10 * Epoch (train):  71% 68/96 [45:25<18:44, 40.15s/it, loss=0.222]\u001b[A\n",
            "6/10 * Epoch (train):  71% 68/96 [46:05<18:44, 40.15s/it, loss=0.246]\u001b[A\n",
            "6/10 * Epoch (train):  72% 69/96 [46:05<18:08, 40.32s/it, loss=0.246]\u001b[A\n",
            "6/10 * Epoch (train):  72% 69/96 [46:46<18:08, 40.32s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  73% 70/96 [46:46<17:26, 40.24s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  73% 70/96 [47:26<17:26, 40.24s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  74% 71/96 [47:26<16:45, 40.22s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  74% 71/96 [48:06<16:45, 40.22s/it, loss=0.220]\u001b[A\n",
            "6/10 * Epoch (train):  75% 72/96 [48:06<16:05, 40.23s/it, loss=0.220]\u001b[A\n",
            "6/10 * Epoch (train):  75% 72/96 [48:46<16:05, 40.23s/it, loss=0.241]\u001b[A\n",
            "6/10 * Epoch (train):  76% 73/96 [48:46<15:24, 40.17s/it, loss=0.241]\u001b[A\n",
            "6/10 * Epoch (train):  76% 73/96 [49:26<15:24, 40.17s/it, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):  77% 74/96 [49:26<14:44, 40.20s/it, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):  77% 74/96 [50:07<14:44, 40.20s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  78% 75/96 [50:07<14:05, 40.28s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  78% 75/96 [50:47<14:05, 40.28s/it, loss=0.207]\u001b[A\n",
            "6/10 * Epoch (train):  79% 76/96 [50:47<13:24, 40.23s/it, loss=0.207]\u001b[A\n",
            "6/10 * Epoch (train):  79% 76/96 [51:27<13:24, 40.23s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  80% 77/96 [51:27<12:46, 40.35s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  80% 77/96 [52:08<12:46, 40.35s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  81% 78/96 [52:08<12:06, 40.35s/it, loss=0.231]\u001b[A\n",
            "6/10 * Epoch (train):  81% 78/96 [52:49<12:06, 40.35s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):  82% 79/96 [52:49<11:28, 40.50s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):  82% 79/96 [53:29<11:28, 40.50s/it, loss=0.238]\u001b[A\n",
            "6/10 * Epoch (train):  83% 80/96 [53:29<10:46, 40.43s/it, loss=0.238]\u001b[A\n",
            "6/10 * Epoch (train):  83% 80/96 [54:09<10:46, 40.43s/it, loss=0.238]\u001b[A\n",
            "6/10 * Epoch (train):  84% 81/96 [54:09<10:06, 40.46s/it, loss=0.238]\u001b[A\n",
            "6/10 * Epoch (train):  84% 81/96 [54:49<10:06, 40.46s/it, loss=0.222]\u001b[A\n",
            "6/10 * Epoch (train):  85% 82/96 [54:49<09:24, 40.31s/it, loss=0.222]\u001b[A\n",
            "6/10 * Epoch (train):  85% 82/96 [55:30<09:24, 40.31s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  86% 83/96 [55:30<08:45, 40.42s/it, loss=0.229]\u001b[A\n",
            "6/10 * Epoch (train):  86% 83/96 [56:11<08:45, 40.42s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):  88% 84/96 [56:11<08:05, 40.47s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train):  88% 84/96 [56:51<08:05, 40.47s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):  89% 85/96 [56:51<07:25, 40.49s/it, loss=0.219]\u001b[A\n",
            "6/10 * Epoch (train):  89% 85/96 [57:31<07:25, 40.49s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  90% 86/96 [57:31<06:43, 40.39s/it, loss=0.223]\u001b[A\n",
            "6/10 * Epoch (train):  90% 86/96 [58:11<06:43, 40.39s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  91% 87/96 [58:11<06:01, 40.18s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (train):  91% 87/96 [58:51<06:01, 40.18s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  92% 88/96 [58:51<05:20, 40.07s/it, loss=0.217]\u001b[A\n",
            "6/10 * Epoch (train):  92% 88/96 [59:31<05:20, 40.07s/it, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):  93% 89/96 [59:31<04:40, 40.07s/it, loss=0.225]\u001b[A\n",
            "6/10 * Epoch (train):  93% 89/96 [1:00:11<04:40, 40.07s/it, loss=0.236]\u001b[A\n",
            "6/10 * Epoch (train):  94% 90/96 [1:00:11<04:00, 40.10s/it, loss=0.236]\u001b[A\n",
            "6/10 * Epoch (train):  94% 90/96 [1:00:51<04:00, 40.10s/it, loss=0.220]\u001b[A\n",
            "6/10 * Epoch (train):  95% 91/96 [1:00:51<03:19, 40.00s/it, loss=0.220]\u001b[A\n",
            "6/10 * Epoch (train):  95% 91/96 [1:01:31<03:19, 40.00s/it, loss=0.210]\u001b[A\n",
            "6/10 * Epoch (train):  96% 92/96 [1:01:31<02:40, 40.14s/it, loss=0.210]\u001b[A\n",
            "6/10 * Epoch (train):  96% 92/96 [1:02:11<02:40, 40.14s/it, loss=0.251]\u001b[A\n",
            "6/10 * Epoch (train):  97% 93/96 [1:02:11<02:00, 40.14s/it, loss=0.251]\u001b[A\n",
            "6/10 * Epoch (train):  97% 93/96 [1:02:52<02:00, 40.14s/it, loss=0.239]\u001b[A\n",
            "6/10 * Epoch (train):  98% 94/96 [1:02:52<01:20, 40.34s/it, loss=0.239]\u001b[A\n",
            "6/10 * Epoch (train):  98% 94/96 [1:03:33<01:20, 40.34s/it, loss=0.222]\u001b[A\n",
            "6/10 * Epoch (train):  99% 95/96 [1:03:33<00:40, 40.34s/it, loss=0.222]\u001b[A\n",
            "6/10 * Epoch (train):  99% 95/96 [1:04:14<00:40, 40.34s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train): 100% 96/96 [1:04:14<00:00, 40.56s/it, loss=0.237]\u001b[A\n",
            "6/10 * Epoch (train): 100% 96/96 [1:04:14<00:00, 40.15s/it, loss=0.237]\n",
            "\n",
            "6/10 * Epoch (valid):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "6/10 * Epoch (valid):   0% 0/6 [00:39<?, ?it/s, loss=0.236]\u001b[A\n",
            "6/10 * Epoch (valid):  17% 1/6 [00:39<03:19, 39.94s/it, loss=0.236]\u001b[A\n",
            "6/10 * Epoch (valid):  17% 1/6 [01:20<03:19, 39.94s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (valid):  33% 2/6 [01:20<02:40, 40.21s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (valid):  33% 2/6 [02:01<02:40, 40.21s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (valid):  50% 3/6 [02:01<02:00, 40.24s/it, loss=0.224]\u001b[A\n",
            "6/10 * Epoch (valid):  50% 3/6 [02:41<02:00, 40.24s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (valid):  67% 4/6 [02:41<01:20, 40.27s/it, loss=0.232]\u001b[A\n",
            "6/10 * Epoch (valid):  67% 4/6 [03:21<01:20, 40.27s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (valid):  83% 5/6 [03:21<00:40, 40.35s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (valid):  83% 5/6 [04:02<00:40, 40.35s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (valid): 100% 6/6 [04:02<00:00, 40.55s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (valid): 100% 6/6 [04:03<00:00, 40.50s/it, loss=0.233]\n",
            "\n",
            "6/10 * Epoch (test):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "6/10 * Epoch (test):   0% 0/6 [00:40<?, ?it/s, loss=0.264]\u001b[A\n",
            "6/10 * Epoch (test):  17% 1/6 [00:40<03:20, 40.15s/it, loss=0.264]\u001b[A\n",
            "6/10 * Epoch (test):  17% 1/6 [01:20<03:20, 40.15s/it, loss=0.247]\u001b[A\n",
            "6/10 * Epoch (test):  33% 2/6 [01:20<02:41, 40.25s/it, loss=0.247]\u001b[A\n",
            "6/10 * Epoch (test):  33% 2/6 [02:01<02:41, 40.25s/it, loss=0.246]\u001b[A\n",
            "6/10 * Epoch (test):  50% 3/6 [02:01<02:01, 40.46s/it, loss=0.246]\u001b[A\n",
            "6/10 * Epoch (test):  50% 3/6 [02:42<02:01, 40.46s/it, loss=0.226]\u001b[A\n",
            "6/10 * Epoch (test):  67% 4/6 [02:42<01:21, 40.54s/it, loss=0.226]\u001b[A\n",
            "6/10 * Epoch (test):  67% 4/6 [03:23<01:21, 40.54s/it, loss=0.247]\u001b[A\n",
            "6/10 * Epoch (test):  83% 5/6 [03:23<00:40, 40.62s/it, loss=0.247]\u001b[A\n",
            "6/10 * Epoch (test):  83% 5/6 [04:03<00:40, 40.62s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (test): 100% 6/6 [04:03<00:00, 40.57s/it, loss=0.233]\u001b[A\n",
            "6/10 * Epoch (test): 100% 6/6 [04:03<00:00, 40.60s/it, loss=0.233]\n",
            "[2020-05-27 15:47:55,828] \n",
            "6/10 * Epoch 6 (_base): lr=0.0010 | momentum=0.9000\n",
            "6/10 * Epoch 6 (train): loss=0.2283\n",
            "6/10 * Epoch 6 (valid): loss=0.2316\n",
            "6/10 * Epoch 6 (test): loss=0.2438\n",
            "[2020-05-27 15:47:55,828] \n",
            "6/10 * Epoch 6 (_base): lr=0.0010 | momentum=0.9000\n",
            "6/10 * Epoch 6 (train): loss=0.2283\n",
            "6/10 * Epoch 6 (valid): loss=0.2316\n",
            "6/10 * Epoch 6 (test): loss=0.2438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:metrics_logger:\n",
            "6/10 * Epoch 6 (_base): lr=0.0010 | momentum=0.9000\n",
            "6/10 * Epoch 6 (train): loss=0.2283\n",
            "6/10 * Epoch 6 (valid): loss=0.2316\n",
            "6/10 * Epoch 6 (test): loss=0.2438\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "7/10 * Epoch (train):   0% 0/96 [00:39<?, ?it/s, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):   1% 1/96 [00:39<1:03:03, 39.83s/it, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):   1% 1/96 [01:20<1:03:03, 39.83s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):   2% 2/96 [01:20<1:02:42, 40.02s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):   2% 2/96 [02:00<1:02:42, 40.02s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):   3% 3/96 [02:00<1:02:01, 40.01s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):   3% 3/96 [02:40<1:02:01, 40.01s/it, loss=0.222]\u001b[A\n",
            "7/10 * Epoch (train):   4% 4/96 [02:40<1:01:26, 40.07s/it, loss=0.222]\u001b[A\n",
            "7/10 * Epoch (train):   4% 4/96 [03:21<1:01:26, 40.07s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):   5% 5/96 [03:21<1:00:59, 40.22s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):   5% 5/96 [04:01<1:00:59, 40.22s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):   6% 6/96 [04:01<1:00:28, 40.31s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):   6% 6/96 [04:41<1:00:28, 40.31s/it, loss=0.237]\u001b[A\n",
            "7/10 * Epoch (train):   7% 7/96 [04:41<59:49, 40.33s/it, loss=0.237]  \u001b[A\n",
            "7/10 * Epoch (train):   7% 7/96 [05:21<59:49, 40.33s/it, loss=0.221]\u001b[A\n",
            "7/10 * Epoch (train):   8% 8/96 [05:21<58:58, 40.21s/it, loss=0.221]\u001b[A\n",
            "7/10 * Epoch (train):   8% 8/96 [06:01<58:58, 40.21s/it, loss=0.221]\u001b[A\n",
            "7/10 * Epoch (train):   9% 9/96 [06:01<58:12, 40.14s/it, loss=0.221]\u001b[A\n",
            "7/10 * Epoch (train):   9% 9/96 [06:42<58:12, 40.14s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  10% 10/96 [06:42<57:36, 40.20s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  10% 10/96 [07:22<57:36, 40.20s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  11% 11/96 [07:22<57:03, 40.27s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  11% 11/96 [08:02<57:03, 40.27s/it, loss=0.220]\u001b[A\n",
            "7/10 * Epoch (train):  12% 12/96 [08:02<56:24, 40.29s/it, loss=0.220]\u001b[A\n",
            "7/10 * Epoch (train):  12% 12/96 [08:43<56:24, 40.29s/it, loss=0.241]\u001b[A\n",
            "7/10 * Epoch (train):  14% 13/96 [08:43<55:50, 40.36s/it, loss=0.241]\u001b[A\n",
            "7/10 * Epoch (train):  14% 13/96 [09:23<55:50, 40.36s/it, loss=0.214]\u001b[A\n",
            "7/10 * Epoch (train):  15% 14/96 [09:23<54:56, 40.20s/it, loss=0.214]\u001b[A\n",
            "7/10 * Epoch (train):  15% 14/96 [10:03<54:56, 40.20s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  16% 15/96 [10:03<54:13, 40.17s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  16% 15/96 [10:43<54:13, 40.17s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  17% 16/96 [10:43<53:25, 40.07s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  17% 16/96 [11:23<53:25, 40.07s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  18% 17/96 [11:23<52:40, 40.01s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  18% 17/96 [12:03<52:40, 40.01s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  19% 18/96 [12:03<52:06, 40.09s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  19% 18/96 [12:43<52:06, 40.09s/it, loss=0.215]\u001b[A\n",
            "7/10 * Epoch (train):  20% 19/96 [12:43<51:16, 39.96s/it, loss=0.215]\u001b[A\n",
            "7/10 * Epoch (train):  20% 19/96 [13:22<51:16, 39.96s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  21% 20/96 [13:22<50:35, 39.94s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  21% 20/96 [14:02<50:35, 39.94s/it, loss=0.208]\u001b[A\n",
            "7/10 * Epoch (train):  22% 21/96 [14:02<49:54, 39.92s/it, loss=0.208]\u001b[A\n",
            "7/10 * Epoch (train):  22% 21/96 [14:43<49:54, 39.92s/it, loss=0.215]\u001b[A\n",
            "7/10 * Epoch (train):  23% 22/96 [14:43<49:28, 40.12s/it, loss=0.215]\u001b[A\n",
            "7/10 * Epoch (train):  23% 22/96 [15:23<49:28, 40.12s/it, loss=0.239]\u001b[A\n",
            "7/10 * Epoch (train):  24% 23/96 [15:23<48:49, 40.14s/it, loss=0.239]\u001b[A\n",
            "7/10 * Epoch (train):  24% 23/96 [16:04<48:49, 40.14s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  25% 24/96 [16:04<48:17, 40.24s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  25% 24/96 [16:44<48:17, 40.24s/it, loss=0.240]\u001b[A\n",
            "7/10 * Epoch (train):  26% 25/96 [16:44<47:35, 40.21s/it, loss=0.240]\u001b[A\n",
            "7/10 * Epoch (train):  26% 25/96 [17:24<47:35, 40.21s/it, loss=0.228]\u001b[A\n",
            "7/10 * Epoch (train):  27% 26/96 [17:25<47:06, 40.38s/it, loss=0.228]\u001b[A\n",
            "7/10 * Epoch (train):  27% 26/96 [18:04<47:06, 40.38s/it, loss=0.212]\u001b[A\n",
            "7/10 * Epoch (train):  28% 27/96 [18:04<46:14, 40.21s/it, loss=0.212]\u001b[A\n",
            "7/10 * Epoch (train):  28% 27/96 [18:45<46:14, 40.21s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):  29% 28/96 [18:45<45:36, 40.24s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):  29% 28/96 [19:25<45:36, 40.24s/it, loss=0.235]\u001b[A\n",
            "7/10 * Epoch (train):  30% 29/96 [19:25<44:54, 40.22s/it, loss=0.235]\u001b[A\n",
            "7/10 * Epoch (train):  30% 29/96 [20:05<44:54, 40.22s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  31% 30/96 [20:05<44:12, 40.20s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  31% 30/96 [20:46<44:12, 40.20s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (train):  32% 31/96 [20:46<43:41, 40.33s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (train):  32% 31/96 [21:25<43:41, 40.33s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  33% 32/96 [21:25<42:47, 40.12s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  33% 32/96 [22:06<42:47, 40.12s/it, loss=0.216]\u001b[A\n",
            "7/10 * Epoch (train):  34% 33/96 [22:06<42:16, 40.27s/it, loss=0.216]\u001b[A\n",
            "7/10 * Epoch (train):  34% 33/96 [22:46<42:16, 40.27s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (train):  35% 34/96 [22:46<41:36, 40.27s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (train):  35% 34/96 [23:27<41:36, 40.27s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (train):  36% 35/96 [23:27<41:10, 40.51s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (train):  36% 35/96 [24:08<41:10, 40.51s/it, loss=0.236]\u001b[A\n",
            "7/10 * Epoch (train):  38% 36/96 [24:08<40:32, 40.54s/it, loss=0.236]\u001b[A\n",
            "7/10 * Epoch (train):  38% 36/96 [24:47<40:32, 40.54s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  39% 37/96 [24:47<39:30, 40.18s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  39% 37/96 [25:28<39:30, 40.18s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  40% 38/96 [25:28<38:56, 40.28s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  40% 38/96 [26:08<38:56, 40.28s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  41% 39/96 [26:08<38:21, 40.37s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  41% 39/96 [26:49<38:21, 40.37s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  42% 40/96 [26:49<37:44, 40.43s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  42% 40/96 [27:29<37:44, 40.43s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  43% 41/96 [27:29<36:59, 40.35s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  43% 41/96 [28:11<36:59, 40.35s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  44% 42/96 [28:11<36:38, 40.71s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  44% 42/96 [28:51<36:38, 40.71s/it, loss=0.251]\u001b[A\n",
            "7/10 * Epoch (train):  45% 43/96 [28:51<35:54, 40.64s/it, loss=0.251]\u001b[A\n",
            "7/10 * Epoch (train):  45% 43/96 [29:32<35:54, 40.64s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):  46% 44/96 [29:32<35:18, 40.74s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):  46% 44/96 [30:13<35:18, 40.74s/it, loss=0.212]\u001b[A\n",
            "7/10 * Epoch (train):  47% 45/96 [30:13<34:39, 40.77s/it, loss=0.212]\u001b[A\n",
            "7/10 * Epoch (train):  47% 45/96 [30:54<34:39, 40.77s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  48% 46/96 [30:54<33:57, 40.76s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  48% 46/96 [31:34<33:57, 40.76s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  49% 47/96 [31:34<33:17, 40.77s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  49% 47/96 [32:15<33:17, 40.77s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  50% 48/96 [32:15<32:28, 40.58s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  50% 48/96 [32:55<32:28, 40.58s/it, loss=0.217]\u001b[A\n",
            "7/10 * Epoch (train):  51% 49/96 [32:55<31:50, 40.64s/it, loss=0.217]\u001b[A\n",
            "7/10 * Epoch (train):  51% 49/96 [33:35<31:50, 40.64s/it, loss=0.235]\u001b[A\n",
            "7/10 * Epoch (train):  52% 50/96 [33:35<31:01, 40.46s/it, loss=0.235]\u001b[A\n",
            "7/10 * Epoch (train):  52% 50/96 [34:16<31:01, 40.46s/it, loss=0.237]\u001b[A\n",
            "7/10 * Epoch (train):  53% 51/96 [34:16<30:20, 40.46s/it, loss=0.237]\u001b[A\n",
            "7/10 * Epoch (train):  53% 51/96 [34:56<30:20, 40.46s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):  54% 52/96 [34:56<29:42, 40.51s/it, loss=0.231]\u001b[A\n",
            "7/10 * Epoch (train):  54% 52/96 [35:36<29:42, 40.51s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  55% 53/96 [35:36<28:54, 40.34s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  55% 53/96 [36:17<28:54, 40.34s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  56% 54/96 [36:17<28:17, 40.41s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  56% 54/96 [36:58<28:17, 40.41s/it, loss=0.245]\u001b[A\n",
            "7/10 * Epoch (train):  57% 55/96 [36:58<27:45, 40.63s/it, loss=0.245]\u001b[A\n",
            "7/10 * Epoch (train):  57% 55/96 [37:39<27:45, 40.63s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  58% 56/96 [37:39<27:06, 40.66s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  58% 56/96 [38:19<27:06, 40.66s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  59% 57/96 [38:19<26:25, 40.65s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  59% 57/96 [39:00<26:25, 40.65s/it, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):  60% 58/96 [39:00<25:46, 40.71s/it, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):  60% 58/96 [39:41<25:46, 40.71s/it, loss=0.228]\u001b[A\n",
            "7/10 * Epoch (train):  61% 59/96 [39:41<25:02, 40.62s/it, loss=0.228]\u001b[A\n",
            "7/10 * Epoch (train):  61% 59/96 [40:21<25:02, 40.62s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  62% 60/96 [40:21<24:19, 40.55s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  62% 60/96 [41:02<24:19, 40.55s/it, loss=0.222]\u001b[A\n",
            "7/10 * Epoch (train):  64% 61/96 [41:02<23:40, 40.58s/it, loss=0.222]\u001b[A\n",
            "7/10 * Epoch (train):  64% 61/96 [41:42<23:40, 40.58s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  65% 62/96 [41:42<22:59, 40.58s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  65% 62/96 [42:22<22:59, 40.58s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  66% 63/96 [42:22<22:11, 40.34s/it, loss=0.227]\u001b[A\n",
            "7/10 * Epoch (train):  66% 63/96 [43:02<22:11, 40.34s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  67% 64/96 [43:02<21:30, 40.32s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (train):  67% 64/96 [43:43<21:30, 40.32s/it, loss=0.215]\u001b[A\n",
            "7/10 * Epoch (train):  68% 65/96 [43:43<20:53, 40.45s/it, loss=0.215]\u001b[A\n",
            "7/10 * Epoch (train):  68% 65/96 [44:24<20:53, 40.45s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  69% 66/96 [44:24<20:14, 40.47s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  69% 66/96 [45:04<20:14, 40.47s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  70% 67/96 [45:04<19:32, 40.44s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  70% 67/96 [45:44<19:32, 40.44s/it, loss=0.219]\u001b[A\n",
            "7/10 * Epoch (train):  71% 68/96 [45:44<18:50, 40.39s/it, loss=0.219]\u001b[A\n",
            "7/10 * Epoch (train):  71% 68/96 [46:25<18:50, 40.39s/it, loss=0.243]\u001b[A\n",
            "7/10 * Epoch (train):  72% 69/96 [46:25<18:12, 40.47s/it, loss=0.243]\u001b[A\n",
            "7/10 * Epoch (train):  72% 69/96 [47:05<18:12, 40.47s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  73% 70/96 [47:05<17:32, 40.47s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  73% 70/96 [47:46<17:32, 40.47s/it, loss=0.216]\u001b[A\n",
            "7/10 * Epoch (train):  74% 71/96 [47:46<16:50, 40.42s/it, loss=0.216]\u001b[A\n",
            "7/10 * Epoch (train):  74% 71/96 [48:26<16:50, 40.42s/it, loss=0.219]\u001b[A\n",
            "7/10 * Epoch (train):  75% 72/96 [48:26<16:10, 40.43s/it, loss=0.219]\u001b[A\n",
            "7/10 * Epoch (train):  75% 72/96 [49:06<16:10, 40.43s/it, loss=0.242]\u001b[A\n",
            "7/10 * Epoch (train):  76% 73/96 [49:06<15:29, 40.40s/it, loss=0.242]\u001b[A\n",
            "7/10 * Epoch (train):  76% 73/96 [49:47<15:29, 40.40s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  77% 74/96 [49:47<14:49, 40.44s/it, loss=0.225]\u001b[A\n",
            "7/10 * Epoch (train):  77% 74/96 [50:28<14:49, 40.44s/it, loss=0.216]\u001b[A\n",
            "7/10 * Epoch (train):  78% 75/96 [50:28<14:11, 40.54s/it, loss=0.216]\u001b[A\n",
            "7/10 * Epoch (train):  78% 75/96 [51:08<14:11, 40.54s/it, loss=0.208]\u001b[A\n",
            "7/10 * Epoch (train):  79% 76/96 [51:08<13:29, 40.49s/it, loss=0.208]\u001b[A\n",
            "7/10 * Epoch (train):  79% 76/96 [51:49<13:29, 40.49s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  80% 77/96 [51:49<12:48, 40.46s/it, loss=0.230]\u001b[A\n",
            "7/10 * Epoch (train):  80% 77/96 [52:29<12:48, 40.46s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  81% 78/96 [52:29<12:06, 40.35s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  81% 78/96 [53:09<12:06, 40.35s/it, loss=0.219]\u001b[A\n",
            "7/10 * Epoch (train):  82% 79/96 [53:09<11:26, 40.36s/it, loss=0.219]\u001b[A\n",
            "7/10 * Epoch (train):  82% 79/96 [53:49<11:26, 40.36s/it, loss=0.235]\u001b[A\n",
            "7/10 * Epoch (train):  83% 80/96 [53:49<10:43, 40.23s/it, loss=0.235]\u001b[A\n",
            "7/10 * Epoch (train):  83% 80/96 [54:29<10:43, 40.23s/it, loss=0.237]\u001b[A\n",
            "7/10 * Epoch (train):  84% 81/96 [54:29<10:03, 40.22s/it, loss=0.237]\u001b[A\n",
            "7/10 * Epoch (train):  84% 81/96 [55:09<10:03, 40.22s/it, loss=0.221]\u001b[A\n",
            "7/10 * Epoch (train):  85% 82/96 [55:09<09:20, 40.02s/it, loss=0.221]\u001b[A\n",
            "7/10 * Epoch (train):  85% 82/96 [55:49<09:20, 40.02s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  86% 83/96 [55:49<08:42, 40.18s/it, loss=0.229]\u001b[A\n",
            "7/10 * Epoch (train):  86% 83/96 [56:30<08:42, 40.18s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  88% 84/96 [56:30<08:02, 40.22s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  88% 84/96 [57:10<08:02, 40.22s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  89% 85/96 [57:10<07:22, 40.24s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  89% 85/96 [57:50<07:22, 40.24s/it, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):  90% 86/96 [57:50<06:41, 40.16s/it, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):  90% 86/96 [58:29<06:41, 40.16s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  91% 87/96 [58:29<05:59, 39.94s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (train):  91% 87/96 [59:09<05:59, 39.94s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  92% 88/96 [59:09<05:19, 39.91s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  92% 88/96 [59:49<05:19, 39.91s/it, loss=0.222]\u001b[A\n",
            "7/10 * Epoch (train):  93% 89/96 [59:49<04:39, 39.87s/it, loss=0.222]\u001b[A\n",
            "7/10 * Epoch (train):  93% 89/96 [1:00:29<04:39, 39.87s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  94% 90/96 [1:00:29<03:59, 39.88s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train):  94% 90/96 [1:01:09<03:59, 39.88s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  95% 91/96 [1:01:09<03:19, 39.85s/it, loss=0.218]\u001b[A\n",
            "7/10 * Epoch (train):  95% 91/96 [1:01:49<03:19, 39.85s/it, loss=0.209]\u001b[A\n",
            "7/10 * Epoch (train):  96% 92/96 [1:01:49<02:40, 40.02s/it, loss=0.209]\u001b[A\n",
            "7/10 * Epoch (train):  96% 92/96 [1:02:29<02:40, 40.02s/it, loss=0.251]\u001b[A\n",
            "7/10 * Epoch (train):  97% 93/96 [1:02:29<02:00, 40.06s/it, loss=0.251]\u001b[A\n",
            "7/10 * Epoch (train):  97% 93/96 [1:03:10<02:00, 40.06s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  98% 94/96 [1:03:10<01:20, 40.28s/it, loss=0.238]\u001b[A\n",
            "7/10 * Epoch (train):  98% 94/96 [1:03:50<01:20, 40.28s/it, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):  99% 95/96 [1:03:50<00:40, 40.25s/it, loss=0.223]\u001b[A\n",
            "7/10 * Epoch (train):  99% 95/96 [1:04:31<00:40, 40.25s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train): 100% 96/96 [1:04:31<00:00, 40.44s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (train): 100% 96/96 [1:04:31<00:00, 40.33s/it, loss=0.234]\n",
            "\n",
            "7/10 * Epoch (valid):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "7/10 * Epoch (valid):   0% 0/6 [00:39<?, ?it/s, loss=0.236]\u001b[A\n",
            "7/10 * Epoch (valid):  17% 1/6 [00:39<03:19, 39.87s/it, loss=0.236]\u001b[A\n",
            "7/10 * Epoch (valid):  17% 1/6 [01:20<03:19, 39.87s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (valid):  33% 2/6 [01:20<02:40, 40.08s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (valid):  33% 2/6 [02:00<02:40, 40.08s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (valid):  50% 3/6 [02:00<02:00, 40.08s/it, loss=0.224]\u001b[A\n",
            "7/10 * Epoch (valid):  50% 3/6 [02:40<02:00, 40.08s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (valid):  67% 4/6 [02:40<01:20, 40.14s/it, loss=0.232]\u001b[A\n",
            "7/10 * Epoch (valid):  67% 4/6 [03:21<01:20, 40.14s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (valid):  83% 5/6 [03:21<00:40, 40.31s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (valid):  83% 5/6 [04:02<00:40, 40.31s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (valid): 100% 6/6 [04:02<00:00, 40.46s/it, loss=0.234]\u001b[A\n",
            "7/10 * Epoch (valid): 100% 6/6 [04:02<00:00, 40.39s/it, loss=0.234]\n",
            "\n",
            "7/10 * Epoch (test):   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "7/10 * Epoch (test):   0% 0/6 [00:39<?, ?it/s, loss=0.265]\u001b[A\n",
            "7/10 * Epoch (test):  17% 1/6 [00:39<03:19, 39.99s/it, loss=0.265]\u001b[A\n",
            "7/10 * Epoch (test):  17% 1/6 [01:20<03:19, 39.99s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (test):  33% 2/6 [01:20<02:40, 40.06s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (test):  33% 2/6 [02:00<02:40, 40.06s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (test):  50% 3/6 [02:00<02:00, 40.26s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (test):  50% 3/6 [02:41<02:00, 40.26s/it, loss=0.226]\u001b[A\n",
            "7/10 * Epoch (test):  67% 4/6 [02:41<01:20, 40.31s/it, loss=0.226]\u001b[A\n",
            "7/10 * Epoch (test):  67% 4/6 [03:21<01:20, 40.31s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (test):  83% 5/6 [03:21<00:40, 40.28s/it, loss=0.247]\u001b[A\n",
            "7/10 * Epoch (test):  83% 5/6 [04:01<00:40, 40.28s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (test): 100% 6/6 [04:01<00:00, 40.21s/it, loss=0.233]\u001b[A\n",
            "7/10 * Epoch (test): 100% 6/6 [04:01<00:00, 40.27s/it, loss=0.233]\n",
            "[2020-05-27 17:00:31,330] \n",
            "7/10 * Epoch 7 (_base): lr=0.0010 | momentum=0.9000\n",
            "7/10 * Epoch 7 (train): loss=0.2276\n",
            "7/10 * Epoch 7 (valid): loss=0.2320\n",
            "7/10 * Epoch 7 (test): loss=0.2442\n",
            "[2020-05-27 17:00:31,330] \n",
            "7/10 * Epoch 7 (_base): lr=0.0010 | momentum=0.9000\n",
            "7/10 * Epoch 7 (train): loss=0.2276\n",
            "7/10 * Epoch 7 (valid): loss=0.2320\n",
            "7/10 * Epoch 7 (test): loss=0.2442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:metrics_logger:\n",
            "7/10 * Epoch 7 (_base): lr=0.0010 | momentum=0.9000\n",
            "7/10 * Epoch 7 (train): loss=0.2276\n",
            "7/10 * Epoch 7 (valid): loss=0.2320\n",
            "7/10 * Epoch 7 (test): loss=0.2442\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "8/10 * Epoch (train):   0% 0/96 [00:00<?, ?it/s]\u001b[A\n",
            "8/10 * Epoch (train):   0% 0/96 [00:40<?, ?it/s, loss=0.223]\u001b[A\n",
            "8/10 * Epoch (train):   1% 1/96 [00:40<1:03:25, 40.05s/it, loss=0.223]\u001b[A\n",
            "8/10 * Epoch (train):   1% 1/96 [01:20<1:03:25, 40.05s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):   2% 2/96 [01:20<1:02:46, 40.07s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):   2% 2/96 [01:59<1:02:46, 40.07s/it, loss=0.222]\u001b[A\n",
            "8/10 * Epoch (train):   3% 3/96 [01:59<1:01:53, 39.93s/it, loss=0.222]\u001b[A\n",
            "8/10 * Epoch (train):   3% 3/96 [02:39<1:01:53, 39.93s/it, loss=0.221]\u001b[A\n",
            "8/10 * Epoch (train):   4% 4/96 [02:39<1:01:19, 40.00s/it, loss=0.221]\u001b[A\n",
            "8/10 * Epoch (train):   4% 4/96 [03:20<1:01:19, 40.00s/it, loss=0.230]\u001b[A\n",
            "8/10 * Epoch (train):   5% 5/96 [03:20<1:00:53, 40.14s/it, loss=0.230]\u001b[A\n",
            "8/10 * Epoch (train):   5% 5/96 [04:00<1:00:53, 40.14s/it, loss=0.232]\u001b[A\n",
            "8/10 * Epoch (train):   6% 6/96 [04:00<1:00:17, 40.20s/it, loss=0.232]\u001b[A\n",
            "8/10 * Epoch (train):   6% 6/96 [04:41<1:00:17, 40.20s/it, loss=0.237]\u001b[A\n",
            "8/10 * Epoch (train):   7% 7/96 [04:41<59:40, 40.23s/it, loss=0.237]  \u001b[A\n",
            "8/10 * Epoch (train):   7% 7/96 [05:21<59:40, 40.23s/it, loss=0.220]\u001b[A\n",
            "8/10 * Epoch (train):   8% 8/96 [05:21<58:54, 40.17s/it, loss=0.220]\u001b[A\n",
            "8/10 * Epoch (train):   8% 8/96 [06:01<58:54, 40.17s/it, loss=0.219]\u001b[A\n",
            "8/10 * Epoch (train):   9% 9/96 [06:01<58:14, 40.16s/it, loss=0.219]\u001b[A\n",
            "8/10 * Epoch (train):   9% 9/96 [06:41<58:14, 40.16s/it, loss=0.223]\u001b[A\n",
            "8/10 * Epoch (train):  10% 10/96 [06:41<57:32, 40.15s/it, loss=0.223]\u001b[A\n",
            "8/10 * Epoch (train):  10% 10/96 [07:22<57:32, 40.15s/it, loss=0.224]\u001b[A\n",
            "8/10 * Epoch (train):  11% 11/96 [07:22<57:09, 40.35s/it, loss=0.224]\u001b[A\n",
            "8/10 * Epoch (train):  11% 11/96 [08:02<57:09, 40.35s/it, loss=0.220]\u001b[A\n",
            "8/10 * Epoch (train):  12% 12/96 [08:02<56:28, 40.34s/it, loss=0.220]\u001b[A\n",
            "8/10 * Epoch (train):  12% 12/96 [08:42<56:28, 40.34s/it, loss=0.244]\u001b[A\n",
            "8/10 * Epoch (train):  14% 13/96 [08:42<55:52, 40.39s/it, loss=0.244]\u001b[A\n",
            "8/10 * Epoch (train):  14% 13/96 [09:23<55:52, 40.39s/it, loss=0.213]\u001b[A\n",
            "8/10 * Epoch (train):  15% 14/96 [09:23<55:07, 40.33s/it, loss=0.213]\u001b[A\n",
            "8/10 * Epoch (train):  15% 14/96 [10:03<55:07, 40.33s/it, loss=0.217]\u001b[A\n",
            "8/10 * Epoch (train):  16% 15/96 [10:03<54:33, 40.42s/it, loss=0.217]\u001b[A\n",
            "8/10 * Epoch (train):  16% 15/96 [10:43<54:33, 40.42s/it, loss=0.227]\u001b[A\n",
            "8/10 * Epoch (train):  17% 16/96 [10:43<53:46, 40.33s/it, loss=0.227]\u001b[A\n",
            "8/10 * Epoch (train):  17% 16/96 [11:24<53:46, 40.33s/it, loss=0.224]\u001b[A\n",
            "8/10 * Epoch (train):  18% 17/96 [11:24<53:06, 40.33s/it, loss=0.224]\u001b[A\n",
            "8/10 * Epoch (train):  18% 17/96 [12:04<53:06, 40.33s/it, loss=0.230]\u001b[A\n",
            "8/10 * Epoch (train):  19% 18/96 [12:04<52:32, 40.42s/it, loss=0.230]\u001b[A\n",
            "8/10 * Epoch (train):  19% 18/96 [12:44<52:32, 40.42s/it, loss=0.214]\u001b[A\n",
            "8/10 * Epoch (train):  20% 19/96 [12:44<51:44, 40.32s/it, loss=0.214]\u001b[A\n",
            "8/10 * Epoch (train):  20% 19/96 [13:25<51:44, 40.32s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):  21% 20/96 [13:25<50:59, 40.26s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):  21% 20/96 [14:05<50:59, 40.26s/it, loss=0.208]\u001b[A\n",
            "8/10 * Epoch (train):  22% 21/96 [14:05<50:21, 40.28s/it, loss=0.208]\u001b[A\n",
            "8/10 * Epoch (train):  22% 21/96 [14:46<50:21, 40.28s/it, loss=0.216]\u001b[A\n",
            "8/10 * Epoch (train):  23% 22/96 [14:46<49:49, 40.39s/it, loss=0.216]\u001b[A\n",
            "8/10 * Epoch (train):  23% 22/96 [15:26<49:49, 40.39s/it, loss=0.238]\u001b[A\n",
            "8/10 * Epoch (train):  24% 23/96 [15:26<49:06, 40.36s/it, loss=0.238]\u001b[A\n",
            "8/10 * Epoch (train):  24% 23/96 [16:06<49:06, 40.36s/it, loss=0.232]\u001b[A\n",
            "8/10 * Epoch (train):  25% 24/96 [16:06<48:27, 40.39s/it, loss=0.232]\u001b[A\n",
            "8/10 * Epoch (train):  25% 24/96 [16:46<48:27, 40.39s/it, loss=0.238]\u001b[A\n",
            "8/10 * Epoch (train):  26% 25/96 [16:46<47:40, 40.29s/it, loss=0.238]\u001b[A\n",
            "8/10 * Epoch (train):  26% 25/96 [17:27<47:40, 40.29s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):  27% 26/96 [17:27<47:05, 40.37s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):  27% 26/96 [18:06<47:05, 40.37s/it, loss=0.213]\u001b[A\n",
            "8/10 * Epoch (train):  28% 27/96 [18:06<46:08, 40.12s/it, loss=0.213]\u001b[A\n",
            "8/10 * Epoch (train):  28% 27/96 [18:47<46:08, 40.12s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  29% 28/96 [18:47<45:29, 40.14s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  29% 28/96 [19:27<45:29, 40.14s/it, loss=0.236]\u001b[A\n",
            "8/10 * Epoch (train):  30% 29/96 [19:27<44:47, 40.12s/it, loss=0.236]\u001b[A\n",
            "8/10 * Epoch (train):  30% 29/96 [20:07<44:47, 40.12s/it, loss=0.227]\u001b[A\n",
            "8/10 * Epoch (train):  31% 30/96 [20:07<44:02, 40.04s/it, loss=0.227]\u001b[A\n",
            "8/10 * Epoch (train):  31% 30/96 [20:47<44:02, 40.04s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  32% 31/96 [20:47<43:29, 40.15s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  32% 31/96 [21:27<43:29, 40.15s/it, loss=0.231]\u001b[A\n",
            "8/10 * Epoch (train):  33% 32/96 [21:27<42:38, 39.98s/it, loss=0.231]\u001b[A\n",
            "8/10 * Epoch (train):  33% 32/96 [22:07<42:38, 39.98s/it, loss=0.216]\u001b[A\n",
            "8/10 * Epoch (train):  34% 33/96 [22:07<42:09, 40.16s/it, loss=0.216]\u001b[A\n",
            "8/10 * Epoch (train):  34% 33/96 [22:47<42:09, 40.16s/it, loss=0.247]\u001b[A\n",
            "8/10 * Epoch (train):  35% 34/96 [22:47<41:30, 40.17s/it, loss=0.247]\u001b[A\n",
            "8/10 * Epoch (train):  35% 34/96 [23:28<41:30, 40.17s/it, loss=0.231]\u001b[A\n",
            "8/10 * Epoch (train):  36% 35/96 [23:28<41:06, 40.44s/it, loss=0.231]\u001b[A\n",
            "8/10 * Epoch (train):  36% 35/96 [24:09<41:06, 40.44s/it, loss=0.234]\u001b[A\n",
            "8/10 * Epoch (train):  38% 36/96 [24:09<40:27, 40.45s/it, loss=0.234]\u001b[A\n",
            "8/10 * Epoch (train):  38% 36/96 [24:48<40:27, 40.45s/it, loss=0.224]\u001b[A\n",
            "8/10 * Epoch (train):  39% 37/96 [24:48<39:26, 40.11s/it, loss=0.224]\u001b[A\n",
            "8/10 * Epoch (train):  39% 37/96 [25:29<39:26, 40.11s/it, loss=0.236]\u001b[A\n",
            "8/10 * Epoch (train):  40% 38/96 [25:29<38:53, 40.23s/it, loss=0.236]\u001b[A\n",
            "8/10 * Epoch (train):  40% 38/96 [26:09<38:53, 40.23s/it, loss=0.228]\u001b[A\n",
            "8/10 * Epoch (train):  41% 39/96 [26:09<38:17, 40.31s/it, loss=0.228]\u001b[A\n",
            "8/10 * Epoch (train):  41% 39/96 [26:50<38:17, 40.31s/it, loss=0.234]\u001b[A\n",
            "8/10 * Epoch (train):  42% 40/96 [26:50<37:41, 40.38s/it, loss=0.234]\u001b[A\n",
            "8/10 * Epoch (train):  42% 40/96 [27:30<37:41, 40.38s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  43% 41/96 [27:30<36:52, 40.22s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  43% 41/96 [28:11<36:52, 40.22s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  44% 42/96 [28:11<36:33, 40.62s/it, loss=0.229]\u001b[A\n",
            "8/10 * Epoch (train):  44% 42/96 [28:52<36:33, 40.62s/it, loss=0.253]\u001b[A\n",
            "8/10 * Epoch (train):  45% 43/96 [28:52<35:51, 40.60s/it, loss=0.253]\u001b[A\n",
            "8/10 * Epoch (train):  45% 43/96 [29:32<35:51, 40.60s/it, loss=0.232]\u001b[A\n",
            "8/10 * Epoch (train):  46% 44/96 [29:32<35:13, 40.64s/it, loss=0.232]\u001b[A\n",
            "8/10 * Epoch (train):  46% 44/96 [30:13<35:13, 40.64s/it, loss=0.212]\u001b[A\n",
            "8/10 * Epoch (train):  47% 45/96 [30:13<34:34, 40.67s/it, loss=0.212]\u001b[A\n",
            "8/10 * Epoch (train):  47% 45/96 [30:54<34:34, 40.67s/it, loss=0.238]\u001b[A\n",
            "8/10 * Epoch (train):  48% 46/96 [30:54<33:50, 40.61s/it, loss=0.238]\u001b[A\n",
            "8/10 * Epoch (train):  48% 46/96 [31:35<33:50, 40.61s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):  49% 47/96 [31:35<33:15, 40.71s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):  49% 47/96 [32:15<33:15, 40.71s/it, loss=0.223]\u001b[A\n",
            "8/10 * Epoch (train):  50% 48/96 [32:15<32:24, 40.52s/it, loss=0.223]\u001b[A\n",
            "8/10 * Epoch (train):  50% 48/96 [32:55<32:24, 40.52s/it, loss=0.216]\u001b[A\n",
            "8/10 * Epoch (train):  51% 49/96 [32:55<31:45, 40.55s/it, loss=0.216]\u001b[A\n",
            "8/10 * Epoch (train):  51% 49/96 [33:35<31:45, 40.55s/it, loss=0.235]\u001b[A\n",
            "8/10 * Epoch (train):  52% 50/96 [33:35<30:55, 40.33s/it, loss=0.235]\u001b[A\n",
            "8/10 * Epoch (train):  52% 50/96 [34:16<30:55, 40.33s/it, loss=0.233]\u001b[A\n",
            "8/10 * Epoch (train):  53% 51/96 [34:16<30:16, 40.37s/it, loss=0.233]\u001b[A\n",
            "8/10 * Epoch (train):  53% 51/96 [34:56<30:16, 40.37s/it, loss=0.230]\u001b[A\n",
            "8/10 * Epoch (train):  54% 52/96 [34:56<29:35, 40.35s/it, loss=0.230]\u001b[A\n",
            "8/10 * Epoch (train):  54% 52/96 [35:36<29:35, 40.35s/it, loss=0.226]\u001b[A\n",
            "8/10 * Epoch (train):  55% 53/96 [35:36<28:46, 40.16s/it, loss=0.226]\u001b[A"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwqhK2dyKuGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "references = []\n",
        "predictions = []\n",
        "model.eval()\n",
        "for i, item in tqdm(enumerate(data.DataLoader(ExtDataset(ext_test_records, vocabulary, bpe_processor=bpe_processor), batch_size=1, collate_fn=collate_fn)), total=ext_test_records.shape[0]):\n",
        "    logits = model(item[\"features\"].to(device))[0] # Прямой проход\n",
        "    record = ext_test_records.iloc[i]\n",
        "    predicted_summary = []\n",
        "    for i, logit in enumerate(logits):\n",
        "        if logit > 0.0:\n",
        "            predicted_summary.append(record['sentences'][i])\n",
        "    if not predicted_summary:\n",
        "        predicted_summary.append(record['sentences'][torch.max(logits, dim=0)[1].item()])\n",
        "    predicted_summary = \" \".join(predicted_summary)\n",
        "    references.append(record['summary'].lower())\n",
        "    predictions.append(predicted_summary)\n",
        "\n",
        "calc_scores(references, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kc0etEGfJ0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}